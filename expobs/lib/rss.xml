<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[AIA]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib/media/favicon.png</url><title>AIA</title><link></link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Tue, 13 Aug 2024 14:00:07 GMT</lastBuildDate><atom:link href="lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Tue, 13 Aug 2024 14:00:06 GMT</pubDate><ttl>60</ttl><dc:creator></dc:creator><item><title><![CDATA[hoofdstuk_1]]></title><description><![CDATA[ 
 <br><br><br>
<br>Deze verordening heeft tot doel de werking van de interne markt te verbeteren en de toepassing van mensgerichte en betrouwbare artificiële intelligentie (AI) te bevorderen, en tegelijkertijd een hoog niveau van bescherming van de gezondheid, de veiligheid en de in het Handvest verankerde grondrechten te waarborgen, met inbegrip van de democratie, de rechtsstaat en de bescherming van het milieu, tegen de schadelijke gevolgen van AI-systemen in de Unie, en innovatie te ondersteunen.
<br>Bij deze verordening worden vastgesteld:

<br>a) geharmoniseerde regels voor het in de handel brengen, in gebruik stellen en gebruiken van AI-systemen in de Unie; 
<br>b) een verbod op bepaalde AI-praktijken; 
<br>c) specifieke eisen voor AI-systemen met een hoog risico en verplichtingen voor de operatoren van dergelijke systemen; 
<br>d) geharmoniseerde transparantievoorschriften voor bepaalde AI-systemen; 
<br>e) geharmoniseerde regels voor het in de handel brengen van AI-modellen voor algemene doeleinden; 
<br>f) regels inzake marktmonitoring, markttoezicht, governance en handhaving van die regels; 
<br>g) maatregelen ter ondersteuning van innovatie, met bijzondere nadruk op kmo’s, waaronder start-ups.


<br><br>
<br>Deze verordening is van toepassing op: 1. a) aanbieders die AI-systemen in de Unie in de handel brengen of in gebruik stellen, of AI-modellen voor algemene doeleinden in de handel brengen, ongeacht of deze aanbieders in de Unie of in een derde land zijn gevestigd of er zich bevinden; 2. b) gebruiksverantwoordelijken van AI-systemen die in de Unie zijn gevestigd of er zich bevinden; 3. c) aanbieders en gebruiksverantwoordelijken van AI-systemen die in een derde land zijn gevestigd of er zich bevinden, indien de output van het AI-systeem in de Unie wordt gebruikt; 4. d) importeurs en distributeurs van AI-systemen; 5. e) fabrikanten van producten die samen met hun product en onder hun eigen naam of merk een AI-systeem in de handel brengen of in gebruik stellen; 6. f) gemachtigden van aanbieders die niet in de Unie gevestigd zijn; 7. g) getroffen personen die zich in de Unie bevinden.
<br>Op AI-systemen die overeenkomstig artikel 6, lid 1, als AI-systemen met een hoog risico worden aangemerkt die verband houden met producten die vallen onder de in bijlage I, afdeling B, opgenomen harmonisatiewetgeving van de Unie, zijn uitsluitend artikel 6, lid 1, de artikelen 102 tot en met 109 en artikel 112 van toepassing. Artikel 57 is alleen van toepassing voor zover de eisen voor AI-systemen met een hoog risico uit hoofde van deze verordening zijn opgenomen in die harmonisatiewetgeving van de Unie.
<br>Deze verordening is niet van toepassing op gebieden die buiten het toepassingsgebied van het Unierecht vallen en doet in geen geval afbreuk aan de bevoegdheden van de lidstaten op het gebied van nationale veiligheid, ongeacht het soort entiteit dat door de lidstaten is belast met de uitvoering van taken in verband met die bevoegdheden.<br>
Deze verordening is niet van toepassing op AI-systemen wanneer en in zover die uitsluitend in de handel worden gebracht, in gebruik worden gesteld of, al dan niet gewijzigd, worden gebruikt voor militaire, defensie- of nationale veiligheidsdoeleinden, ongeacht het soort entiteit dat deze activiteiten uitvoert.<br>
Deze verordening is niet van toepassing op AI-systemen die niet in de Unie in de handel worden gebracht of in gebruik worden gesteld en waarvan de output in de Unie uitsluitend wordt gebruikt voor militaire, defensie- of nationale veiligheidsdoeleinden, ongeacht het soort entiteit dat deze activiteiten uitvoert.
<br>Deze verordening is niet van toepassing op overheidsinstanties in derde landen of internationale organisaties die op grond van lid 1 binnen het toepassingsgebied van deze verordening vallen, wanneer deze instanties of organisaties AI-systemen gebruiken in het kader van internationale samenwerking of overeenkomsten met de Unie of een of meer lidstaten op het gebied van rechtshandhaving en justitie, op voorwaarde dat een dergelijk derde land of internationale organisatie passende waarborgen biedt met betrekking tot de bescherming van de grondrechten en fundamentele vrijheden van natuurlijke personen.
<br>Deze verordening laat de toepassing van de bepalingen inzake de aansprakelijkheid van aanbieders van tussenhandelsdiensten als vastgelegd in hoofdstuk II van Verordening (EU) 2022/2065 onverlet.
<br>Deze verordening is niet van toepassing op AI-systemen of AI-modellen, met inbegrip van hun output, die specifiek zijn ontwikkeld en in gebruik gesteld met wetenschappelijk onderzoek en wetenschappelijke ontwikkeling als enig doel.
<br>Het Unierecht inzake de bescherming van persoonsgegevens, de privacy en de vertrouwelijkheid van communicatie is van toepassing op persoonsgegevens die worden verwerkt in verband met de rechten en verplichtingen die in deze verordening zijn vastgelegd. Deze verordening laat de Verordeningen (EU) 2016/679 of (EU) 2018/1725, of de Richtlijnen 2002/58/EG of (EU) 2016/680 onverlet, onverminderd artikel 10, lid 5, en artikel 59 van deze verordening.
<br>Deze verordening is niet van toepassing op onderzoeks-, test- of ontwikkelingsactiviteiten met betrekking tot AI-systemen of AI-modellen voor zij in de handel worden gebracht of in gebruik worden gesteld. Dergelijke activiteiten worden uitgevoerd in overeenstemming met het toepasselijke Unierecht. Testen onder reële omstandigheden vallen niet onder die uitsluiting.
<br>Deze verordening doet geen afbreuk aan de regels die zijn vastgelegd in andere rechtshandelingen van de Unie betreffende consumentenbescherming en productveiligheid.
<br>Deze verordening is niet van toepassing op verplichtingen van gebruiksverantwoordelijken die natuurlijke personen zijn die AI-systemen gebruiken in het kader van een louter persoonlijke niet-professionele activiteit.
<br>Deze verordening belet de Unie of de lidstaten niet om wettelijke of bestuursrechtelijke bepalingen te handhaven of in te voeren die gunstiger zijn voor werknemers wat betreft de bescherming van hun rechten met betrekking tot het gebruik van AI-systemen door werkgevers, of om de toepassing van voor werknemers gunstigere collectieve overeenkomsten aan te moedigen of toe te staan.
<br>Deze verordening is niet van toepassing op AI-systemen die worden vrijgegeven onder vrije en opensource licenties, tenzij zij in de handel worden gebracht of in gebruik worden gesteld als AI-systemen met een hoog risico of als een AI-systeem dat onder artikel 5 of artikel 50 valt.
<br><br>Voor de toepassing van deze verordening wordt verstaan onder:<br>
<br>“AI-systeem”: een op een machine gebaseerd systeem dat is ontworpen om met verschillende niveaus van autonomie te werken en dat na het inzetten ervan aanpassingsvermogen kan vertonen, en dat, voor expliciete of impliciete doelstellingen, uit de ontvangen input afleidt hoe output te genereren zoals voorspellingen, inhoud, aanbevelingen of beslissingen die van invloed kunnen zijn op fysieke of virtuele omgevingen;
<br>“risico”: de combinatie van de kans op schade en de ernst van die schade;
<br>“aanbieder”: een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem of een AI-model voor algemene doeleinden ontwikkelt of laat ontwikkelen en dat systeem of model in de handel brengt of het AI-systeem in gebruik stelt onder de eigen naam of merk, al dan niet tegen betaling;
<br>“gebruiksverantwoordelijke”: een natuurlijke of rechtspersoon, overheidsinstantie, agentschap of ander orgaan die/dat een AI-systeem onder eigen verantwoordelijkheid gebruikt, tenzij het AI-systeem wordt gebruikt in het kader van een persoonlijke niet-beroepsactiviteit;
<br>“gemachtigde”: een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een schriftelijke machtiging heeft gekregen en aanvaard van een aanbieder van een AI-systeem of een AI-model voor algemene doeleinden om namens die aanbieder de verplichtingen en procedures van deze verordening respectievelijk na te komen en uit te voeren;
<br>“importeur”: een natuurlijke of rechtspersoon die zich bevindt of gevestigd is in de Unie die een AI-systeem in de handel brengt dat de naam of het merk van een in een derde land gevestigde natuurlijke of rechtspersoon draagt;
<br>“distributeur”: een andere natuurlijke persoon of rechtspersoon in de toeleveringsketen dan de aanbieder of de importeur, die een AI-systeem in de Unie op de markt aanbiedt;
<br>“operator”: een aanbieder, productfabrikant, gebruiksverantwoordelijke, gemachtigde, importeur of distributeur;
<br>“in de handel brengen”: het voor het eerst in de Unie op de markt aanbieden van een AI-systeem of een AI-model voor algemene doeleinden;
<br>“op de markt aanbieden”: het in het kader van een handelsactiviteit, al dan niet tegen betaling, verstrekken van een AI-systeem of een AI-model voor algemene doeleinden met het oog op distributie of gebruik op de markt van de Unie;
<br>“in gebruik stellen”: de directe levering van een AI-systeem aan de gebruiksverantwoordelijke voor het eerste gebruik of voor eigen gebruik in de Unie voor het beoogde doel;
<br>“beoogd doel”: het gebruik waarvoor een AI-systeem door de aanbieder is bedoeld, met inbegrip van de specifieke context en voorwaarden van het gebruik, zoals gespecificeerd in de informatie die door de aanbieder in de gebruiksinstructies, reclame- of verkoopmaterialen en verklaringen, alsook in de technische documentatie is verstrekt;
<br>“redelijkerwijs te voorzien misbruik”: het gebruik van een AI-systeem op een wijze die niet in overeenstemming is met het beoogde doel, maar die kan voortvloeien uit redelijkerwijs te voorzien menselijk gedrag of redelijkerwijs te voorziene interactie met andere systemen, waaronder andere AI-systemen;
<br>“veiligheidscomponent”: een component van een product of van een AI-systeem die een veiligheids-functie voor dat product of AI-systeem vervult of waarvan het falen of gebrekkig functioneren de gezondheid en veiligheid van personen of eigendom in gevaar brengt;
<br>“gebruiksinstructies”: de door de aanbieder verstrekte informatie om de gebruiksverantwoordelijke te informeren over met name het beoogde doel en juiste gebruik van een AI-systeem;
<br>“terugroepen van een AI-systeem”: een maatregel gericht op het retourneren aan de aanbieder, het buiten gebruik stellen of het onbruikbaar maken van een AI-systeem dat aan gebruiksverantwoordelijken ter beschikking is gesteld;
<br>“uit de handel nemen van een AI-systeem”: een maatregel waarmee wordt beoogd te voorkomen dat een AI-systeem dat zich in de toeleveringsketen bevindt, op de markt wordt aangeboden;
<br>“prestaties van een AI-systeem”: het vermogen van een AI-systeem om het beoogde doel te verwezenlijken;
<br>“aanmeldende autoriteit”: de nationale autoriteit die verantwoordelijk is voor het opzetten en uitvoeren van de noodzakelijke procedures voor de beoordeling, aanwijzing en kennisgeving van de conformiteitsbeoordelingsinstanties en de monitoring hiervan;
<br>“conformiteitsbeoordeling”: het proces waarbij de naleving wordt aangetoond van de voorschriften van hoofdstuk III, afdeling 2, in verband met een AI-systeem met een hoog risico;
<br>“conformiteitsbeoordelingsinstantie”: een instantie die als derde partij conformiteits-beoordelingsactiviteiten verricht, zoals onder meer testen, certificeren en inspecteren;
<br>“aangemelde instantie”: een conformiteitsbeoordelingsinstantie die overeenkomstig deze verordening en andere relevante harmonisatiewetgeving van de Unie, is aangemeld;
<br>“substantiële wijziging”: een verandering van een AI-systeem nadat dit in de handel is gebracht of in gebruik is gesteld, die door de aanbieder niet is voorzien of gepland in de initiële conformiteitsbeoordeling en als gevolg waarvan de overeenstemming van het AI-systeem met de voorschriften van hoofdstuk III, afdeling 2, wordt beïnvloed, of die leidt tot een wijziging van het beoogde doel waarvoor het AI-systeem is beoordeeld;
<br>“CE-markering”: een markering waarmee een aanbieder aangeeft dat een AI-systeem in overeenstemming is met de voorschriften van hoofdstuk III, afdeling 2, en andere toepasselijke harmonisatiewetgeving van de Unie, die in het aanbrengen ervan voorzien;
<br>“systeem voor monitoring na het in de handel brengen”: alle door aanbieders van AI-systemen verrichte activiteiten voor het verzamelen en evalueren van ervaringen met door hen in de handel gebrachte of in gebruik gestelde AI-systemen, teneinde te kunnen vaststellen of er onmiddellijk corrigerende dan wel preventieve maatregelen nodig zijn;
<br>“markttoezichtautoriteit”: de nationale autoriteit die de activiteiten verricht en maatregelen neemt als bedoeld in Verordening (EU) 2019/1020;
<br>“geharmoniseerde norm”: een geharmoniseerde norm zoals gedefinieerd in artikel 2, lid 1, punt c), van Verordening (EU) nr. 1025/2012;
<br>“gemeenschappelijke specificatie”: een reeks technische specificaties zoals gedefinieerd in artikel 2, punt 4, van Verordening (EU) nr. 1025/2012, om te voldoen aan bepaalde voorschriften zoals vastgelegd in deze verordening;
<br>“trainingsdata”: data die worden gebruikt voor het trainen van een AI-systeem door de leerbare parameters hiervan aan te passen;
<br>“validatiedata”: data die worden gebruikt voor het verrichten van een evaluatie van het getrainde AI-systeem en voor het afstemmen van onder andere de niet-leerbare parameters en het leerproces ervan, om underfitting of overfitting te voorkomen;
<br>“validatiedataset”: een afzonderlijke dataset of deel van de trainingsdataset, als vaste of variabele opdeling;
<br>“testdata”: data die worden gebruikt voor het verrichten van een onafhankelijke evaluatie van het AI-systeem om de verwachte prestaties van dat systeem te bevestigen voordat het in de handel wordt gebracht of in gebruik wordt gesteld;
<br>“inputdata”: data die in een AI-systeem worden ingevoerd of direct door een AI-systeem worden verworven en op basis waarvan het systeem een output genereert;
<br>“biometrische gegevens”: persoonsgegevens die het resultaat zijn van een specifieke technische verwerking met betrekking tot de fysieke, fysiologische of gedragsgerelateerde kenmerken van een natuurlijk persoon, zoals gezichtsafbeeldingen of vingerafdrukgegevens;
<br>“biometrische identificatie”: de geautomatiseerde herkenning van fysieke, fysiologische, gedragsgerelateerde of psychologische menselijke kenmerken om de identiteit van een natuurlijk persoon vast te stellen door biometrische gegevens van die persoon te vergelijken met in een databank opgeslagen biometrische gegevens van personen;
<br>“biometrische verificatie”: de geautomatiseerde één-op-éénverificatie, met inbegrip van de authenticatie, van de identiteit van natuurlijke personen door hun biometrische gegevens te vergelijken met eerder verstrekte biometrische gegevens;
<br>“bijzondere categorieën persoonsgegevens”: de categorieën persoonsgegevens als bedoeld in artikel 9, lid 1, van Verordening (EU) 2016/679, artikel 10 van Richtlijn (EU) 2016/680 en artikel 10, lid 1, van Verordening (EU) 2018/1725;
<br>“gevoelige operationele gegevens”: operationele gegevens met betrekking tot activiteiten op het gebied van preventie, opsporing, onderzoek of vervolging van strafbare feiten waarvan de openbaarmaking de integriteit van strafprocedures in het gedrang zou kunnen brengen;
<br>“systeem voor het herkennen van emoties”: een AI-systeem dat is bedoeld voor het vaststellen of afleiden van de emoties of intenties van natuurlijke personen op basis van hun biometrische gegevens;
<br>“systeem voor biometrische categorisering” een AI-systeem dat is bedoeld voor het indelen van natuurlijke personen in specifieke categorieën op basis van hun biometrische gegevens, tenzij dit een aanvulling vormt op een andere commerciële dienst en om objectieve technische redenen strikt noodzakelijk is;
<br>“systeem voor biometrische identificatie op afstand”: een AI-systeem dat is bedoeld voor het identificeren van natuurlijke personen, zonder dat zij daar actief bij betrokken zijn en doorgaans van een afstand, door middel van vergelijking van de biometrische gegevens van een persoon met de biometrische gegevens die zijn opgenomen in een referentiedatabank;
<br>“systeem voor biometrische identificatie op afstand in real time”: een systeem voor biometrische identificatie op afstand, waarbij het vastleggen van biometrische gegevens, de vergelijking en de identificatie zonder significante vertraging plaatsvinden, zowel wanneer de identificatie niet enkel onmiddellijk plaatsvindt, maar ook wanneer de identificatie met beperkte korte vertragingen plaatsvindt, om omzeiling te voorkomen;
<br>“systeem voor biometrische identificatie op afstand achteraf”: een ander biometrisch systeem voor de identificatie op afstand dan een systeem voor biometrische identificatie op afstand in real time;
<br>“openbare ruimte”: een fysieke plek die in publieke of private handen is en toegankelijk is voor een onbepaald aantal natuurlijke personen, ongeacht of bepaalde voorwaarden voor de toegang van toepassing zijn, en ongeacht eventuele capaciteitsbeperkingen;
<br>“rechtshandhavingsinstantie”:

<br>a) iedere overheidsinstantie die bevoegd is voor de voorkoming van, het onderzoek naar, de opsporing en de vervolging van strafbare feiten of de uitvoering van straffen, met inbegrip van de bescherming tegen en de voorkoming van gevaren voor de openbare veiligheid, of
<br>b) ieder ander orgaan dat of iedere andere entiteit die krachtens het recht van de lidstaten is gemachtigd openbaar gezag en openbare bevoegdheden uit te oefenen met het oog op de voorkoming van, het onderzoek naar, de opsporing en de vervolging van strafbare feiten of de uitvoering van straffen, met inbegrip van de bescherming tegen en de voorkoming van gevaren voor de openbare veiligheid;


<br>“rechtshandhaving”: activiteiten die worden verricht door of namens rechtshandhavings-instanties met het oog op de voorkoming van, het onderzoek naar, de opsporing of de vervolging van strafbare feiten of de uitvoering van straffen, met inbegrip van de bescherming tegen en de voorkoming van gevaren voor de openbare veiligheid;
<br>“AI-bureau”: de taak van de Commissie waarbij zij bijdraagt aan de uitvoering van, de monitoring van en het toezicht op AI-systemen en AI-modellen voor algemene doeleinden, en AI-governance, als bepaald in het besluit van de Commissie van 24 januari 2024; verwijzingen in deze verordening naar het AI-bureau worden begrepen als verwijzingen naar de Commissie;
<br>“nationale bevoegde autoriteit”: een aanmeldende autoriteit of een de markttoezichtautoriteit; wat betreft AI-systemen die door instellingen, organen en instanties van de EU in gebruik worden gesteld of worden gebruikt, worden verwijzingen naar nationale bevoegde autoriteiten of markttoezichtautoriteiten in deze verordening begrepen als verwijzingen naar de Europese Toezichthouder voor gegevensbescherming;
<br>“ernstig incident”: een incident of gebrekkig functioneren van een AI-systeem dat direct of indirect leidt tot:

<br>a) het overlijden van een persoon of ernstige schade voor de gezondheid van een persoon;
<br>b) een ernstige en onomkeerbare verstoring van het beheer of de exploitatie van kritieke infrastructuur;
<br>c) een schending van de uit het recht van de Unie voortvloeiende verplichtingen ter bescherming van de grondrechten;
<br>d) ernstige schade aan eigendommen of het milieu;


<br>“persoonsgegevens”: persoonsgegevens zoals gedefinieerd in artikel 4, punt 1, van Verordening (EU) 2016/679;
<br>“niet-persoonsgebonden gegevens”: andere gegevens dan persoonsgegevens zoals gedefinieerd in artikel 4, punt 1, van Verordening (EU) 2016/679;
<br>“profilering”: profilering zoals gedefinieerd in artikel 4, punt 4, van Verordening (EU) 2016/679;
<br>“plan voor testen onder reële omstandigheden”: een document waarin de doelstellingen, methode, geografische reikwijdte, betrokken personen, duur, monitoring, organisatie en wijze van uitvoering van een test onder reële omstandigheden worden omschreven;
<br>“testomgevingsplan”: tussen de deelnemende aanbieder en de bevoegde autoriteit overeengekomen document waarin de doelstellingen, de voorwaarden, het tijdschema, de methode en de vereisten voor de in de testomgeving uitgevoerde activiteiten worden beschreven;
<br>“AI-testomgeving voor regelgeving”: een door een bevoegde autoriteit opgezet gecontroleerd kader dat aanbieders of toekomstige aanbieders van AI-systemen de mogelijkheid biedt een innovatief AI-systeem te ontwikkelen, trainen, valideren en testen, zo nodig onder reële omstandigheden, volgens een testomgevingsplan, voor een beperkte periode en onder begeleiding van een toezichthouder;
<br>“AI-geletterdheid”: vaardigheden, kennis en begrip die aanbieders, gebruiksverantwoordelijken en betrokken personen, rekening houdend met hun respectieve rechten en plichten in het kader van deze verordening, in staat stellen geïnformeerd AI-systemen in te zetten en zich bewuster te worden van de kansen en risico’s van AI en de mogelijke schade die zij kan veroorzaken;
<br>“testen onder reële omstandigheden”: het tijdelijk testen van een AI-systeem voor zijn beoogde doel onder reële omstandigheden buiten een laboratorium of anderszins gesimuleerde omgeving teneinde betrouwbare en robuuste gegevens te verkrijgen, en te beoordelen en te verifiëren of het AI-systeem overeenstemt met de voorschriften van deze verordening en het wordt niet aangemerkt als het in de handel brengen of in gebruik stellen van het AI-systeem in de zin van deze verordening, mits aan alle in artikel 57 of artikel 60 vastgestelde voorwaarden is voldaan;
<br>“proefpersoon” in het kader van tests onder reële omstandigheden: een natuurlijk persoon die deelneemt aan een test onder reële omstandigheden;
<br>“geïnformeerde toestemming”: de vrijelijk gegeven, specifieke, ondubbelzinnige en vrijwillige uiting door een proefpersoon van zijn of haar bereidheid deel te nemen aan een bepaalde test onder reële omstandigheden, na geïnformeerd te zijn over alle aspecten van de test die van belang zijn voor zijn of haar beslissing om deel te nemen;
<br>“deepfake”: door AI gegenereerd of gemanipuleerd beeld-, audio- of videomateriaal dat een gelijkenis vertoont met bestaande personen, voorwerpen, plaatsen, entiteiten of gebeurtenissen, en door een persoon ten onrechte voor authentiek of waarheidsgetrouw zou worden aangezien;
<br>“wijdverbreide inbreuk”: alle handelingen of omissies die in strijd zijn met het Unierecht ter bescherming van de belangen van natuurlijke personen, waarbij:

<br>a) schade is veroorzaakt of waarschijnlijk zal worden veroorzaakt aan de collectieve belangen van natuurlijke personen met verblijfplaats in ten minste twee andere lidstaten dan de lidstaat waar:

<br>i) de handeling of omissie haar oorsprong vond of plaatshad;
<br>ii) de betrokken aanbieder of, waar van toepassing, diens gemachtigde zich bevindt of is gevestigd, of
<br>iii) de gebruiksverantwoordelijke is gevestigd, indien de inbreuk door de gebruiksverantwoordelijke is gepleegd;


<br>b) schade is veroorzaakt, wordt veroorzaakt of waarschijnlijk zal worden veroorzaakt aan de collectieve belangen van natuurlijke personen, en die gemeenschappelijke kenmerken hebben, waaronder dezelfde onrechtmatige praktijk of een inbreuk op hetzelfde belang, en die zich gelijktijdig voordoen en door dezelfde operator worden begaan in ten minste drie lidstaten;


<br>“kritieke infrastructuur”: kritieke infrastructuur zoals gedefinieerd in artikel 2, punt 4, van Richtlijn (EU) 2022/2557;
<br>“AI-model voor algemene doeleinden”: een AI-model, ook wanneer het is getraind met een grote hoeveelheid data met behulp van self-supervision op grote schaal, dat een aanzienlijk algemeen karakter vertoont en in staat is op competente wijze een breed scala aan verschillende taken uit te voeren, ongeacht de wijze waarop het model in de handel wordt gebracht, en dat kan worden geïntegreerd in een verscheidenheid aan systemen verder in de AI-waardeketen of toepassingen verder in de AI-waardeketen, met uitzondering van AI-modellen die worden gebruikt voor onderzoek, ontwikkeling of prototypingactiviteiten alvorens zij in de handel worden gebracht;
<br>“capaciteiten met een grote impact”: capaciteiten die overeenkomen met of groter zijn dan de capaciteiten die worden opgetekend bij de meest geavanceerde AI-modellen voor algemene doeleinden;
<br>“systeemrisico”: een risico dat specifiek is voor de capaciteiten met een grote impact van AI-modellen voor algemene doeleinden, die aanzienlijke gevolgen hebben voor de markt van de Unie vanwege hun bereik, of vanwege feitelijke of redelijkerwijs te voorziene negatieve gevolgen voor de gezondheid, de veiligheid, de openbare veiligheid, de grondrechten of de samenleving als geheel, en dat op grote schaal in de hele waardeketen kan worden verspreid;
<br>“AI-systeem voor algemene doeleinden”: een AI-systeem dat is gebaseerd op een AI-model voor algemene doeleinden en dat verschillende doeleinden kan dienen, zowel voor direct gebruik als voor integratie in andere AI-systemen;
<br>zwevendekommabewerking of “floating-point operation (FLOP)”: elke wiskundige bewerking of toewijzing met zwevendekommagetallen, die een subset vormen van de reële getallen die gewoonlijk op computers worden gerepresenteerd door een geheel getal met een vaste precisie, geschaald door een gehele exponent van een vaste basis;
<br>“aanbieder verder in de AI-waardeketen”: een aanbieder van een AI-systeem, met inbegrip van een AI-systeem voor algemene doeleinden, waarin een AI-model is geïntegreerd, ongeacht of het AI-model door hemzelf wordt verstrekt en verticaal geïntegreerd is of door een andere entiteit wordt aangeboden op basis van contractuele betrekkingen.
<br><br>Aanbieders en gebruiksverantwoordelijken van AI-systemen nemen maatregelen om, zoveel als mogelijk, te zorgen voor een toereikend niveau van AI-geletterdheid bij hun personeel en andere personen die namens hen AI-systemen exploiteren en gebruiken, en houden daarbij rekening met hun technische kennis, ervaring, onderwijs en opleiding en de context waarin de AI-systemen zullen worden gebruikt, evenals met de personen of groepen personen ten aanzien van wie de AI-systemen zullen worden gebruikt.]]></description><link>hoofdstukken/hoofdstuk_1.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_1.md</guid><pubDate>Tue, 13 Aug 2024 13:44:08 GMT</pubDate></item><item><title><![CDATA[HOOFDSTUK II VERBODEN AI-PRAKTIJKEN]]></title><description><![CDATA[ 
 <br><br><br>
<br>De volgende AI-praktijken zijn verboden:

<br>a) het in de handel brengen, het in gebruik stellen of het gebruiken van een AI-systeem dat subliminale technieken waarvan personen zich niet bewust zijn of doelbewust manipulatieve of misleidende technieken gebruikt, met als doel of effect het gedrag van personen of een groep personen wezenlijk te verstoren door hun vermogen om een geïnformeerd besluit te nemen merkbaar te belemmeren, waardoor zij een besluit nemen dat zij anders niet hadden genomen, op een wijze die ertoe leidt of er redelijkerwijs waarschijnlijk toe zal leiden dat deze of andere personen, of een groep personen, aanzienlijke schade oplopen;
<br>b) het in de handel brengen, het in gebruik stellen of het gebruiken van een AI-systeem dat gebruikmaakt van de kwetsbaarheden van een natuurlijke persoon of specifieke groep personen als gevolg van hun leeftijd, handicap of een specifieke sociale of economische omstandigheid, met als doel of met als gevolg het gedrag van die persoon of personen die tot deze groep behoren, wezenlijk te verstoren op een wijze die ertoe leidt of waarvan redelijkerwijze te verwachten is dat deze ertoe zal leiden dat deze of andere personen aanzienlijke schade oplopen;
<br>c) het in de handel brengen, het in gebruik stellen of het gebruiken van AI-systemen voor de evaluatie of classificatie van natuurlijke personen of groepen personen gedurende een bepaalde periode op basis van hun sociale gedrag of bekende, afgeleide of voorspelde persoonlijke of persoonlijkheidskenmerken, waarbij de sociale score een of beide van de volgende gevolgen heeft:

<br>i) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen in een sociale context die geen verband houdt met de context waarin de data oorspronkelijk werden gegenereerd of verzameld;
<br>ii) de nadelige of ongunstige behandeling van bepaalde natuurlijke personen of groepen personen die ongerechtvaardigd of onevenredig met hun sociale gedrag of de ernst hiervan is;


<br>d) het in de handel brengen, het voor dit specifieke doel in gebruik stellen of het gebruiken van een AI-systeem voor risicobeoordelingen van natuurlijke personen om het risico dat een natuurlijke persoon een strafbaar feit pleegt te beoordelen of te voorspellen, uitsluitend op basis van de profilering van een natuurlijke persoon of op basis van de beoordeling van diens persoonlijkheidseigenschappen en -kenmerken; dit verbod geldt niet voor AI-systemen die worden gebruikt ter ondersteuning van de menselijke beoordeling van de betrokkenheid van een persoon bij een criminele activiteit, die reeds op rechtstreeks met de criminele activiteit verband houdende objectieve en verifieerbare feiten is gebaseerd;
<br>e) het in de handel brengen, het voor dit specifieke doel in gebruik stellen of het gebruiken van AI-systemen die databanken voor gezichtsherkenning aanleggen of aanvullen door ongerichte scraping van gezichtsafbeeldingen van internet of CCTV-beelden;
<br>f) het in de handel brengen, het voor dit specifieke doel in gebruik stellen of het gebruiken van AI-systemen om emoties van een natuurlijke persoon op de werkplek en in het onderwijs uit af te leiden, behalve wanneer het gebruik van het AI-systeem is bedoeld om uit medische of veiligheidsoverwegingen te worden ingevoerd of in de handel te worden gebracht;
<br>g) het in de handel brengen, het voor dit specifieke doel in gebruik stellen of het gebruiken van systemen voor biometrische categorisering die natuurlijke personen individueel in categorieën indelen op basis van biometrische gegevens om hun ras, politieke opvattingen, lidmaatschap van een vakbond, religieuze of levensbeschouwelijke overtuigingen, seksleven of seksuele gerichtheid af te leiden; dit verbod geldt niet voor het labelen of filteren van rechtmatig verkregen biometrische datasets, zoals afbeeldingen, op basis van biometrische gegevens of categorisering van biometrische gegevens op het gebied van rechtshandhaving;
<br>h) het gebruik van systemen voor biometrische identificatie op afstand in real time in openbare ruimten met het oog op de rechtshandhaving, tenzij en voor zover een dergelijk gebruik strikt noodzakelijk is voor een van de volgende doelstellingen:

<br>i) het gericht zoeken naar specifieke slachtoffers van ontvoering, mensenhandel of seksuele uitbuiting van mensen, alsook het zoeken naar vermiste personen;
<br>ii) het voorkomen van een specifieke, aanzienlijke en imminente dreiging voor het leven of de fysieke veiligheid van natuurlijke personen of een reële en actuele of reële en voorspelbare dreiging van een terroristische aanslag;
<br>iii) de lokalisatie of identificatie van een persoon die ervan wordt verdacht een strafbaar feit te hebben gepleegd, ten behoeve van een strafrechtelijk onderzoek of vervolging of tenuitvoerlegging van een straf voor in bijlage II genoemde strafbare feiten waarop in de betrokken lidstaat een vrijheidsstraf of een tot vrijheidsbeneming strekkende maatregel staat met een maximumduur van ten minste vier jaar.<br>
Punt h) van de eerste alinea doet geen afbreuk aan artikel 9 van Verordening (EU) 2016/679 voor de verwerking van biometrische gegevens voor andere doeleinden dan rechtshandhaving.




<br>Het gebruik van systemen voor biometrische identificatie op afstand in real time in openbare ruimten met het oog op de rechtshandhaving voor de in lid 1, eerste alinea, punt h), bedoelde doelstellingen wordt ingezet voor de in dat punt bedoelde doeleinden, uitsluitend om de identiteit van de specifiek beoogde persoon te bevestigen en daarbij wordt rekening gehouden met het volgende:<br>
1. a) de aard van de situatie die aanleiding geeft tot het mogelijke gebruik van het systeem, met inbegrip van de ernst, waarschijnlijkheid en omvang van de schade die zonder het gebruik van het systeem zou worden veroorzaakt;<br>
2. b) de gevolgen van het gebruik van het systeem voor de rechten en vrijheden van alle betrokken personen, en met name de ernst, waarschijnlijkheid en omvang van deze gevolgen.<br>
Daarnaast moet het gebruik van systemen voor biometrische identificatie op afstand in real time in openbare ruimten met het oog op de rechtshandhaving voor de in lid 1, eerste alinea, punt h), genoemde doelstellingen in overeenstemming zijn met noodzakelijke en evenredige waarborgen en voorwaarden in verband met het gebruik in overeenstemming met het nationale recht dat het gebruik ervan toelaat, en met name ten aanzien van de beperking in de tijd en de geografische en persoonlijke beperkingen. Het gebruik van het systeem voor biometrische identificatie op afstand in real time in openbare ruimten wordt alleen toegestaan indien de rechtshandhavingsinstantie een in artikel 27 voorziene effectbeoordeling op het gebied van de grondrechten heeft uitgevoerd en het systeem volgens artikel 49 in de EU-databank heeft geregistreerd. In naar behoren gemotiveerde spoedeisende gevallen kan echter met het gebruik van dergelijke systemen worden begonnen zonder de systemen in de EU-databank te registreren, op voorwaarde dat die registratie zonder onnodige vertraging wordt voltooid.
<br>Voor de toepassing van lid 1, eerste alinea, punt h), en lid 2, wordt elk gebruik van systemen voor biometrische identificatie op afstand in real time in openbare ruimten met het oog op de rechtshandhaving afhankelijk gesteld van een voorafgaande toestemming die wordt verleend door een gerechtelijke instantie of een onafhankelijke administratieve instantie, waarvan het besluit bindend is, van de lidstaat waarin het gebruik moet plaatsvinden en die wordt gegeven op verzoek en in overeenstemming met de gedetailleerde regels van het nationale recht als bedoeld in lid 5. In een naar behoren gemotiveerde spoedeisende situatie kan echter zonder toestemming met het gebruik van een dergelijk systeem worden begonnen, op voorwaarde dat een dergelijke toestemming zonder onnodige vertraging en ten minste binnen 24 uur wordt aangevraagd. Bij weigering van die toestemming wordt het gebruik onmiddellijk gestaakt en worden alle gegevens, resultaten en outputs van dat gebruik onmiddellijk verwijderd en gewist.<br>
De bevoegde gerechtelijke instantie of onafhankelijke administratieve instantie, waarvan het besluit bindend is verleent de toestemming slechts wanneer zij op basis van objectief bewijs of duidelijke indicaties die aan haar zijn voorgelegd ervan overtuigd is dat het gebruik van het betreffende systeem voor biometrische identificatie op afstand in real time noodzakelijk is voor en evenredig is aan het bereiken van een van de in lid 1, eerste alinea, punt h), gespecificeerde doelstellingen, zoals genoemd in het verzoek en met name beperkt blijft tot wat strikt noodzakelijk is met betrekking tot de periode en de geografische en personele werkingssfeer. Bij haar beslissing over het verzoek houdt die instantie rekening met de in lid 2 bedoelde elementen. Een besluit dat nadelige rechtsgevolgen heeft voor een persoon mag niet uitsluitend worden genomen op basis van de output van het systeem voor biometrische identificatie op afstand in real time.
<br>Onverminderd lid 3 wordt elk gebruik van een systeem voor biometrische identificatie op afstand in real time in openbare ruimten met het oog op de rechtshandhaving gemeld bij de bevoegde markttoezichtautoriteit en de nationale gegevensbeschermingsautoriteit in overeenstemming met de in lid 5 bedoelde nationale regels. Die melding bevat ten minste de in lid 6 bepaalde informatie en bevat geen gevoelige operationele gegevens.
<br>Een lidstaat kan besluiten om te voorzien in de mogelijkheid om volledig of gedeeltelijk toestemming te verlenen voor het gebruik van systemen voor biometrische identificatie op afstand in real time in openbare ruimten met het oog op de rechtshandhaving binnen de grenzen en onder de voorwaarden van lid 1, eerste alinea, punt h), en de leden 2 en 3. De betrokken lidstaten leggen in hun nationale recht de noodzakelijke gedetailleerde regels vast voor het verzoek om en de afgifte en het gebruik van, evenals het toezicht en verslaglegging in verband met, de in lid 3 bedoelde vergunningen. In deze regels wordt ook gespecificeerd voor welke doelstellingen van lid 1, eerste alinea, punt h), en voor welke strafbare feiten als bedoeld in punt h), iii), daarvan de bevoegde autoriteiten deze systemen mogen gebruiken met het oog op de rechtshandhaving. De lidstaten stellen de Commissie uiterlijk dertig dagen na de vaststelling van die regels in kennis. De lidstaten kunnen in overeenstemming met het Unierecht restrictievere wetgeving inzake het gebruik van systemen voor biometrische identificatie op afstand invoeren.
<br>Nationale markttoezichtautoriteiten en nationale gegevensbeschermingsautoriteiten van lidstaten die op grond van lid 4 in kennis zijn gesteld van het gebruik van systemen voor biometrische identificatie op afstand in real time in openbare ruimten met het oog op de rechtshandhaving, dienen bij de Commissie jaarverslagen over dat gebruik in. Daartoe verstrekt de Commissie de lidstaten en de nationale markttoezicht- en gegevensbeschermingsautoriteiten een sjabloon, met informatie over het aantal besluiten dat is genomen door bevoegde gerechtelijke instanties of een onafhankelijke administratieve instantie, waarvan het besluit bindend is overeenkomstig lid 3, alsook het resultaat van die besluiten.
<br>De Commissie publiceert jaarverslagen over het gebruik van systemen voor biometrische identificatie op afstand in real time in openbare ruimten met het oog op de rechtshandhaving, op basis van geaggregeerde gegevens in de lidstaten op basis van de in lid 6 bedoelde jaarverslagen. Die jaarverslagen bevatten geen gevoelige operationele gegevens van de gerelateerde rechtshandhavingsactiviteiten.
<br>Dit artikel doet geen afbreuk aan de verbodsbepalingen die van toepassing zijn wanneer een AI-praktijk een inbreuk vormt op het Unierecht.
]]></description><link>hoofdstukken/hoofdstuk_2.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_2.md</guid><pubDate>Tue, 13 Aug 2024 13:54:21 GMT</pubDate></item><item><title><![CDATA[HOOFDSTUK III AI-SYSTEMEN MET EEN HOOG RISICO]]></title><description><![CDATA[ 
 <br><br><br><br>
<br>Ongeacht of een AI-systeem los van in de punten a) en b) bedoelde producten in de handel wordt gebracht of in gebruik wordt gesteld, wordt een AI-systeem als AI-systeem met een hoog risico beschouwd wanneer aan beide van de volgende voorwaarden is voldaan: 1. a) het AI-systeem is bedoeld om te worden gebruikt als veiligheidscomponent van een product of het AI-systeem is zelf een product dat valt onder de in bijlage I opgenomen harmonisatiewetgeving van de Unie; 2. b) voor het product waarvan het AI-systeem de veiligheidscomponent op grond van punt a) vormt of voor het AI-systeem als product zelf moet een conformiteits-beoordeling door een derde partij worden uitgevoerd met het oog op het in de handel brengen of in gebruik stellen van dat product op grond van de in bijlage I opgenomen harmonisatiewetgeving van de Unie.
<br>Naast de in lid 1 bedoelde AI-systemen met een hoog risico worden ook AI-systemen zoals bedoeld in bijlage III als AI-systeem met een hoog risico beschouwd.
<br>In afwijking van lid 2 wordt een in bijlage III bedoeld AI-systeem niet als AI-systeem met een hoog risico beschouwd wanneer het geen significant risico op schade voor de gezondheid, veiligheid of de grondrechten van natuurlijke personen inhoudt, onder meer doordat het de uitkomst van de besluitvorming niet wezenlijk beïnvloedt.<br>
De eerste alinea is van toepassing wanneer aan een van de volgende voorwaarden is voldaan:<br>
a) het AI-systeem is bedoeld om een beperkte procedurele taak uit te voeren;<br>
b) het AI-systeem is bedoeld om het resultaat van een eerder voltooide menselijke activiteit te verbeteren;<br>
c) het AI-systeem is bedoeld om besluitvormingspatronen of afwijkingen van eerdere besluitvormingspatronen op te sporen en is niet bedoeld om de eerder voltooide menselijke beoordeling zonder behoorlijke menselijke toetsing te vervangen of te beïnvloeden, of<br>
d) het AI-systeem is bedoeld om een voorbereidende taak uit te voeren voor een beoordeling die relevant is voor de in bijlage III vermelde gebruiksgevallen.<br>
Niettegenstaande de eerste alinea wordt een in bijlage III bedoeld AI-systeem altijd als een AI-systeem met een hoog risico beschouwd indien het AI-systeem profilering van natuurlijke personen uitvoert.
<br>Een aanbieder die van mening is dat een in bijlage III bedoeld AI-systeem geen hoog risico inhoudt, documenteert zijn beoordeling voordat dat systeem in de handel wordt gebracht of in gebruik wordt gesteld. Die aanbieder is onderworpen aan de registratieverplichting van artikel 49, lid 2. Op verzoek van de nationale bevoegde autoriteiten verstrekt de aanbieder de documentatie van de beoordeling.
<br>De Commissie verstrekt na raadpleging van de Europese raad voor artificiële intelligentie (de “AI-board”) en uiterlijk op 2 februari 2026 richtsnoeren voor de praktische uitvoering van dit artikel in overeenstemming met artikel 96, samen met een uitgebreide lijst van praktische voorbeelden van gebruiksgevallen van AI-systemen met een hoog risico en zonder hoog risico.
<br>De Commissie is bevoegd overeenkomstig artikel 97 gedelegeerde handelingen vast te stellen om teneinde lid 3, tweede alinea, van dit artikel te wijzigen door nieuwe voorwaarden toe te voegen aan de daarin vastgelegde voorwaarden, of door hen te wijzigen, indien er concrete en betrouwbare bewijzen zijn voor het bestaan van AI-systemen die onder het toepassingsgebied van bijlage III vallen, maar die geen significant risico inhouden op schade voor de gezondheid, veiligheid of grondrechten van natuurlijke personen.
<br>De Commissie stelt overeenkomstig artikel 97 gedelegeerde handelingen vast om lid 3, tweede alinea, van dit artikel te wijzigen door de daarin vastgelegde voorwaarden te schrappen, indien er concrete en betrouwbare aanwijzingen zijn dat dit noodzakelijk is om het in deze verordening bepaalde niveau van bescherming van de gezondheid, de veiligheid en de grondrechten te behouden.
<br>Overeenkomstig de leden 6 en 7 van dit artikel vastgestelde wijzigingen van de in lid 3, tweede alinea, vastgelegde voorwaarden doen geen afbreuk aan het in deze verordening bepaalde algemene niveau van bescherming van de gezondheid, de veiligheid en de grondrechten, en zorgen voor samenhang met de op grond van artikel 7, lid 1, vastgestelde gedelegeerde handelingen en houdenrekening met markt- en technologische ontwikkelingen.
<br><br>
<br>De Commissie is bevoegd overeenkomstig artikel 97 gedelegeerde handelingen vast te stellen tot wijziging van bijlage III door hieraan gebruiksgevallen van AI-systemen met een hoog risico toe te voegen of te wijzigen wanneer aan beide van de volgende voorwaarden is voldaan:<br>
a) de AI-systemen zijn bedoeld om te worden gebruikt op een van de gebieden als bedoeld in bijlage III;<br>
b) de AI-systemen vormen een risico op schade voor de gezondheid en veiligheid, of nadelige effecten op de grondrechten, en dat risico is gelijk aan of groter dan het risico op schade of nadelige effecten dat wordt gevormd door de AI-systemen met een hoog risico die reeds zijn opgenomen in bijlage III.
<br>Bij de beoordeling van de voorwaarde van lid 1, punt b), houdt de Commissie rekening met de volgende criteria:<br>
a) het beoogde doel van het AI-systeem;<br>
b) de mate waarin een AI-systeem is gebruikt of waarschijnlijk zal worden gebruikt;<br>
c) de aard van en de hoeveelheid gegevens die het AI-systeem verwerkt en gebruikt, met name of bijzondere categorieën persoonsgegevens worden verwerkt;<br>
d) de mate waarin het AI-systeem autonoom handelt en de mogelijkheid voor een mens om beslissingen of aanbevelingen die tot schade kunnen leiden terzijde te schuiven;<br>
e) de mate waarin het gebruik van een AI-systeem reeds schade voor de gezondheid en veiligheid of nadelige effecten op de grondrechten heeft veroorzaakt of aanleiding heeft gegeven tot aanzienlijke zorgen in verband met de waarschijnlijkheid van dergelijke schade of nadelige effecten, zoals aangetoond bijvoorbeeld door verslagen of gedocumenteerde beweringen die zijn ingediend bij de nationale bevoegde autoriteiten of, in voorkomend geval, door andere verslagen;<br>
f) de potentiële omvang van dergelijke schade of dergelijke nadelige effecten, met name wat betreft de intensiteit ervan en de mogelijkheid dat meerdere personen worden getroffen of dat een bepaalde groep personen onevenredig wordt getroffen;<br>
g) de mate waarin potentieel geschade of nadelig getroffen personen afhankelijk zijn van de aan de hand van een AI-systeem geproduceerde uitkomst, met name omdat het om praktische of juridische redenen niet redelijkerwijs mogelijk is om van deze uitkomst af te zien;<br>
h) de mate waarin sprake is van een onevenwichtige machtsverhouding, of de potentieel geschade of nadelig getroffen personen zich in een kwetsbare positie bevinden ten opzichte van de gebruiksverantwoordelijke van een AI-systeem, met name als gevolg van status, autoriteit, kennis, economische of sociale omstandigheden of leeftijd;<br>
i) de mate waarin de geproduceerde uitkomst waarbij een AI-systeem betrokken is niet gemakkelijk kan worden rechtgezet of omgekeerd, rekening houdend met de beschikbare technische oplossingen om die uitkomst recht te zetten of om te keren, waarbij van uitkomsten die nadelige effecten hebben op de gezondheid, veiligheid of grondrechten, niet wordt beschouwd dat zij eenvoudig kunnen worden rechtgezet of omgekeerd;<br>
j) de omvang en waarschijnlijkheid van het voordeel dat het inzetten van het AI-systeem voor natuurlijke personen, groepen of de samenleving in het algemeen, met inbegrip van mogelijke verbeteringen op het gebied van productveiligheid, met zich meebrengt;<br>
k) de mate waarin in het bestaande Unierecht is voorzien in:<br>
i) doeltreffende maatregelen om beroep aan te tekenen in verband met de risico’s van een AI-systeem, met uitzondering van vorderingen tot schadevergoeding;<br>
ii) doeltreffende maatregelen om deze risico’s te voorkomen of aanzienlijk te beperken.
<br>De Commissie is bevoegd overeenkomstig artikel 97 gedelegeerde handelingen vast te stellen tot wijziging van bijlage III door AI-systemen met een hoog risico te schrappen wanneer aan beide van de volgende voorwaarden is voldaan:<br>
a) het betrokken AI-systeem met een hoog risico vormt, rekening houdend met de in lid 2 vermelde criteria, geen significant risico voor de grondrechten, de gezondheid of de veiligheid;<br>
b) de schrapping leidt niet tot een lager algeheel beschermingsniveau wat betreft de gezondheid, de veiligheid en de grondrechten uit hoofde van het Unierecht.<br>
AFDELING 2<br>
Eisen voor AI-systemen met een hoog risico
<br><br>
<br>AI-systemen met een hoog risico moeten voldoen aan de eisen van deze afdeling, rekening houdend met hun beoogde doel en de algemeen erkende stand van de techniek op het gebied van AI en AI-gerelateerde technologieën. Bij het waarborgen van de naleving van deze eisen wordt rekening gehouden met het in artikel 9 bedoelde systeem voor risicobeheer.
<br>Indien een product een AI-systeem omvat waarop zowel de vereisten van deze verordening als die van de in bijlage I, afdeling A, vermelde harmonisatiewetgeving van de Unie van toepassing zijn, zijn aanbieders ervoor verantwoordelijk te waarborgen dat hun product volledig voldoet aan alle toepasselijke vereisten uit hoofde van de toepasselijke harmonisatiewetgeving van de Unie. Om te waarborgen dat de in lid 1 bedoelde AI-systemen met een hoog risico voldoen aan de eisen van deze afdeling en om te zorgen voor consistentie, dubbel werk te voorkomen en de extra lasten tot een minimum te beperken, hebben aanbieders de keuze om in voorkomend geval de nodige test- en rapportageprocessen en door hen verstrekte informatie en documentatie over hun product op te nemen in de reeds bestaande documentatie en procedures die vereist zijn uit hoofde van de in bijlage I, afdeling A, bedoelde harmonisatiewetgeving van de Unie.
<br><br>
<br>Met betrekking tot AI-systemen met een hoog risico wordt een systeem voor risicobeheer vastgesteld, uitgevoerd, gedocumenteerd en in stand gehouden.
<br>Onder het systeem voor risicobeheer wordt verstaan een tijdens de gehele levensduur van een AI-systeem met een hoog risico doorlopend en gepland iteratief proces, dat periodieke systematische toetsing en actualisering vereist. Het omvat de volgende stappen:<br>
a) het vaststellen en analyseren van de bekende en de redelijkerwijs te voorziene risico’s die het AI-systeem met een hoog risico kan inhouden voor de gezondheid, veiligheid of grondrechten indien het AI-systeem met een hoog risico in overeenstemming met het beoogde doel ervan wordt gebruikt;<br>
b) het inschatten en evalueren van de risico’s die zich kunnen voordoen wanneer het AI-systeem met een hoog risico wordt gebruikt in overeenstemming met het beoogde doel ervan en in een situatie van redelijkerwijs te voorzien misbruik;<br>
c) het evalueren van andere risico’s die zich kunnen voordoen op basis van de analyse van de data die zijn verzameld door het systeem voor monitoring na het in de handel brengen, als bedoeld in artikel 72;<br>
d) het vaststellen van gepaste en gerichte risicobeheersmaatregelen om de op grond van punt a) vastgestelde risico’s aan te pakken.
<br>De in dit artikel bedoelde risico’s omvatten uitsluitend risico’s die redelijkerwijs kunnen worden beperkt of weggenomen via het ontwikkelen of ontwerpen van het AI-systeem met een hoog risico of de verstrekking van adequate technische informatie.
<br>Ten aanzien van de in lid 2, punt d), bedoelde risicobeheersmaatregelen wordt naar behoren rekening gehouden met de effecten en mogelijke wisselwerking die voortvloeien uit de gecombineerde toepassing van de in deze afdeling uiteengezette eisen, teneinde de risico’s doeltreffender tot een minimum te beperken en tegelijkertijd een passend evenwicht te bereiken bij de uitvoering van de maatregelen ter vervulling van de voorschriften.
<br>De in lid 2, punt d), bedoelde risicobeheersmaatregelen zijn zodanig dat het desbetreffende restrisico in verband met elk gevaar en het totale restrisico van de AI-systemen met een hoog risico aanvaardbaar wordt geacht.<br>
Bij het vaststellen van de passendste risicobeheersmaatregelen wordt het volgende gewaarborgd:<br>
a) uitsluiting of beperking van op grond van lid 2 vastgestelde en geëvalueerde risico’s voor zover technisch haalbaar door middel van een adequaat ontwerp en ontwikkeling van het AI-systeem met een hoog risico;<br>
b) waar passend worden adequate maatregelen voor beperking en controle genomen voor het aanpakken van risico’s die niet kunnen worden uitgesloten;<br>
c) verstrekking van op grond van artikel 13 vereiste informatie en waar passend opleiding voor gebruiksverantwoordelijken.<br>
Teneinde de risico’s in verband met het gebruik van het AI-systeem met een hoog risico weg te nemen of te beperken, wordt naar behoren aandacht besteed aan de te verwachten technische kennis, ervaring, scholing en opleiding van de gebruiksverantwoordelijke en de vermoedelijke context waarin het systeem dient te worden gebruikt.
<br>AI-systemen met een hoog risico worden getest met het oog op het vaststellen van de passendste en gerichte risicobeheersmaatregelen. De tests zorgen ervoor dat AI-systemen met een hoog risico consistent presteren ten aanzien van het beoogde doel ervan en in overeenstemming zijn met de eisen van deze afdeling.
<br>De testprocedures kunnen onder meer bestaan in testen onder reële omstandigheden overeenkomstig artikel 60.
<br>Het testen van AI-systemen met een hoog risico vindt, zoals passend, in de loop van het ontwikkelingsproces plaats en in ieder geval voordat het systeem in de handel wordt gebracht of in gebruik wordt gesteld. Er wordt getest aan de hand van vooraf vastgestelde beoordelingsmaatstaven en probabilistische drempels die passend zijn voor het beoogde doel van het AI-systeem met een hoog risico.
<br>Bij de uitvoering van het in de leden 1 tot en met 7 bepaalde systeem voor risicobeheer houden aanbieders rekening met de vraag of het beoogde doel van het AI-systeem met een hoog risico waarschijnlijk negatieve gevolgen zal hebben voor personen jonger dan 18 jaar en, in voorkomend geval, voor andere kwetsbare groepen.
<br>Voor aanbieders van AI-systemen met een hoog risico die onderworpen zijn aan eisen met betrekking tot interne risicobeheerprocessen uit hoofde van andere relevante bepalingen van het Unierecht, kunnen de in de leden 1 tot en met 9 bepaalde aspecten deel uitmaken van of gecombineerd worden met de op grond van dat recht vastgestelde risicobeheerprocedures.
<br><br>
<br>AI-systemen met een hoog risico die technieken gebruiken die het trainen van AI-modellen met data omvatten, worden ontwikkeld op basis van datasets voor training, validatie en tests die voldoen aan de in de leden 2 tot en met 5 bedoelde kwaliteitscriteria telkens wanneer dergelijke datasets worden gebruikt.
<br>Datasets voor training, validatie en tests worden onderworpen aan praktijken op het gebied van databeheer die stroken met het beoogde doel van het AI-systeem met een hoog risico. Deze praktijken hebben in het bijzonder betrekking op:<br>
a) de relevante ontwerpkeuzes;<br>
b) processen voor dataverzameling en de oorsprong van de data en, in het geval van persoonsgegevens, het oorspronkelijke doel van de dataverzameling;<br>
c) relevante verwerkingsactiviteiten voor datavoorbereiding, zoals annotatie, labelen, opschoning, actualisatie, verrijking en aggregatie;<br>
d) het opstellen van aannames, met name met betrekking tot de informatie die de data moeten meten en vertegenwoordigen;<br>
e) een beoordeling van de beschikbaarheid, kwantiteit en geschiktheid van de datasets die nodig zijn;<br>
f) een beoordeling met het oog op mogelijke vooringenomenheid die waarschijnlijk gevolgen heeft voor de gezondheid en de veiligheid van personen, nadelige effecten heeft op de grondrechten, of leidt tot discriminatie die op grond van het Unierecht verboden is, vooral wanneer data-outputs invloed hebben op inputs voor toekomstige operaties;<br>
g) en passende maatregelen om mogelijke overeenkomstig punt f) vastgestelde vertekeningen op te sporen, te voorkomen en te beperken;<br>
h) het identificeren van relevante leemten of tekortkomingen in de data die naleving van deze verordening in de weg staan, en de manier waarop deze leemten en tekortkomingen kunnen worden aangepakt.
<br>Datasets voor training, validatie en tests zijn relevant, voldoende representatief, en zoveel mogelijk foutenvrij en volledig met het oog op het beoogde doel. De datasets hebben bovendien de passende statistische kenmerken, onder meer, waar van toepassing, met betrekking tot de personen of groepen personen ten aanzien van wie de AI-systemen met een hoog risico moeten worden gebruikt. Deze kenmerken van de datasets kunnen op het niveau van de afzonderlijke datasets of combinatie daarvan worden verwezenlijkt.
<br>Ten aanzien van datasets wordt, voor zover vereist gezien het beoogde doel hiervan, rekening gehouden met de eigenschappen of elementen die specifiek zijn voor een bepaalde geografische, contextuele, functionele of gedragsomgeving waarin het AI-systeem met een hoog risico moet worden gebruikt.
<br>Voor zover dit strikt noodzakelijk is om de opsporing en correctie van vertekeningen te waarborgen in verband met de AI-systemen met een hoog risico overeenkomstig lid 2, punten f) en g), van dit artikel, mogen de aanbieders van dergelijke systemen uitzonderlijk bijzondere categorieën persoonsgegevens verwerken, mits passende waarborgen worden geboden voor de grondrechten en fundamentele vrijheden van natuurlijke personen. Naast de bepalingen van Verordeningen (EU) 2016/679 en (EU) 2018/1725 en Richtlijn (EU) 2016/680 moeten voor een dergelijke verwerking alle volgende voorwaarden van toepassing zijn vervuld:<br>
a) de opsporing en correctie van vooringenomenheid kunnen niet doeltreffend worden vervuld door het verwerken van andere data, waaronder synthetische of geanonimiseerde data;<br>
b) de bijzondere categorieën persoonsgegevens zijn onderworpen aan technische beperkingen voor het hergebruik van persoonsgegevens, en geavanceerde beveiligings- en privacybeschermingsmaatregelen, waaronder pseudonimisering;<br>
c) de bijzondere categorieën persoonsgegevens zijn onderworpen aan maatregelen om ervoor te zorgen dat de verwerkte persoonsgegevens worden beveiligd, beschermd met passende waarborgen, waaronder strikte controles en documentatie van de toegang ertoe, om misbruik te voorkomen en ervoor te zorgen dat alleen personen die gemachtigd zijn toegang tot die persoonsgegevens hebben met passende vertrouwelijkheidsverplichtingen;<br>
d) de bijzondere categorieën persoonsgegevens worden niet verzonden, doorgegeven of anderszins geraadpleegd door andere partijen;<br>
e) de bijzondere categorieën persoonsgegevens worden verwijderd zodra de vertekening is gecorrigeerd of de periode van bewaring van de persoonsgegevens ten einde is gekomen, indien dit eerder is;<br>
f) het register op grond van Verordeningen (EU) 2016/679 en (EU) 2018/1725 en Richtlijn (EU) 2016/680 van verwerkingsactiviteiten bevat de redenen waarom de verwerking van bijzondere categorieën persoonsgegevens strikt noodzakelijk was om vertekeningen op te sporen en waarom die doelstelling niet kon worden bereikt door de verwerking van andere data.
<br>Voor de ontwikkeling van AI-systemen met een hoog risico die geen technieken voor de training van modellen gebruiken, zijn de leden 2 tot en met 5 uitsluitend van toepassing op de datasets voor tests.
<br><br>
<br>De technische documentatie van een AI-systeem met een hoog risico wordt opgesteld voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld, en wordt geactualiseerd.<br>
De technische documentatie wordt op zodanige wijze opgesteld dat wordt aangetoond dat het AI-systeem met een hoog risico in overeenstemming is met de eisen van deze afdeling en dat nationale bevoegde autoriteiten en aangemelde instanties over de noodzakelijke, op heldere en begrijpelijke wijze gestelde informatie beschikken om de overeenstemming van het AI-systeem met deze voorschriften te kunnen beoordelen. De documentatie omvat ten minste de in bijlage IV uiteengezette elementen. Kmo’s, met inbegrip van start-ups, kunnen de elementen van de in bijlage IV gespecificeerde technische documentatie op vereenvoudigde wijze verstrekken. Daartoe stelt de Commissie een vereenvoudigd formulier voor technische documentatie op dat is afgestemd op de behoeften van kleine en micro-ondernemingen. Kmo’s, met inbegrip van start-ups, die ervoor kiezen de in bijlage IV vereiste informatie op vereenvoudigde wijze te verstrekken, gebruiken het in dit lid bedoelde formulier. Aangemelde instanties aanvaarden het formulier met het oog op de conformiteitsbeoordeling.
<br>Wanneer een AI-systeem met een hoog risico dat verband houdt met een product dat valt onder de in bijlage I, afdeling A, opgenomen harmonisatiewetgeving van de Unie in de handel wordt gebracht of in gebruik wordt gesteld, wordt een enkel technisch document opgesteld dat alle informatie bevat zoals uiteengezet in lid 1, alsook de informatie die vereist is op grond van die rechtshandelingen.
<br>De Commissie is bevoegd overeenkomstig artikel 97 gedelegeerde handelingen vast te stellen om, waar nodig, bijlage IV te wijzigen om, in het licht van de technische vooruitgang, te waarborgen dat in de technische documentatie alle noodzakelijke informatie wordt verstrekt om de overeenstemming van het systeem met de eisen van deze afdeling te kunnen beoordelen.
<br><br>
<br>AI-systemen met een hoog risico zijn dusdanig technisch vormgegeven dat gebeurtenissen gedurende de levenscyclus van het systeem automatisch worden geregistreerd (“logs”).
<br>Teneinde ervoor te zorgen dat de werking van het AI-systeem met een hoog risico een niveau van traceerbaarheid heeft dat passend is voor het beoogde doel van het systeem, maken loggingfuncties het mogelijk om gebeurtenissen te registreren die relevant zijn ter:<br>
a) identificatie van situaties die ertoe kunnen leiden dat het AI-systeem met een hoog risico een risico vormt in de zin van artikel 79, lid 1, of dat er een substantiële wijziging optreedt;<br>
b) facilitering van de in artikel 72 bedoelde monitoring na het in de handel brengen, en<br>
c) monitoring van de werking van in artikel 26, lid 5, bedoelde AI-systemen met een hoog risico.
<br>Voor AI-systemen met een hoog risico als bedoeld in punt 1, a), van bijlage III voorzien de loggingcapaciteiten ten minste in:<br>
a) de registratie van de duur van elk gebruik van het systeem (begindatum en -tijd en einddatum en -tijd van elk gebruik);<br>
b) de referentiedatabank aan de hand waarvan de inputdata zijn gecontroleerd door het systeem;<br>
c) de inputdata ten aanzien waarvan de zoekopdracht een match heeft opgeleverd;<br>
d) de identificatie van de natuurlijke personen die betrokken zijn bij de verificatie van de resultaten, zoals bedoeld in artikel 14, lid 5.
<br><br>
<br>AI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat de werking ervan voldoende transparant is om gebruiksverantwoordelijken in staat te stellen de output van een systeem te interpreteren en op passende wijze te gebruiken. Een passende soort en mate van transparantie wordt gewaarborgd met het oog op de naleving van de relevante verplichtingen van de aanbieder en de gebruiksverantwoordelijke zoals uiteengezet in afdeling 3.
<br>AI-systemen met een hoog risico gaan vergezeld van gebruiksinstructies in een passend digitaal of ander formaat dat beknopte, volledige, juiste en duidelijke informatie bevat die relevant, toegankelijk en begrijpelijk is voor gebruiksverantwoordelijken.
<br>De gebruiksinstructies bevatten ten minste de volgende gegevens:<br>
a) de identiteit en de contactgegevens van de aanbieder en, in voorkomend geval, van zijn gemachtigde;<br>
b) de kenmerken, capaciteiten en beperkingen van de prestaties van het AI-systeem met een hoog risico, waaronder:<br>
i) het beoogde doel;<br>
ii) de mate van nauwkeurigheid, waaronder de beoordelingsmaatstaven, robuustheid en cyberbeveiliging als bedoeld in artikel 15 waarop het AI-systeem met een hoog risico is getest en gevalideerd en die kan worden verwacht, en eventuele bekende en te voorziene omstandigheden die een effect kunnen hebben op die verwachte mate van nauwkeurigheid, robuustheid en cyberbeveiliging;<br>
iii)<br>
eventuele bekende of te voorziene omstandigheden in verband met het gebruik van het AI-systeem met een hoog risico in overeenstemming met het beoogde doel ervan of in een situatie van redelijkerwijs te voorzien misbruik, die kunnen leiden tot risico’s voor de gezondheid en veiligheid of de grondrechten als bedoeld in artikel 9, lid 2;<br>
iv) in voorkomend geval, de technische capaciteiten en kenmerken van het AI-systeem met een hoog risico om informatie te verstrekken die relevant is om de output ervan toe te lichten;<br>
v) in voorkomend geval, zijn prestaties met betrekking tot specifieke personen of groepen personen voor wie het systeem moet worden gebruikt;<br>
vi) in voorkomend geval, specificaties voor de inputdata of eventuele andere relevante informatie met betrekking tot de gebruikte datasets voor training, validatie en tests, rekening houdend met het beoogde doel van het AI-systeem met een hoog risico;<br>
vii)<br>
in voorkomend geval, informatie om de gebruiksverantwoordelijken in staat te stellen de output van het AI-systeem met een hoog risico te interpreteren en op passende wijze te gebruiken;<br>
c) de wijzigingen van het AI-systeem met een hoog risico en de prestaties ervan die vooraf door de aanbieder zijn bepaald op het moment van de eerste conformiteitsbeoordeling, indien van toepassing;<br>
d) de in artikel 14 bedoelde maatregelen voor menselijk toezicht, met inbegrip van de technische maatregelen die zijn getroffen om de interpretatie van de output van de AI-systemen met een hoog risico door gebruiksverantwoordelijken te vergemakkelijken;<br>
e) de benodigde rekenkracht en hardware, de verwachte levensduur van het AI-systeem met een hoog risico en eventuele noodzakelijke maatregelen — en de frequentie daarvan — voor onderhoud en verzorging ter waarborging van de goede werking van dat AI-systeem, ook in verband met software-updates;<br>
f) in voorkomend geval, een beschrijving van de mechanismen in het AI-systeem met een hoog risico die gebruiksverantwoordelijken in staat stellen de logs naar behoren te verzamelen, op te slaan en te interpreteren overeenkomstig artikel 12.
<br><br>
<br>AI-systemen met een hoog risico worden zodanig ontworpen en ontwikkeld, met inbegrip van passende mens-machine-interface-instrumenten, dat hierop tijdens de periode dat zij worden gebruikt, op doeltreffende wijze toezicht kan worden uitgeoefend door natuurlijke personen.
<br>Het menselijk toezicht is gericht op het voorkomen of beperken van de risico’s voor de gezondheid, veiligheid of grondrechten die zich kunnen voordoen wanneer een AI-systeem met een hoog risico wordt gebruikt in overeenstemming met het beoogde doel ervan of in een situatie van redelijkerwijs te voorzien misbruik, met name wanneer dergelijke risico’s blijven bestaan ondanks de toepassing van andere eisen van deze afdeling.
<br>De toezichtmaatregelen staan in verhouding met de risico’s, de mate van autonomie en de gebruikscontext van het AI-systeem met een hoog risico en worden gewaarborgd door middel van een of alle van de volgende soorten maatregelen:<br>
a) door de aanbieder bepaalde maatregelen die waar technisch haalbaar in het AI-systeem met een hoog risico worden ingebouwd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld;<br>
b) door de aanbieder bepaalde maatregelen voordat het AI-systeem met een hoog risico in de handel wordt gebracht of in gebruik wordt gesteld en die passend zijn om door de gebruiksverantwoordelijke te worden uitgevoerd.
<br>Met het oog op de uitvoering van de leden 1, 2 en 3 wordt het AI-systeem met een hoog risico zodanig aan de gebruiksverantwoordelijke verstrekt dat natuurlijke personen die verantwoordelijk zijn voor het menselijk toezicht, in staat worden gesteld om waar passend en evenredig:<br>
a) de relevante capaciteiten en beperkingen van het AI-systeem met een hoog risico goed te begrijpen en de werking ervan naar behoren te kunnen monitoren, onder meer met het oog op het opsporen en aanpakken van onregelmatigheden, storingen en onverwachte prestaties;<br>
b) zich bewust te blijven van de mogelijke neiging om automatisch of te veel te vertrouwen op de output van een AI-systeem met een hoog risico (de zogenaamde “automation bias”), met name voor AI-systemen met een hoog risico die worden gebruikt om informatie of aanbevelingen te verstrekken voor beslissingen die door natuurlijke personen moeten worden genomen;<br>
c) de output van het AI-systeem met een hoog risico juist te interpreteren, bijvoorbeeld de beschikbare instrumenten en methoden voor interpretatie;<br>
d) in alle specifieke situaties te kunnen besluiten om het AI-systeem met een hoog risico niet te gebruiken of de output van het AI-systeem met een hoog risico op andere wijze te negeren, door een andere beslissing te vervangen of terug te draaien;<br>
e) in te grijpen in de werking van het AI-systeem met een hoog risico of het systeem te onderbreken door middel van een stopknop of een vergelijkbare procedure waarmee het systeem op veilige wijze kan worden stopgezet.
<br>Voor AI-systemen met een hoog risico als bedoeld in bijlage III, punt 1, a), zijn de maatregelen als bedoeld in lid 3 van dit artikel zodanig dat zij waarborgen dat daarnaast door de gebruiksverantwoordelijke geen maatregelen worden getroffen of beslissingen worden genomen op basis van de identificatie door het systeem, tenzij deze identificatie door ten minste twee natuurlijke personen met de nodige bekwaamheid, opleiding en bevoegdheid apart zijn geverifieerd en bevestigd.<br>
Het vereiste van een afzonderlijke verificatie door ten minste twee natuurlijke personen is niet van toepassing op AI-systemen met een hoog risico die gebruikt worden voor rechtshandhaving, migratie, grenstoezicht of asiel, in gevallen waarin het Unierecht of het nationale recht de toepassing van dit vereiste onevenredig acht.
<br><br>
<br>AI-systemen met een hoog risico worden op zodanige wijze ontworpen en ontwikkeld dat deze een passend niveau van nauwkeurigheid, robuustheid en cyberbeveiliging bieden, alsook consistente prestaties gedurende de levensduur met betrekking tot deze aspecten.
<br>Ter verduidelijking van de technische aspecten van de meting van het passende niveau van nauwkeurigheid en robuustheid als bedoeld in lid 1 en andere relevante prestatiestatistieken, moedigt de Commissie, in samenwerking met relevante belanghebbenden en organisaties, zoals metrologie- en benchmarkingautoriteiten, waar passend, de ontwikkeling van benchmarks en meetmethoden aan.
<br>De niveaus van nauwkeurigheid en de relevante maatstaven voor de nauwkeurigheid van AI-systemen met een hoog risico worden vermeld in de bijbehorende gebruiksaanwijzingen.
<br>AI-systemen met een hoog risico zijn zo goed mogelijk bestand tegen fouten en onregelmatigheden die zich binnen het systeem of de omgeving waarin het systeem wordt gebruikt, kunnen voordoen, met name als gevolg van de interactie ervan met natuurlijke personen of andere systemen. In dat opzicht worden technische en organisatorische maatregelen genomen.<br>
De robuustheid van AI-systemen met een hoog risico kan worden gerealiseerd door middel van technische oplossingen voor redundantie, die plannen voor de back-up of de veiligheid bij defecten kunnen omvatten.<br>
AI-systemen met een hoog risico die blijven leren nadat ze in de handel zijn gebracht of in gebruik zijn gesteld, worden op zodanige wijze ontwikkeld dat het risico op beïnvloeding van toekomstige operaties door gebruik van vertekende outputs als input (“feedback loops”) wordt weggenomen of zo veel mogelijk worden beperkt en dat elke dergelijke feedback loop naar behoren wordt aangepakt met behulp van passende beperkende maatregelen.
<br>AI-systemen met een hoog risico zijn bestand tegen pogingen van ongeautoriseerde derden om het gebruik, de outputs of de prestaties ervan te wijzigen door gebruik te maken van de kwetsbaarheden van het systeem.<br>
De technische oplossingen die gericht zijn op het waarborgen van de cyberbeveiliging van AI-systemen met een hoog risico sluiten aan op de relevante omstandigheden en risico’s.<br>
De technische oplossingen voor het aanpakken van AI-specifieke kwetsbaarheden omvatten, waar passend, maatregelen voor het voorkomen, traceren, reageren op, oplossen en beheersen van aanvallen waarmee een poging wordt gedaan tot het manipuleren van de dataset voor de training (de zogenaamde “datavervuiling”), van vooraf getrainde componenten die in de training zijn gebruikt (de zogenaamde “modelvervuiling”), van input die is gecreëerd om fouten van het model te veroorzaken (zogenaamde “vijandige voorbeelden” of “modelontwijking”), van aanvallen om vertrouwelijke gegevens te bemachtigen of van tekortkomingen van het model.<br>
AFDELING 3<br>
Verplichtingen van aanbieders en gebruiksverantwoordelijken van AI-systemen met een hoog risico en andere partijen
<br><br>Aanbieders van AI-systemen met een hoog risico:<br>
a) zorgen ervoor dat hun AI-systemen met een hoog risico in overeenstemming zijn met de eisen van afdeling 2;<br>
b) vermelden op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, naargelang het geval, hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres;<br>
c) beschikken over een systeem voor kwaliteitsbeheer dat in overeenstemming is met artikel 17;<br>
d) bewaren de in artikel 18 bedoelde documentatie;<br>
e) bewaren de in artikel 19 bedoelde logs die automatisch door hun AI-systemen met een hoog risico zijn gegenereerd, wanneer zij hierover de controle hebben;<br>
f) zorgen ervoor dat voor het AI-systeem met een hoog risico de desbetreffende in artikel 43 bedoelde conformiteitsbeoordelingsprocedure wordt uitgevoerd voordat dit systeem in de handel wordt gebracht of in gebruik wordt gesteld;<br>
g) stellen een EU-conformiteitsverklaring op, in overeenstemming met artikel 47;<br>
h) brengen de CE-markering aan op het AI-systeem met een hoog risico of, wanneer dit niet mogelijk is, op de verpakking of in de bij het product gevoegde documentatie, om aan te geven dat aan deze verordening is voldaan, overeenkomstig artikel 48;<br>
i) leven de registratieverplichtingen als bedoeld in artikel 49, lid 1, na;<br>
j) nemen de noodzakelijke corrigerende maatregelen en verstrekken de uit hoofde van artikel 20 vereiste informatie;<br>
k) tonen op een met redenen omkleed verzoek van een nationale bevoegde autoriteit de overeenstemming aan van het AI-systeem met een hoog risico met de eisen van afdeling 2;<br>
l) zorgen ervoor dat het AI-systeem met een hoog risico voldoet aan de toegankelijkheidseisen overeenkomstig de Richtlijnen (EU) 2016/2102 en (EU) 2019/882.<br><br>
<br>Aanbieders van AI-systemen met een hoog risico voorzien in een systeem voor kwaliteitsbeheer dat de naleving van deze verordening waarborgt. Dit systeem wordt op systematische en ordelijke wijze gedocumenteerd in de vorm van schriftelijke beleidslijnen, procedures en instructies en omvat ten minste de volgende aspecten:<br>
a) een strategie voor de naleving van de regelgeving, inclusief de naleving van de conformiteitsbeoordelingsprocedures en de procedures voor het beheer van de wijzigingen van het AI-systeem met een hoog risico;<br>
b) technieken, procedures en systematische maatregelen die moeten worden toegepast voor het ontwerp, de controle van het ontwerp en de verificatie van het ontwerp van het AI-systeem met een hoog risico;<br>
c) technieken, procedures en systematische maatregelen die moeten worden toegepast voor de ontwikkeling, de kwaliteitscontrole en de kwaliteitsborging van het AI-systeem met een hoog risico;<br>
d) procedures voor het inspecteren, testen en valideren die vóór, tijdens en na de ontwikkeling van het AI-systeem met een hoog risico moeten worden uitgevoerd en de regelmaat waarmee zij moeten worden uitgevoerd;<br>
e) technische specificaties, met inbegrip van normen, die moeten worden toegepast en, wanneer de relevante geharmoniseerde normen niet volledig worden toegepast of geen betrekking hebben op alle relevante eisen van afdeling 2, de middelen die worden gebruikt om ervoor te zorgen dat het AI-systeem met een hoog risico in overeenstemming is met deze eisen;<br>
f) systemen en procedures voor databeheer, met inbegrip van dataverwerving, -verzameling, -analyse, -labeling, -opslag, -zuivering, -aggregatie en -behoud en datamining en eventuele andere operaties met betrekking tot de data die worden uitgevoerd voorafgaand aan en met het oog op het in de handel brengen of in gebruik stellen van AI-systemen met een hoog risico;<br>
g) het systeem voor risicobeheer zoals bedoeld in artikel 9;<br>
h) het opzetten, toepassen en onderhouden van een systeem voor monitoring na het in de handel brengen, overeenkomstig artikel 72;<br>
i) procedures in verband met het melden van een ernstig incident in overeenstemming met artikel 73;<br>
j) de communicatie met nationale bevoegde autoriteiten, andere relevante autoriteiten, met inbegrip van autoriteiten die de toegang tot data verlenen of ondersteunen, aangemelde instanties, andere operatoren, klanten of andere belanghebbenden;<br>
k) systemen en procedures voor de registratie van alle relevante documentatie en informatie;<br>
l) het beheer van hulpmiddelen, met inbegrip van maatregelen in verband met de voorzieningszekerheid;<br>
m) een kader voor de verantwoording, waarin de verantwoordelijkheden van het management en ander personeel uiteen worden gezet met betrekking tot alle aspecten van dit lid.
<br>De uitvoering van de in lid 1 bedoelde aspecten is evenredig aan de omvang van de organisatie van de aanbieder. Aanbieders voldoen hoe dan ook aan de striktheid en het beschermingsniveau die nodig zijn om te garanderen dat hun AI-systemen met een hoog risico aan deze verordening voldoen.
<br>Aanbieders van AI-systemen met een hoog risico die onderworpen zijn aan verplichtingen met betrekking tot kwaliteitsbeheersystemen of een gelijkwaardige functie uit hoofde van het desbetreffende sectorale Unierecht, kunnen de in lid 1 genoemde aspecten opnemen als onderdeel van de op grond van dat recht vastgestelde kwaliteitsbeheersystemen.
<br>Voor aanbieders die in de hoedanigheid van financiële instellingen onderworpen zijn aan eisen met betrekking tot hun interne governance, regelingen of processen uit hoofde van het desbetreffende Unierecht inzake financiële diensten, wordt met uitzondering van lid 1, punten g), h) en i), van dit artikel de verplichting een systeem voor kwaliteitsbeheer in te voeren geacht te zijn vervuld door te voldoen aan de regels inzake interne governance, regelingen of processen uit hoofde van het desbetreffende Unierecht inzake financiële diensten. Daartoe wordt rekening gehouden met eventuele geharmoniseerde normen als bedoeld in artikel 40.
<br><br>
<br>De aanbieder houdt gedurende een periode van tien jaar nadat het AI-systeem met een hoog risico in de handel is gebracht of in gebruik is gesteld de volgende elementen ter beschikking van de nationale bevoegde autoriteiten:<br>
a) de technische documentatie als bedoeld in artikel 11;<br>
b) de documentatie betreffende het in artikel 17 bedoelde systeem voor kwaliteitsbeheer;<br>
c) in voorkomend geval de documentatie betreffende de door aangemelde instanties goedgekeurde wijzigingen;<br>
d) in voorkomend geval de besluiten en andere documenten die door de aangemelde instanties zijn afgegeven;<br>
e) de EU-conformiteitsverklaring als bedoeld in artikel 47.
<br>Elke lidstaat stelt de voorwaarden vast waaronder de in lid 1 bedoelde documentatie gedurende de in dat lid genoemde periode ter beschikking van de nationale bevoegde autoriteiten blijft voor de gevallen waarin een aanbieder of zijn op zijn grondgebied gevestigde gemachtigde failliet gaat of zijn activiteiten vóór het verstrijken van die termijn staakt.
<br>Aanbieders die in de hoedanigheid van financiële instellingen onderworpen zijn aan eisen met betrekking tot hun interne governance, regelingen of processen uit hoofde van het Unierecht voor financiële diensten, bewaren de technische documentatie als onderdeel van de documentatie die bewaard wordt krachtens het desbetreffende Unierecht inzake financiële diensten.
<br><br>
<br>Aanbieders van AI-systemen met een hoog risico bewaren de in artikel 12, lid 1, bedoelde logs die automatisch worden gegenereerd door hun AI-systemen met een hoog risico voor zover dergelijke logs onder hun controle vallen. Onverminderd het toepasselijke Unie- of nationale recht worden deze logs bewaard gedurende een periode, die passend is voor het beoogde doel van het AI-systeem met een hoog risico, van ten minste zes maanden, tenzij anders is bepaald in het toepasselijke Unie- of nationaal recht, met name het Unierecht inzake de bescherming van persoonsgegevens.
<br>Aanbieders die in de hoedanigheid van financiële instellingen onderworpen zijn aan eisen met betrekking tot hun interne governance, regelingen of processen uit hoofde van het Unierecht inzake financiële diensten, bewaren de automatisch door hun AI-systemen met een hoog risico gegenereerde logs, als onderdeel van de documentatie die bewaard wordt krachtens het desbetreffende recht inzake financiële diensten.
<br><br>
<br>Aanbieders van AI-systemen met een hoog risico die van mening zijn of redenen hebben om aan te nemen dat een door hen in de handel gebracht of in gebruik gesteld AI-systeem met een hoog risico niet in overeenstemming is met deze verordening, nemen onmiddellijk de nodige corrigerende maatregelen om dat systeem naargelang het geval in overeenstemming te brengen, uit de handel te nemen, te deactiveren of terug te roepen. Zij stellen de distributeurs van het betrokken AI-systeem met een hoog risico en, indien van toepassing, de gebruiksverantwoordelijken, de gemachtigden en importeurs dienovereenkomstig in kennis.
<br>Wanneer het AI-systeem met een hoog risico een risico vormt in de zin van artikel 79, lid 1, en de aanbieder kennis neemt van dat risico, onderzoekt hij onmiddellijk de oorzaken in samenwerking met, in voorkomend geval, de gebruiksverantwoordelijke die het risico heeft gemeld, informeert hij de markttoezichtautoriteiten die bevoegd zijn voor het betrokken AI-systeem met een hoog risico en, in voorkomend geval, de aangemelde instantie die een certificaat voor het AI-systeem met een hoog risico heeft afgegeven overeenkomstig artikel 44, met name over de aard van de non-conformiteit en over eventuele relevante getroffen corrigerende maatregelen.
<br><br>
<br>Op een met redenen omkleed verzoek van een bevoegde autoriteit, verstrekken aanbieders van AI-systemen met een hoog risico die autoriteit alle informatie en documentatie die noodzakelijk is om de overeenstemming van het AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, in een eenvoudig door de instantie te begrijpen en door de betrokken lidstaat gekozen officiële taal van de instellingen van de Unie.
<br>Op een met redenen omkleed verzoek van een bevoegde autoriteit verlenen aanbieders die verzoekende bevoegde autoriteit, indien van toepassing, toegang tot de in artikel 12, lid 1, bedoelde logs die automatisch zijn gegenereerd door hun AI-systeem met een hoog risico voor zover dergelijke logs onder hun controle vallen.
<br>De door de bevoegde autoriteit krachtens dit artikel verkregen informatie en documentatie worden verwerkt overeenkomstig de in artikel 78 vastgestelde vertrouwelijkheidsverplichtingen.
<br><br>
<br>Aanbieders die in derde landen zijn gevestigd, wijzen voordat zij hun AI-systemen met een hoog risico in de Unie in de handel brengen, middels een schriftelijke machtiging een gemachtigde aan die is gevestigd in de Unie.
<br>De aanbieder stelt zijn gemachtigde in staat de taken uit te voeren die staan gespecificeerd in het mandaat dat hij van de aanbieder heeft ontvangen.
<br>De gemachtigde voert de taken uit die gespecificeerd zijn in het mandaat dat hij van de aanbieder heeft ontvangen. Hij legt op verzoek een kopie van het mandaat over aan de markttoezichtautoriteiten, in een door de bevoegde autoriteit aangegeven officiële taal van de instellingen van de Unie. Voor de toepassing van deze verordening geeft het mandaat de gemachtigde de bevoegdheid om de volgende taken te verrichten:<br>
a) nagaan of de in artikel 47 bedoelde EU-conformiteitsverklaring en de in artikel 11 bedoelde technische documentatie zijn opgesteld en of de aanbieder een passende conformiteits-beoordelingsprocedure heeft uitgevoerd;<br>
b) gedurende een periode van tien jaar nadat het AI-systeem met een hoog risico in de handel is gebracht of in gebruik is gesteld, de contactgegevens van de aanbieder die de gemachtigde heeft aangewezen alsmede een kopie van de in artikel 47 bedoelde EU-conformiteitsverklaring, de technische documentatie en, in voorkomend geval, het door de aangemelde instantie afgegeven certificaat, ter beschikking houden van de bevoegde autoriteiten en de in artikel 74, lid 10, bedoelde nationale autoriteiten of organen;<br>
c) een bevoegde autoriteit op met redenen omkleed verzoek alle informatie en documentatie verstrekken, met inbegrip van de in punt b) van deze alinea bedoelde documentatie, die noodzakelijk is om de overeenstemming van een AI-systeem met een hoog risico met de eisen van afdeling 2 aan te tonen, met inbegrip van de in artikel 12, lid 1, bedoelde logs die automatisch zijn gegenereerd door het AI-systeem met een hoog risico voor zover dergelijke logs onder de controle van de aanbieder vallen;<br>
d) op met redenen omkleed verzoek samenwerken met bevoegde autoriteiten met betrekking tot alle maatregelen die door deze autoriteiten worden getroffen in verband met het AI-systeem met een hoog risico, met name om de risico’s van dat systeem te verminderen en te beperken;<br>
e) waar toepasselijk, voldoen aan de in artikel 49, lid 1, bedoelde registratieverplichtingen of, indien de registratie door de aanbieder zelf wordt uitgevoerd, waarborgen dat de in bijlage VIII, afdeling A, punt 3, bedoelde informatie juist is.<br>
Door het mandaat wordt de gemachtigde aangesteld als aanspreekpunt, naast of in plaats van de aanbieder, voor de bevoegde autoriteiten, met betrekking tot alle vraagstukken die verband houden met het waarborgen van de naleving van deze verordening.
<br>De gemachtigde beëindigt het mandaat indien hij van mening is of redenen heeft om aan te nemen dat de aanbieder in strijd met zijn verplichtingen op grond van deze verordening handelt. Hij stelt daar dan, met opgave van redenen, de relevante markttoezichtautoriteit onmiddellijk van in kennis, alsmede, in voorkomend geval, de relevante aangemelde instantie.
<br><br>
<br>Alvorens een AI-systeem met een hoog risico in de handel wordt gebracht, zorgen de importeurs ervoor dat het systeem in overeenstemming is met deze verordening door na te gaan of:<br>
a) de relevante conformiteitsbeoordelingsprocedure als bedoeld in artikel 43 is uitgevoerd door de aanbieder van het AI-systeem met een hoog risico;<br>
b) de aanbieder de technische documentatie heeft opgesteld in overeenstemming met artikel 11 en bijlage IV;<br>
c) de vereiste CE-markering op het systeem is aangebracht en het systeem vergezeld gaat van de in artikel 47 bedoelde EU-conformiteitsverklaring en gebruiksaanwijzingen;<br>
d) de aanbieder een gemachtigde heeft aangewezen, in overeenstemming met artikel 22, lid 1.
<br>Ingeval een importeur afdoende redenen heeft om aan te nemen dat een AI-systeem met een hoog risico niet in overeenstemming is met deze verordening, vervalst is of vergezeld gaat van vervalste documenten, brengt hij het systeem niet in de handel voordat het in overeenstemming is gebracht. Wanneer het AI-systeem met een hoog risico een risico vormt in de zin van artikel 79, lid 1, stelt de importeur de aanbieder van het systeem, de gemachtigden, en de markttoezichtautoriteiten hiervan in kennis.
<br>Importeurs vermelden hun naam, geregistreerde handelsnaam of geregistreerd merk en hun contactadres voor het AI-systeem met een hoog risico op de verpakking of in de bij het product gevoegde documentatie, indien van toepassing.
<br>Importeurs zorgen gedurende de periode dat zij voor een AI-systeem met een hoog risico verantwoordelijk zijn voor opslag- en vervoersomstandigheden, indien van toepassing, die de overeenstemming van het systeem met de eisen van afdeling 2 niet in het gedrang brengen.
<br>Importeurs bewaren gedurende een periode van tien jaar nadat het AI-systeem met een hoog risico in de handel is gebracht of in gebruik is gesteld, een kopie van het door de aangemelde instantie afgegeven certificaat, en in voorkomend geval tevens een kopie van de gebruiksaanwijzing en van de in artikel 47 bedoelde EU-conformiteitsverklaring.
<br>Importeurs verstrekken ter staving van de conformiteit van een AI-systeem met een hoog risico met de eisen van afdeling 2, de relevante bevoegde autoriteiten op met redenen omkleed verzoek alle nodige informatie en documentatie, met inbegrip van de in lid 5 bedoelde informatie en documentatie, in een gemakkelijk voor die autoriteit te begrijpen taal. Hiertoe zorgen zij er tevens voor dat aan deze autoriteiten de technische documentatie ter beschikking kan worden gesteld.
<br>Importeurs werken met de relevante bevoegde autoriteiten samen met betrekking tot alle maatregelen die door deze autoriteiten worden getroffen in verband met het AI-systeem met een hoog risico dat door de importeurs in de handel is gebracht, met name om de risico’s van dat systeem te verminderen en te beperken.
<br><br>
<br>Voordat zij een AI-systeem met een hoog risico op de markt aanbieden, controleren distributeurs of daarop de vereiste CE-markering is aangebracht, of het systeem vergezeld gaat van de in artikel 47 bedoelde EU-conformiteitsverklaring en gebruiksinstructies en of de aanbieder en importeur van dat systeem, naargelang het geval, hun respectievelijke verplichtingen als vastgelegd in artikel 16, punten b) en c), en artikel 23, lid 3, hebben nageleefd.
<br>Wanneer een distributeur van mening is of redenen heeft om, op grond van de informatie waarover hij beschikt, aan te nemen dat een AI-systeem met een hoog risico niet in overeenstemming is met de eisen van afdeling 2, brengt hij het AI-systeem met een hoog risico niet in de handel voordat het in overeenstemming is gebracht met deze eisen. Daarnaast stelt de distributeur, wanneer het AI-systeem met een hoog risico een risico vormt in de zin van artikel 79, lid 1, de aanbieder of de importeur van het AI-systeem, naargelang als van toepassing, hiervan in kennis.
<br>Distributeurs zorgen gedurende de periode waarin zij voor een AI-systeem met een hoog risico verantwoordelijk zijn voor opslag- en vervoersomstandigheden, indien van toepassing, die de overeenstemming van het systeem met de eisen van afdeling 2 niet in het gedrang brengen.
<br>Een distributeur die van mening is of redenen heeft om, op grond van de informatie waarover hij beschikt, aan te nemen dat een AI-systeem met een hoog risico dat hij op de markt heeft aangeboden, niet in overeenstemming is met de eisen van afdeling 2, neemt de noodzakelijke corrigerende maatregelen om dat systeem in overeenstemming te brengen met deze eisen, uit de handel te nemen of terug te roepen of zorgt ervoor dat de aanbieder, de importeur of een eventuele betrokken operator, waar passend, dergelijke corrigerende maatregelen treft. Indien het AI-systeem met een hoog risico een risico vormt in de zin van artikel 79, lid 1, stelt de distributeur de aanbieder of importeur van het systeem en de autoriteiten die bevoegd zijn voor het betreffende AI-systeem met een hoog risico hiervan onmiddellijk in kennis, waarbij hij in het bijzonder de non-conformiteit en de eventueel getroffen corrigerende maatregelen uitvoerig beschrijft.
<br>Op een met redenen omkleed verzoek van een relevante bevoegde autoriteit verstrekken distributeurs van een AI-systeem met een hoog risico die autoriteit alle informatie en documentatie met betrekking tot de op grond van de leden 1 tot en met 4 door hen genomen maatregelen die nodig zijn om aan te tonen dat het systeem voldoet aan de eisen van afdeling 2.
<br>Distributeurs werken met de relevante bevoegde autoriteiten samen met betrekking tot alle maatregelen die door deze autoriteiten worden getroffen in verband met het AI-systeem met een hoog risico dat door de distributeurs op de markt is aangeboden, met name om de risico’s van dat systeem te verminderen of te beperken.
<br><br>
<br>In de volgende omstandigheden wordt een distributeur, importeur, gebruiksverantwoordelijke of derde voor de toepassing van deze verordening beschouwd als een aanbieder van een AI-systeem met een hoog risico en is hij onderworpen aan de verplichtingen van de aanbieder uit hoofde van artikel 16:<br>
a) hij zet zijn naam of merk op een AI-systeem met een hoog risico dat reeds in de handel is gebracht of in gebruik is gesteld, onverminderd contractuele regelingen waarin wordt bepaald dat de verplichtingen anders worden toegewezen;<br>
b) hij brengt een substantiële wijziging aan in een AI-systeem met een hoog risico dat reeds in de handel is gebracht of reeds in gebruik is gesteld op zodanige wijze dat het systeem een AI-systeem met een hoog risico blijft op grond van artikel 6;<br>
c) hij wijzigt het beoogde doel van een AI-systeem, met inbegrip van een AI-systeem voor algemene doeleinden, dat niet als een systeem met een hoog risico is geclassificeerd en reeds in de handel is gebracht of in gebruik is gesteld, op zodanige wijze dat het betrokken AI-systeem een AI-systeem met een hoog risico overeenkomstig artikel 6 wordt.
<br>Wanneer sprake is van de in lid 1 bedoelde omstandigheden, wordt de aanbieder die het AI-systeem voor het eerst in de handel heeft gebracht of in gebruik heeft gesteld, niet langer beschouwd als aanbieder van dat specifieke AI-systeem voor de toepassing van deze verordening. Die oorspronkelijke aanbieder werkt nauw samen met nieuwe aanbieders, stelt de nodige informatie beschikbaar en verstrekt de redelijkerwijs verwachte technische toegang en andere bijstand die nodig zijn om te voldoen aan de verplichtingen van deze verordening, met name wat betreft de naleving van de conformiteitsbeoordeling van AI-systemen met een hoog risico. Dit lid is niet van toepassing in gevallen waarin de oorspronkelijke aanbieder duidelijk heeft aangegeven dat zijn AI-systeem niet mag worden gewijzigd in een AI-systeem met een hoog risico en derhalve niet onder de verplichting valt om de documentatie te verstrekken.
<br>Bij AI-systemen met een hoog risico die veiligheidscomponenten van producten zijn die vallen onder de in bijlage I, afdeling A, genoemde harmonisatiewetgeving van de Unie, wordt de productfabrikant beschouwd als de aanbieder van het AI-systeem met een hoog risico en is hij onderworpen aan de verplichtingen krachtens artikel 16 in een van de volgende situaties:<br>
a) het AI-systeem met een hoog risico wordt samen met het product onder de naam of het merk van de productfabrikant in de handel gebracht;<br>
b) het AI-systeem met een hoog risico wordt onder de naam of het merk van de productfabrikant in gebruik gesteld nadat het product in de handel is gebracht.
<br>De aanbieder van een AI-systeem met een hoog risico en de derde partij die instrumenten, diensten, onderdelen of processen voor AI-systemen levert die worden gebruikt of geïntegreerd in een AI-systeem met een hoog risico, preciseren in een schriftelijke overeenkomst de nodige informatie, capaciteiten, technische toegang en andere bijstand, op basis van de algemeen erkende stand van de techniek, om de aanbieder van het AI-systeem met een hoog risico in staat te stellen volledig te voldoen aan de verplichtingen van deze verordening. Dit lid is niet van toepassing op derden die andere instrumenten, diensten, processen of onderdelen dan AI-modellen voor algemene doeleinden onder een vrije en opensource licentie toegankelijk maken voor het publiek.<br>
Het AI-bureau kan vrijwillige modelvoorwaarden ontwikkelen en aanbevelen voor contracten tussen aanbieders van AI-systemen met een hoog risico en derden die instrumenten, diensten, componenten of processen leveren die worden gebruikt of geïntegreerd in AI-systemen met een hoog risico. Bij de ontwikkeling van die vrijwillige modelvoorwaarden moet het AI-bureau rekening houden met de contractuele eisen die kunnen gelden in specifieke sectoren of businesscases. De vrijwillige modelvoorwaarden worden gepubliceerd en kosteloos beschikbaar gesteld in een gemakkelijk bruikbaar elektronisch formaat.
<br>De leden 2 en 3 doen geen afbreuk aan de noodzaak om intellectuele-eigendomsrechten, vertrouwelijke bedrijfsinformatie en bedrijfsgeheimen te eerbiedigen en te beschermen overeenkomstig het Unierecht en het nationale recht.
<br><br>
<br>Gebruiksverantwoordelijken van AI-systemen met een hoog risico nemen passende technische en organisatorische maatregelen om te waarborgen dat zij dergelijke systemen gebruiken in overeenstemming met de gebruiksaanwijzingen die bij de systemen zijn gevoegd, op grond van de leden 3 en 6.
<br>Gebruiksverantwoordelijken dragen het menselijk toezicht op aan natuurlijke personen die over de nodige bekwaamheid, opleiding en autoriteit beschikken en de nodige ondersteuning krijgen.
<br>De verplichtingen van de leden 1 en 2 doen geen afbreuk aan andere verplichtingen van gebruiksverantwoordelijken op grond van het Unie- of nationaal recht en aan de vrijheid van gebruiksverantwoordelijken om hun eigen middelen en activiteiten te organiseren voor de uitvoering van de maatregelen inzake menselijk toezicht zoals aangegeven door de aanbieder.
<br>Onverminderd de leden 1 en 2 zorgt de gebruiksverantwoordelijke, voor zover hij controle heeft over de inputdata, ervoor dat de inputdata relevant en voldoende representatief zijn voor het beoogde doel van het AI-systeem met een hoog risico.
<br>Gebruiksverantwoordelijken monitoren de werking van het AI-systeem met een hoog risico op basis van de gebruiksaanwijzingen en stellen in voorkomend geval de aanbieders in kennis overeenkomstig artikel 72. Wanneer gebruiksverantwoordelijken redenen hebben om aan te nemen dat het gebruik overeenkomstig de gebruiksaanwijzingen ertoe kan leiden dat dat AI-systeem een risico vormt in de zin van artikel 79, lid 1, stellen zij de aanbieder of distributeur en de betreffende markttoezichtautoriteit hiervan zonder onnodige vertraging in kennis en onderbreken zij het gebruik van dat systeem. Wanneer gebruiksverantwoordelijke een ernstig incident vaststellen, stellen zij ook onmiddellijk eerst de aanbieder hiervan in kennis, en vervolgens de importeur of distributeur en de betreffende markttoezichtautoriteiten van dat incident. Wanneer de gebruiksverantwoordelijke de aanbieder niet kan bereiken, is artikel 73 mutatis mutandis van toepassing. Deze verplichting geldt niet voor gevoelige operationele gegevens van gebruiksverantwoordelijke van AI-systemen die de hoedanigheid van rechtshandhavingsinstanties hebben.<br>
Voor gebruiksverantwoordelijke die in de hoedanigheid van financiële instellingen onderworpen zijn aan eisen met betrekking tot hun interne governance, regelingen of processen uit hoofde van het Unierecht inzake financiële diensten, wordt de monitoringsverplichting overeenkomstig de eerste alinea geacht te zijn vervuld door te voldoen aan de regels inzake interne governance, regelingen of processen en -mechanismen uit hoofde van het desbetreffende recht inzake financiële diensten.
<br>Gebruiksverantwoordelijken van AI-systemen met een hoog risico bewaren de logs die automatisch worden gegenereerd door dat AI-systeem met een hoog risico voor zover dergelijke logs onder hun controle vallen gedurende een periode die passend is voor het beoogde doel van het AI-systeem met een hoog risico, of ten minste zes maanden, tenzij anders is bepaald in het toepasselijke Unie- of nationaal recht, meer in het bijzonder het Unierecht over de bescherming van persoonsgegevens.<br>
Gebruiksverantwoordelijken die in de hoedanigheid van financiële instellingen onderworpen zijn aan eisen met betrekking tot hun interne governance, regelingen of processen uit hoofde van het Unierecht inzake financiële diensten, bewaren de logs als onderdeel van de documentatie die bewaard wordt krachtens het desbetreffende Unierecht inzake financiële diensten.
<br>Voordat een AI-systeem met een hoog risico op de werkplek in gebruik wordt gesteld of wordt gebruikt, delen gebruiksverantwoordelijken die werkgever zijn werknemersvertegenwoordigers en de betrokken werknemers mee dat zij zullen worden onderworpen aan het gebruik van het AI-systeem met een hoog risico. Deze informatie wordt, indien van toepassing, verstrekt in overeenstemming met de in het Unie- en nationaal recht vastgelegde regels en procedures en de praktijk inzake informatie van werknemers en hun vertegenwoordigers.
<br>Gebruiksverantwoordelijken van AI-systemen met een hoog risico die de hoedanigheid van overheidsinstanties of instellingen, organen of instanties van de Unie hebben, leven de in artikel 49 bedoelde registratieverplichtingen na. Wanneer deze gebruiksverantwoordelijke vaststellen dat het AI-systeem met een hoog risico dat zij voornemens zijn te gebruiken niet in de in artikel 71 bedoelde EU-databank is geregistreerd, gebruiken zij dat systeem niet en stellen zij de aanbieder of de distributeur daarvan in kennis.
<br>Indien van toepassing, gebruiken gebruiksverantwoordelijken van AI-systemen met een hoog risico de informatie die op grond van artikel 13 van deze verordening wordt verstrekt om hun verplichting na te komen om een gegevensbeschermingseffectbeoordeling uit te voeren op grond van artikel 35 van Verordening (EU) 2016/679 of artikel 27 van Richtlijn (EU) 2016/680.
<br>Onverminderd Richtlijn (EU) 2016/680 verzoekt de gebruiksverantwoordelijke van een AI-systeem met een hoog risico voor biometrische identificatie op afstand achteraf in het kader van een onderzoek waarbij gericht wordt gezocht naar een persoon die wordt verdacht van of veroordeeld is voor het plegen van een strafbaar feit, vooraf of zonder onnodige vertraging en uiterlijk 48 uur na het feit, om toestemming van een gerechtelijke instantie of administratieve instantie, van wie de beslissing bindend is en onderworpen is aan rechterlijke toetsing, voor het gebruik van dat systeem, behalve wanneer het wordt gebruikt voor de initiële identificatie van een potentiële verdachte op basis van objectieve en verifieerbare feiten die rechtstreeks verband houden met het strafbare feit. Elk gebruik wordt beperkt tot hetgeen strikt noodzakelijk is voor het onderzoek naar een specifiek strafbaar feit.<br>
Indien de op grond van de eerste alinea verzochte toestemming wordt geweigerd, wordt het gebruik van het systeem voor biometrische identificatie op afstand achteraf dat verband houdt met de verzochte toestemming met onmiddellijke ingang stopgezet en worden de persoonsgegevens die verband houden met het gebruik van het AI-systeem met een hoog risico waarvoor de toestemming is gevraagd, gewist.<br>
Een dergelijk AI-systeem met een hoog risico voor biometrische identificatie op afstand achteraf mag in geen geval op niet-gerichte wijze worden gebruikt voor rechtshandhavingsdoeleinden, zonder enig verband met een strafbaar feit, een strafrechtelijke procedure, een werkelijke en actuele of werkelijke en te verwachten dreiging van een strafbaar feit, of zoektocht naar een specifieke vermiste persoon. Er moet voor worden gezorgd dat rechtshandhavingsinstanties geen enkel besluit met nadelige rechtsgevolgen voor een persoon mogen nemen op basis van uitsluitend de output van dergelijke systemen voor biometrische identificatie op afstand achteraf.<br>
Deze alinea doet geen afbreuk aan artikel 9 van Verordening (EU) 2016/679 en artikel 10 van Richtlijn (EU) 2016/680 voor de verwerking van biometrische gegevens.<br>
Ongeacht het doel of de gebruiksverantwoordelijke wordt elk gebruik van dergelijke AI-systemen met een hoog risico gedocumenteerd in het desbetreffende politiedossier en op verzoek ter beschikking gesteld van de relevante markttoezichtautoriteit en de nationale gegevensbeschermingsautoriteit, met uitzondering van gevoelige operationele gegevens in verband met rechtshandhaving. Deze alinea doet geen afbreuk aan de bij Richtlijn (EU) 2016/680 aan de toezichthoudende autoriteiten verleende bevoegdheden.<br>
Gebruiksverantwoordelijken dienen bij de relevante markttoezichtautoriteiten en de nationale gegevensbeschermingsautoriteiten jaarverslagen in over hun gebruik van systemen voor biometrische identificatie op afstand achteraf, met uitzondering van gevoelige operationele gegevens in verband met rechtshandhaving. De verslagen kunnen worden samengevoegd, zodat ze informatie bevatten over meerdere soorten van inzetten.<br>
De lidstaten kunnen, in overeenstemming met het Unierecht, beperkendere wetgeving invoeren inzake het gebruik van systemen voor biometrische identificatie op afstand achteraf.
<br>Onverminderd artikel 50 van deze verordening informeren gebruiksverantwoordelijken van in bijlage III bedoelde AI-systemen met een hoog risico die beslissingen met betrekking tot natuurlijke personen nemen of helpen nemen, de natuurlijke personen dat het AI-systeem met een hoog risico op hen wordt toegepast. Op AI-systemen met een hoog risico die voor rechtshandhavingsdoeleinden worden gebruikt, is artikel 13 van Richtlijn (EU) 2016/680 van toepassing.
<br>Gebruiksverantwoordelijken werken samen met de relevante bevoegde autoriteiten bij alle door deze autoriteiten genomen maatregelen met betrekking tot een AI-systeem met een hoog risico met het oog op de uitvoering van deze verordening.
<br><br>
<br>Voordat een AI-systeem met een hoog risico als bedoeld in artikel 6, lid 2, in gebruik wordt gesteld, met uitzondering van AI-systemen met een hoog risico die bedoeld zijn om te worden gebruikt op het in punt 2 van bijlage III vermelde gebied, voeren gebruiksverantwoordelijken die publiekrechtelijke organen zijn of particuliere entiteiten zijn die openbare diensten verlenen, en gebruiksverantwoordelijken van AI-systemen met een hoog risico als bedoeld in bijlage III, punt 5, b) en c), een beoordeling uit van de gevolgen voor de grondrechten die het gebruik van een dergelijk systeem kan opleveren. Daartoe voeren gebruiksverantwoordelijken een beoordeling uit die bestaat uit:<br>
a) een beschrijving van de processen van de gebruiksverantwoordelijke waarbij het AI-systeem met een hoog risico zal worden gebruikt in overeenstemming met het beoogde doel ervan;<br>
b) een beschrijving van de periode waarbinnen en de frequentie waarmee elk AI-systeem met een hoog risico zal worden gebruikt;<br>
c) categorieën van natuurlijke personen en groepen die naar verwachting gevolgen zullen ondervinden van het gebruik van het systeem in een specifieke context;<br>
d) de specifieke risico’s op schade die waarschijnlijk gevolgen zullen hebben voor de op grond van punt c) van dit lid geïdentificeerde categorieën natuurlijke personen of groepen personen, rekening houdend met de door de aanbieder op grond van artikel 13 verstrekte informatie;<br>
e) een beschrijving van de uitvoering van maatregelen voor menselijk toezicht, overeenkomstig de gebruiksaanwijzing;<br>
f) de maatregelen die moeten worden genomen wanneer die risico’s zich voordoen, met inbegrip van de regelingen voor interne governance en klachtenregelingen.
<br>De verplichting als neergelegd in lid 1 is van toepassing op het eerste gebruik van een AI-systeem met een hoog risico. De gebruiksverantwoordelijke kan in soortgelijke gevallen gebruik maken van eerder uitgevoerde effectbeoordelingen op het gebied van de grondrechten of bestaande effectbeoordelingen die door de aanbieder zijn uitgevoerd. Indien de gebruiksverantwoordelijke tijdens het gebruik van het AI-systeem met een hoog risico ziet dat een van de in lid 1 vermelde elementen is gewijzigd of niet langer actueel is, neemt de gebruiksverantwoordelijke de nodige maatregelen om de informatie te actualiseren.
<br>Zodra de in lid 1 van dit artikel bedoelde beoordeling is uitgevoerd, stelt de gebruiksverantwoordelijke de markttoezichtautoriteit in kennis van de resultaten ervan, en dient hij als onderdeel van de kennisgeving het in lid 5 van dit artikel bedoelde ingevulde sjabloon in. In het in artikel 46, lid 1, bedoelde geval kunnen gebruiksverantwoordelijken van de verplichting tot kennisgeving worden vrijgesteld.
<br>Indien een van de in dit artikel vastgelegde verplichtingen reeds is nagekomen door de gegevensbeschermingseffectbeoordeling die is uitgevoerd op grond van artikel 35 van Verordening (EU) 2016/679 of artikel 27 van Richtlijn (EU) 2016/680, vormt de in lid 1 van dit artikel bedoelde effectbeoordeling op het gebied van de grondrechten een aanvulling op die gegevensbeschermingseffectbeoordeling.
<br>Het AI-bureau ontwikkelt een sjabloon voor een vragenlijst, onder meer via een geautomatiseerd instrument, om gebruiksverantwoordelijken te helpen hun verplichtingen uit hoofde van dit artikel op vereenvoudigde wijze na te komen.<br>
AFDELING 4<br>
Aanmeldende autoriteiten en aangemelde instanties
<br><br>
<br>Elke lidstaat wijst ten minste één aanmeldende autoriteit aan of richt een aanmeldende autoriteit op die verantwoordelijk is voor het opzetten en uitvoeren van de nodige procedures voor de beoordeling, aanwijzing en aanmelding van conformiteitsbeoordelingsinstanties en voor het toezicht erop. Deze procedures worden ontwikkeld in samenwerking tussen de aanmeldende autoriteiten van alle lidstaten.
<br>De lidstaten kunnen besluiten de beoordeling en het toezicht als bedoeld in lid 1 overeenkomstig Verordening (EG) nr. 765/2008 te laten uitvoeren door een nationale accreditatie-instantie in de zin van die verordening.
<br>Aanmeldende autoriteiten worden zodanig opgericht en georganiseerd en functioneren zodanig dat zich geen belangenconflicten met conformiteitsbeoordelingsinstanties voordoen en dat de objectiviteit en onpartijdigheid van hun activiteiten gewaarborgd zijn.
<br>Aanmeldende autoriteiten worden zodanig georganiseerd dat besluiten in verband met de aanmelding van conformiteitsbeoordelingsinstanties worden genomen door bekwame personen die niet de beoordeling van die instanties hebben verricht.
<br>Aanmeldende autoriteiten bieden of verrichten geen activiteiten die worden uitgevoerd door conformiteitsbeoordelingsinstanties en verlenen geen adviezen op commerciële of concurrentiële basis.
<br>Aanmeldende autoriteiten waarborgen dat de door hen verkregen informatie overeenkomstig artikel 78 vertrouwelijk wordt behandeld.
<br>Aanmeldende autoriteiten beschikken over een toereikend aantal bekwame personeelsleden om hun taken naar behoren uit te voeren. Bekwame personeelsleden beschikken, indien van toepassing, over de nodige deskundigheid voor hun functies op gebieden als informatietechnologie, AI en recht, met inbegrip van het toezicht op de grondrechten.
<br><br>
<br>Conformiteitsbeoordelingsinstanties dienen een verzoek om aanmelding in bij de aanmeldende autoriteit van de lidstaat waar zij zijn gevestigd.
<br>Het verzoek om aanmelding gaat vergezeld van een beschrijving van de conformiteitsbeoordelingsactiviteiten, de conformiteitsbeoordelingsmodule(s) en de soorten AI-systemen waarvoor de conformiteitsbeoordelingsinstantie verklaart bekwaam te zijn en, indien dit bestaat, van een accreditatiecertificaat dat is afgegeven door een nationale accreditatie-instantie, waarin wordt verklaard dat de conformiteitsbeoordelingsinstantie voldoet aan de eisen van artikel 31.<br>
Geldige documenten met betrekking tot bestaande aanwijzingen van de verzoekende aangemelde instantie uit hoofde van andere harmonisatiewetgeving van de Unie worden bijgevoegd.
<br>Wanneer de betrokken conformiteitsbeoordelingsinstantie geen accreditatiecertificaat kan overleggen, verschaft zij de aanmeldende autoriteit alle bewijsstukken die nodig zijn om haar overeenstemming met de eisen van artikel 31 te verifiëren en te erkennen en om daar geregeld toezicht op te houden.
<br>Voor aangemelde instanties die uit hoofde van andere harmonisatiewetgeving van de Unie zijn aangewezen, kunnen waar passend alle documenten en certificaten met betrekking tot die aanwijzingen worden gebruikt om hun aanwijzingsprocedure krachtens deze verordening te ondersteunen. Om de voor aangemelde instanties verantwoordelijke autoriteit in staat te stellen de continue naleving van alle eisen van artikel 31 te monitoren en te verifiëren, werkt de aangemelde instantie de in de leden 2 en 3 bij dit artikel bedoelde documentatie telkens bij wanneer relevante veranderingen plaatsvinden.
<br><br>
<br>Aanmeldende autoriteiten mogen uitsluitend conformiteitsbeoordelingsinstanties aanmelden die aan de eisen van artikel 31 voldoen.
<br>Aanmeldende autoriteiten melden elke in lid 1 bedoeld conformiteitsbeoordelingsinstantie aan bij de Commissie en de andere lidstaten door middel van het door de Commissie ontwikkelde en beheerde elektronische aanmeldingssysteem.
<br>Bij de in lid 2 van dit artikel bedoelde aanmelding worden de conformiteitsbeoordelingsactiviteiten, de conformiteitsbeoordelingsmodule(s), de soorten AI-systemen in kwestie en de desbetreffende bekwaamheidsattestatie uitvoerig beschreven. Indien een aanmelding niet gebaseerd is op een accreditatiecertificaat als bedoeld in artikel 29, lid 2, verschaft de aanmeldende autoriteit de Commissie en de andere lidstaten de bewijsstukken waaruit de bekwaamheid van de conformiteitsbeoordelingsinstantie blijkt, evenals de regeling die waarborgt dat de instantie regelmatig wordt gecontroleerd en zal blijven voldoen aan de eisen van artikel 31.
<br>De betrokken conformiteitsbeoordelingsinstantie mag de activiteiten van een aangemelde instantie alleen verrichten als de Commissie en de andere lidstaten binnen twee weken na aanmelding door een aanmeldende autoriteit indien een accreditatiecertificaat bedoeld in artikel 29, lid 2, wordt gebruikt en binnen twee maanden na aanmelding door de aanmeldende autoriteit indien de in artikel 29, lid 3, bedoelde bewijsstukken worden gebruikt, geen bezwaren hebben ingediend.
<br>Indien er bezwaar wordt ingediend, treedt de Commissie onverwijld in overleg met de betrokken lidstaten en de conformiteitsbeoordelingsinstantie. Met het oog daarop besluit de Commissie of de toelating gerechtvaardigd is. De Commissie richt haar besluit aan de betrokken lidstaat en aan de relevante conformiteitsbeoordelingsinstantie.
<br><br>
<br>Een aangemelde instantie wordt naar het recht van een lidstaat opgericht en bezit rechtspersoonlijkheid.
<br>Aangemelde instanties voldoen aan de eisen inzake organisatie, kwaliteitsbeheer, personeel en processen die nodig zijn voor het vervullen van hun taken, alsook aan de passende cyberbeveiligingseisen.
<br>De organisatiestructuur, de toewijzing van verantwoordelijkheden, de rapportagelijnen en het functioneren van aangemelde instanties moeten ervoor zorgen dat er vertrouwen is in hun uitvoering en de resultaten van de conformiteitsbeoordelingsactiviteiten die de aangemelde instanties verrichten.
<br>Aangemelde instanties zijn onafhankelijk van de aanbieder van een AI-systeem met een hoog risico met betrekking waartoe de aanbieder conformiteitsbeoordelingsactiviteiten verricht. Aangemelde instanties zijn ook onafhankelijk van andere operatoren die een economisch belang hebben in beoordeelde AI-systemen met een hoog risico, alsook van concurrenten van de aanbieder. Dit belet echter niet dat beoordeelde AI-systemen met een hoog risico die nodig zijn voor activiteiten van de conformiteitsbeoordelingsinstantie worden gebruikt of dat dergelijke AI-systemen met een hoog risico voor persoonlijke doeleinden worden gebruikt.
<br>Een conformiteitsbeoordelingsinstantie, haar hoogste leidinggevenden en het personeel dat de conformiteitsbeoordelingstaken verricht, zijn niet rechtstreeks of als vertegenwoordiger van de betrokken partijen betrokken bij het ontwerpen, ontwikkelen, verhandelen of gebruiken van de AI-systemen met een hoog risico. Zij oefent geen activiteiten uit die de onafhankelijkheid van haar oordeel of haar integriteit met betrekking tot de conformiteitsbeoordelingsactiviteiten waarvoor zij is aangemeld in het gedrang kunnen brengen. Dit geldt met name voor adviesdiensten.
<br>Aangemelde instanties worden zodanig georganiseerd en functioneren zodanig dat de onafhankelijkheid, objectiviteit en onpartijdigheid van hun activiteiten gewaarborgd zijn. Aangemelde instanties documenteren en implementeren een structuur en procedures voor het waarborgen van de onpartijdigheid en voor het bevorderen en toepassen van de onpartijdigheidsbeginselen in hun gehele organisatie, onder het personeel en in de beoordelingsactiviteiten.
<br>Aangemelde instanties beschikken over gedocumenteerde procedures die waarborgen dat hun personeel, comités, dochterondernemingen, onderaannemers, geassocieerde instanties of personeel van externe instanties overeenkomstig artikel 78 de informatie die zij tijdens conformiteitsbeoordelingsactiviteiten in hun bezit krijgen vertrouwelijk houden, behalve wanneer de openbaarmaking ervan wettelijk vereist is. Het personeel van aangemelde instanties is gebonden aan het beroepsgeheim ten aanzien van alle informatie waarvan het kennisneemt bij de uitoefening van de taken uit hoofde van deze verordening, behalve ten opzichte van de aanmeldende autoriteiten van de lidstaat waar de activiteiten plaatsvinden.
<br>Aangemelde instanties beschikken over de nodige procedures voor de uitoefening van hun activiteiten, waarin voldoende rekening wordt gehouden met de omvang van een aanbieder, de sector waarin deze actief is, de structuur en de relatieve complexiteit van het betreffende AI-systeem.
<br>Aangemelde instanties sluiten voor hun conformiteitsbeoordelingsactiviteiten een passende aansprakelĳkheidsverzekering af, tenzij de wettelijke aansprakelijkheid krachtens het nationale recht door de lidstaat van vestiging wordt gedekt of die lidstaat zelf rechtstreeks verantwoordelijk is voor de conformiteitsbeoordeling.
<br>Aangemelde instanties zijn in staat al hun taken uit hoofde van deze verordening te verrichten met de grootste mate van beroepsintegriteit en met de vereiste bekwaamheid op het specifieke gebied, ongeacht of deze taken door de aangemelde instanties zelf dan wel namens hen en onder hun verantwoordelijkheid worden verricht.
<br>Aangemelde instanties beschikken over voldoende interne deskundigheid om de namens hen door externe partijen verrichte taken doeltreffend te kunnen evalueren. De aangemelde instantie moet permanent beschikken over voldoende administratief, technisch, juridisch en wetenschappelijk personeel dat ervaring heeft met en kennis over de relevante soorten AI-systemen, gegevens en gegevensverwerking en de voorschriften van afdeling 2.
<br>Aangemelde instanties nemen deel aan coördinatieactiviteiten als bedoeld in artikel 38. Zij nemen ook rechtstreeks deel aan of worden vertegenwoordigd in Europese normalisatie-instellingen of zorgen ervoor op de hoogte te zijn van actuele relevante normen.
<br><br>Wanneer een conformiteitsbeoordelingsinstantie aantoont dat zij voldoet aan de criteria in de ter zake doende geharmoniseerde normen of delen ervan, waarvan de referentienummers in het Publicatieblad van de Europese Unie zijn bekendgemaakt, wordt zij geacht aan de eisen van artikel 31 te voldoen, op voorwaarde dat de van toepassing zijnde geharmoniseerde normen deze eisen dekken.<br><br>
<br>Wanneer de aangemelde instantie specifieke taken in verband met de conformiteits-beoordeling door een onderaannemer of door een dochteronderneming laat uitvoeren, waarborgt zij dat de onderaannemer of dochteronderneming aan de eisen van artikel 31 voldoet, en brengt zij de aanmeldende autoriteit hiervan op de hoogte.
<br>Aangemelde instanties nemen de volledige verantwoordelijkheid op zich voor de door onderaannemers of dochterondernemingen verrichte taken.
<br>Activiteiten mogen uitsluitend met instemming van de aanbieder door een onderaannemer of dochteronderneming worden uitgevoerd. Aangemelde instanties maken een lijst van hun dochterondernemingen openbaar.
<br>De relevante documenten betreffende de beoordeling van de kwalificaties van de onderaannemer of dochteronderneming en de door hen uit hoofde van deze verordening uitgevoerde werkzaamheden worden gedurende een periode van vijf jaar vanaf de einddatum van de onderaanneming ter beschikking van de aanmeldende autoriteit gehouden.
<br><br>
<br>Aangemelde instanties controleren de conformiteit van AI-systemen met een hoog risico overeenkomstig de conformiteitsbeoordelingsprocedures van artikel 43.
<br>Aangemelde instanties vermijden onnodige lasten voor aanbieders bij de uitvoering van hun activiteiten en houden terdege rekening met de omvang van de aanbieder, de sector waarin hij actief is, zijn structuur en de mate van complexiteit van het betrokken AI-systeem met een hoog risico, met name om de administratieve lasten en nalevingskosten voor micro- en kleine ondernemingen in de zin van Aanbeveling 2003/361/EG tot een minimum te beperken. De aangemelde instantie eerbiedigt echter de striktheid en het beschermingsniveau die nodig zijn opdat het AI-systeem met een hoog risico voldoet aan de eisen van deze verordening.
<br>Aangemelde instanties stellen alle relevante documentatie, waaronder de documentatie van de aanbieder, ter beschikking van de in artikel 28 bedoelde aanmeldende autoriteit, en verstrekken die aan haar op verzoek, teneinde haar in staat te stellen haar beoordelings-, aanwijzings-, kennisgevings- en monitoringsactiviteiten te verrichten, en de in deze afdeling beschreven beoordeling te vergemakkelijken.
<br><br>
<br>De Commissie kent elke aangemelde instantie één enkel identificatienummer toe, zelfs wanneer een instantie op grond van meer dan één handeling van de Unie is aangemeld.
<br>De Commissie maakt de lijst van krachtens deze verordening aangemelde instanties openbaar, onder vermelding van hun identificatienummers en de activiteiten waarvoor zij zijn aangemeld. De Commissie zorgt ervoor dat de lijst actueel blijft.
<br><br>
<br>De aanmeldende autoriteit stelt de Commissie en de andere lidstaten via het in artikel 30, lid 2, bedoelde elektronische aanmeldingssysteem in kennis van alle relevante wijzigingen in de aanmelding van een aangemelde instantie.
<br>De in artikel 29 en artikel 30 vastgelegde procedures zijn van toepassing op uitbreidingen van de reikwijdte van de aanmelding.<br>
Voor andere wijzigingen met betrekking tot de aanmelding dan uitbreidingen van de reikwijdte, zijn de procedures van de leden 3 tot en met 9 van toepassing.
<br>Indien een aangemelde instantie besluit haar conformiteitsbeoordelingsactiviteiten stop te zetten, brengt zij de aanmeldende autoriteit en de betrokken aanbieders zo snel mogelijk, en in het geval van een geplande stopzetting minstens één jaar voor de stopzetting van haar activiteiten, daarvan op de hoogte. De certificaten van de aangemelde instantie kunnen gedurende een periode van negen maanden na de stopzetting van de activiteiten van de aangemelde instantie geldig blijven, op voorwaarde dat een andere aangemelde instantie schriftelijk heeft bevestigd dat zij de verantwoordelijkheid voor de AI-systemen met een hoog risico waarop die certificaten betrekking hebben, op zich zal nemen. Die laatste aangemelde instantie verricht vóór het einde van die periode van negen maanden een volledige beoordeling van de betrokken AI-systemen met een hoog risico, alvorens er nieuwe certificaten voor af te leveren. Ingeval de aangemelde instantie haar activiteiten heeft gestaakt, trekt de aanmeldende autoriteit de aanwijzing in.
<br>Wanneer een aanmeldende autoriteit voldoende reden heeft om van mening te zijn dat een aangemelde instantie niet meer aan de eisen van artikel 31 voldoet of haar verplichtingen niet nakomt, moet de aanmeldende autoriteit de kwestie onverwijld zo zorgvuldig mogelijk onderzoeken. In die context stelt zij de betrokken aangemelde instantie in kennis van de geopperde bezwaren en biedt zij haar de mogelijkheid haar standpunten kenbaar te maken. Als de aanmeldende autoriteit tot de conclusie komt dat de aangemelde instantie niet meer aan de eisen van artikel 31 voldoet of haar verplichtingen niet nakomt, wordt de aanwijzing door haar beperkt, geschorst of ingetrokken, als passend, afhankelijk van de ernst van het niet naleven van die eisen of verplichtingen. Zij brengt de Commissie en de andere lidstaten daar onmiddellijk van op de hoogte.
<br>Indien de aanwijzing van een aangemelde instantie wordt geschorst, beperkt of geheel of gedeeltelijk wordt ingetrokken, stelt die aangemelde instantie de betrokken aanbieders binnen tien dagen hiervan in kennis.
<br>Indien een aanwijzing wordt beperkt, geschorst of ingetrokken, onderneemt de aanmeldende autoriteit de nodige stappen om ervoor te zorgen dat de dossiers van de betrokken aangemelde instantie worden bewaard en op verzoek ter beschikking worden gesteld van aanmeldende autoriteiten in andere lidstaten en van markttoezichtautoriteiten.
<br>In geval van beperking, schorsing of intrekking van een aanwijzing:<br>
a) beoordeelt de aanmeldende autoriteit het gevolg voor de door de aangemelde instantie afgegeven certificaten;<br>
b) dient de aanmeldende autoriteit binnen drie maanden na mededeling van de wijzigingen in de aanwijzing een verslag over haar bevindingen in bij de Commissie en de overige lidstaten;<br>
c) schrijft de aanmeldende autoriteit voor dat de aangemelde instantie binnen een redelijke, door de autoriteit bepaalde termijn, onterecht afgegeven certificaten schorst of intrekt, zulks om de voortdurende conformiteit van de in de handel gebrachte AI-systemen met een hoog risico te waarborgen;<br>
d) stelt de aanmeldende autoriteit de Commissie en de lidstaten in kennis van certificaten die moeten worden geschorst of ingetrokken;<br>
e) verstrekt de aanmeldende autoriteit de nationale bevoegde autoriteiten van de lidstaat waar de aanbieder zijn geregistreerde vestigingsplaats heeft, alle relevante informatie over de certificaten waarvan zij de schorsing of intrekking heeft gelast; die autoriteit neemt de gepaste maatregelen die nodig zijn om een mogelijk risico voor de gezondheid, veiligheid of grondrechten af te wenden.
<br>Met uitzondering van onterecht afgegeven certificaten en indien een aanwijzing is geschorst of beperkt, blijven de certificaten geldig in een van de volgende omstandigheden:<br>
a) de aanmeldende autoriteit heeft binnen één maand na de schorsing of beperking bevestigd dat er met betrekking tot de certificaten waarop de schorsing of beperking van toepassing is, geen risico’s voor de gezondheid, veiligheid of grondrechten bestaan, en de aanmeldende autoriteit heeft voorzien in een termijn voor maatregelen om de schorsing of beperking te ondervangen, of<br>
b) de aanmeldende autoriteit heeft bevestigd dat er geen certificaten in verband met de schorsing zullen worden afgegeven, gewijzigd, of opnieuw afgegeven gedurende de schorsing of beperking en geeft aan of de aangemelde instantie het vermogen heeft om de bestaande, voor de periode van schorsing of beperking afgegeven certificaten te blijven monitoren en daarvoor verantwoordelijk te blijven; indien de aanmeldende autoriteit vaststelt dat de aangemelde instantie niet in staat is bestaande afgegeven certificaten te ondersteunen, bevestigt de aanbieder van het systeem waarop het certificaat betrekking heeft binnen drie maanden na de schorsing of beperking aan de nationale bevoegde autoriteiten van de lidstaat waar hij zijn geregistreerde vestigingsplaats heeft via schriftelijke weg dat in plaats van de aangemelde instantie een andere gekwalificeerde aangemelde instantie tijdelijk de certificaten tijdens de periode van schorsing of beperking zal monitoren en er de verantwoordelijkheid voor zal dragen.
<br>Met uitzondering van onterecht afgegeven certificaten en indien een aanwijzing is ingetrokken, blijven de certificaten in de volgende omstandigheden negen maanden geldig:<br>
a) de nationale bevoegde autoriteit van de lidstaat waar de aanbieder van het onder het certificaat vallende AI-systeem met een hoog risico zijn geregistreerde vestigingsplaats heeft, bevestigd heeft dat de betreffende AI-systemen met een hoog risico geen risico voor de gezondheid, veiligheid of grondrechten inhouden, en<br>
b) een andere aangemelde instantie schriftelijk heeft bevestigd dat zij de onmiddellijke verantwoordelijkheid voor deze AI-systemen op zich neemt en haar beoordeling binnen twaalf maanden na intrekking van de aanwijzing afrondt.<br>
Onder de in de eerste alinea bedoelde omstandigheden kan de nationale bevoegde autoriteit van de lidstaat waarin de aanbieder van het systeem waarop het certificaat betrekking heeft, zijn vestigingsplaats heeft, de voorlopige geldigheidsduur van de certificaten verlengen met perioden van drie maanden, die samen niet meer dan twaalf maanden mogen bedragen.<br>
De nationale bevoegde autoriteit of de aangemelde instantie die de functies van de door de wijziging van de aanwijzing getroffen aangemelde instantie vervult, stelt de Commissie, de andere lidstaten en de andere aangemelde instanties hiervan onmiddellijk in kennis.
<br><br>
<br>De Commissie onderzoekt indien nodig alle gevallen waarin er redenen zijn om te twijfelen aan de bekwaamheid van een aangemelde instantie of te twijfelen of een aangemelde instantie nog aan de eisen van artikel 31 voldoet en haar toepasselijke verantwoordelijkheden nakomt.
<br>De aanmeldende autoriteit verstrekt de Commissie op verzoek alle relevante informatie over de aanmelding of het op peil houden van de bekwaamheid van de betrokken aangemelde instantie.
<br>De Commissie ziet erop toe dat alle gevoelige informatie die zij in de loop van haar onderzoeken op grond van dit artikel ontvangt, overeenkomstig artikel 78 vertrouwelijk wordt behandeld.
<br>Wanneer de Commissie vaststelt dat een aangemelde instantie niet of niet meer aan de aanmeldingseisen voldoet, brengt zij de aanmeldende lidstaat daarvan op de hoogte en verzoekt zij deze lidstaat de nodige corrigerende maatregelen te nemen, en zo nodig de aanmelding te schorsen of in te trekken. Indien de lidstaat niet de nodige corrigerende actie onderneemt, kan de Commissie door middel van een uitvoeringshandeling de aanwijzing schorsen, beperken of intrekken. De uitvoeringshandeling wordt vastgesteld volgens de in artikel 98, lid 2, bedoelde onderzoeksprocedure.
<br><br>
<br>Ten aanzien van AI-systemen met een hoog risico zorgt de Commissie voor het instellen en naar behoren uitvoeren van passende coördinatie en samenwerking tussen aangemelde instanties die zich bezighouden met de conformiteitsbeoordelingsprocedures krachtens deze verordening in de vorm van een sectorale groep van aangemelde instanties.
<br>Elke aanmeldende autoriteit zorgt ervoor dat de door haar aangemelde instanties rechtstreeks of via aangestelde vertegenwoordigers aan de werkzaamheden van een in lid 1 vermelde groep deelnemen.
<br>De Commissie voorziet in de uitwisseling van kennis en beste praktijken tussen aanmeldende autoriteiten.
<br><br>Conformiteitsbeoordelingsinstanties die zijn opgericht naar het recht van een derde land waarmee de Unie een overeenkomst heeft gesloten, kunnen worden gemachtigd de activiteiten van aangemelde instanties krachtens deze verordening te verrichten, mits zij aan de in artikel 31 vastgelegde voorschriften voldoen of een gelijkwaardig nalevingsniveau waarborgen.<br>
AFDELING 5<br>
Normen, conformiteitsbeoordeling, certificaten, registratie<br><br>
<br>AI-systemen met een hoog risico of AI-modellen voor algemene doeleinden die in overeenstemming zijn met geharmoniseerde normen of delen daarvan, waarvan de referenties in het Publicatieblad van de Europese Unie zijn bekendgemaakt, overeenkomstig Verordening (EU) nr. 1025/2012, worden geacht in overeenstemming te zijn met de in afdeling 2 van dit hoofdstuk beschreven eisen, of, naargelang het geval, de in hoofdstuk V, afdelingen 2 en 3, van deze verordening beschreven verplichtingen, voor zover die eisen of verplichtingen door die normen worden gedekt.
<br>Overeenkomstig artikel 10 van Verordening (EU) nr. 1025/2012 dient de Commissie zonder onnodige vertraging normalisatieverzoeken in die betrekking hebben op alle eisen van afdeling 2 van dit hoofdstuk en, in voorkomend geval, normalisatieverzoeken die betrekking hebben op verplichtingen van hoofdstuk V, afdelingen 2 en 3, van deze verordening. In het normalisatieverzoek wordt ook gevraagd om producten met betrekking tot rapporterings- en documentatieprocessen om de prestaties van hulpbronnen van AI-systemen te verbeteren, zoals het verminderen van het energieverbruik en het verbruik van andere hulpbronnen van AI-systemen met een hoog risico tijdens de levenscyclus ervan, en met betrekking tot de energie-efficiënte ontwikkeling van AI-modellen voor algemene doeleinden. Bij het opstellen van een normalisatieverzoek raadpleegt de Commissie de AI-board en de relevante belanghebbenden, met inbegrip van het adviesforum.<br>
Bij het richten van een normalisatieverzoek aan Europese normalisatie-instellingen specificeert de Commissie dat normen duidelijk en consistent moeten zijn, met inbegrip van de normen die in de verschillende sectoren ontwikkeld zijn voor producten die onder de in bijlage I vermelde bestaande harmonisatiewetgeving van de Unie vallen, en tot doel hebben ervoor te zorgen dat AI-systemen met een hoog risico of AI-modellen voor algemene doeleinden die in de Unie in de handel worden gebracht of in gebruik worden gesteld, voldoen aan de relevante eisen of verplichtingen van deze verordening.<br>
De Commissie verzoekt de Europese normalisatieorganisaties aan te tonen dat zij alles in het werk stellen om de in de eerste en tweede alinea van dit lid bedoelde doelstellingen te verwezenlijken overeenkomstig artikel 24 van Verordening (EU) nr. 1025/2012.
<br>De deelnemers aan het normalisatieproces streven naar het bevorderen van investeringen en innovatie in AI, onder andere door voor meer rechtszekerheid te zorgen, en het concurrentievermogen en de groei van de markt van de Unie, naar het bijdragen aan de versterking van de wereldwijde samenwerking op het gebied van normalisatie, rekening houdend met bestaande internationale normen op het gebied van AI die in overeenstemming zijn met de waarden, grondrechten en belangen van de Unie, en naar het verbeteren van de multistakeholdergovernance door te zorgen voor een evenwichtige vertegenwoordiging van de belangen en de effectieve deelname van alle relevante belanghebbenden overeenkomstig de artikelen 5, 6 en 7 van Verordening (EU) nr. 1025/2012.
<br><br>
<br>De Commissie kan uitvoeringshandelingen vaststellen tot vaststelling van gemeenschappelijke specificaties voor de eisen van afdeling 2 van dit hoofdstuk of, in voorkomend geval, voor de verplichtingen van hoofdstuk V, afdelingen 2 en 3, indien aan de volgende voorwaarden is voldaan:<br>
a) de Commissie heeft op grond van artikel 10, lid 1, van Verordening (EU) nr. 1025/2012 een of meer Europese normalisatieorganisaties verzocht een geharmoniseerde norm op te stellen voor de in afdeling 2 van dit hoofdstuk beschreven eisen, of, in voorkomend geval, voor de verplichtingen van hoofdstuk V, afdelingen 2 en 3, en:<br>
i) het verzoek is door geen enkele van de Europese normalisatieorganisaties aanvaard, of<br>
ii) de geharmoniseerde normen waarop dat verzoek betrekking heeft, worden niet binnen de overeenkomstig artikel 10, lid 1, van Verordening (EU) nr. 1025/2012 vastgestelde termijn geleverd, of<br>
iii)<br>
in de relevante geharmoniseerde normen wordt onvoldoende rekening gehouden met problemen op het gebied van de grondrechten, of<br>
iv) de geharmoniseerde normen voldoen niet aan het verzoek, en<br>
b) er is geen referentie van geharmoniseerde normen overeenkomstig Verordening (EU) nr. 1025/2012 bekendgemaakt in het Publicatieblad van de Europese Unie voor de eisen van afdeling 2 van dit hoofdstuk of, in voorkomend geval, voor de verplichtingen van hoofdstuk V, afdelingen 2 en 3, en een dergelijke referentie zal naar verwachting niet binnen een redelijke termijn worden bekendgemaakt.<br>
Bij het opstellen van de gemeenschappelijke specificaties raadpleegt de Commissie het in artikel 67 bedoelde adviesforum.<br>
De in de eerste alinea van dit lid bedoelde uitvoeringshandelingen worden vastgesteld volgens de in artikel 98, lid 2, bedoelde onderzoeksprocedure.
<br>Alvorens een ontwerpuitvoeringshandeling op te stellen, stelt de Commissie het in artikel 22 van Verordening (EU) nr. 1025/2012 bedoelde comité ervan in kennis dat zij van oordeel is dat aan de voorwaarden van lid 1 van dit artikel is voldaan.
<br>AI-systemen met een hoog risico of AI-modellen voor algemene doeleinden die in overeenstemming zijn met de in lid 1 bedoelde gemeenschappelijke specificaties of delen daarvan worden geacht in overeenstemming te zijn met de in afdeling 2 van dit hoofdstuk beschreven voorschriften, of, in voorkomend geval, met de verplichtingen van hoofdstuk V, afdelingen 2 en 3, voor zover die voorschriften of die verplichtingen door die gemeenschappelijke specificaties worden bestreken.
<br>Wanneer een Europese normalisatieorganisatie een geharmoniseerde norm vaststelt en deze aan de Commissie voorstelt met het oog op de bekendmaking van de referentie ervan in het Publicatieblad van de Europese Unie, beoordeelt de Commissie de geharmoniseerde norm overeenkomstig Verordening (EU) nr. 1025/2012. Wanneer de referentie van een geharmoniseerde norm in het Publicatieblad van de Europese Unie wordt bekendgemaakt, trekt de Commissie de in lid 1 bedoelde uitvoeringshandelingen of delen daarvan die dezelfde in afdeling 2 van dit hoofdstuk vermelde eisen of, in voorkomend geval, dezelfde verplichtingen van hoofdstuk V, afdelingen 2 en 3, dekken, in.
<br>Wanneer aanbieders van AI-systemen met een hoog risico of AI-modellen voor algemene doeleinden niet voldoen aan de in lid 1 bedoelde gemeenschappelijke specificaties, moeten zij naar behoren rechtvaardigen dat zij technische oplossingen hebben gekozen die voldoen aan de in afdeling 2 van dit hoofdstuk beschreven voorschriften of, in voorkomend geval, aan de verplichtingen van hoofdstuk V, afdelingen 2 en 3, in een mate die minstens gelijkwaardig daarmee is.
<br>Wanneer een lidstaat van oordeel is dat een gemeenschappelijke specificatie niet volledig aan de eisen van afdeling 2 van dit hoofdstuk of, in voorkomend geval, de verplichtingen van hoofdstuk V, afdelingen 2 en 3, voldoet, stelt deze lidstaat de Commissie daarvan in kennis met een gedetailleerde toelichting. De Commissie beoordeelt die informatie en wijzigt de uitvoeringshandeling tot vaststelling van de betrokken gemeenschappelijke specificatie zo nodig.
<br><br>
<br>AI-systemen met een hoog risico die zijn getraind en getest op data die overeenkomen met de specifieke geografische, gedragsgerelateerde, contextuele of functionele omgeving waarin zij zullen worden gebruikt, geacht te voldoen de in artikel 10, lid 4, beschreven relevante eisen.
<br>AI-systemen met een hoog risico die zijn gecertificeerd of waarvoor een conformiteitsverklaring is verstrekt volgens een cyberbeveiligingsregeling krachtens Verordening (EU) 2019/881 en waarvan de referenties in het Publicatieblad van de Europese Unie zijn bekendgemaakt, worden geacht te voldoen aan de in artikel 15 van deze verordening beschreven cyberbeveiligingseisen, voor zover die eisen door het cyberbeveiligingscertificaat of de conformiteitsverklaring of delen daarvan worden bestreken.
<br><br>
<br>Voor in punt 1 van bijlage III opgesomde AI-systemen met een hoog risico kiest de aanbieder, wanneer de aanbieder bij het aantonen van de overeenstemming met de in afdeling 2 beschreven voorschriften van een AI-systeem met een hoog risico geharmoniseerde normen als bedoeld in artikel 40 of in voorkomend geval gemeenschappelijke specificaties als bedoeld in artikel 41 heeft toegepast, een van de volgende conformiteitsbeoordelingsprocedures op basis van:<br>
a) de in bijlage VI bedoelde interne controle, of<br>
b) de beoordeling van het systeem voor kwaliteitsbeheer en de beoordeling van de technische documentatie, met betrokkenheid van een aangemelde instantie, als bedoeld in bijlage VII.<br>
Bij het aantonen van de overeenstemming met de in afdeling 2 beschreven voorschriften van een AI-systeem met een hoog risico volgt de aanbieder de conformiteitsbeoordelingsprocedure van bijlage VII indien:<br>
a) er geen geharmoniseerde normen als bedoeld in artikel 40 bestaan en er geen gemeenschappelijke specificaties als bedoeld in artikel 41 voorhanden zijn;<br>
b) de aanbieder de geharmoniseerde norm niet of slechts gedeeltelijk heeft toegepast;<br>
c) de in punt a) bedoelde gemeenschappelijke specificaties bestaan, maar de aanbieder deze niet heeft toegepast;<br>
d) een of meer van de in punt a) bedoelde geharmoniseerde normen met beperkingen zijn bekendgemaakt, en alleen met betrekking tot het deel van de norm waarvoor de beperkingen gelden.<br>
Ten behoeve van de in bijlage VII bedoelde conformiteitsbeoordelingsprocedure kan de aanbieder om het even welke aangemelde instantie kiezen. Wanneer het AI-systeem met een hoog risico echter is bedoeld om door rechtshandhavingsinstanties, immigratie- of asielautoriteiten of door instellingen, organen of instanties van de Unie in gebruik te worden gesteld, treedt de markttoezichtautoriteit als bedoeld in artikel 74, lid 8 of lid 9, naargelang van toepassing, als aangemelde instantie op.
<br>Voor AI-systemen met een hoog risico als bedoeld in de punten 2 tot en met 8 van bijlage III volgen aanbieders de in bijlage VI bedoelde conformiteitsbeoordelingsprocedure op basis van interne controle, waarvoor de betrokkenheid van een aangemelde instantie niet nodig is.
<br>Voor AI-systemen met een hoog risico die onder de in afdeling A van bijlage I vermelde harmonisatiewetgeving van de Unie vallen, volgt de aanbieder de relevante conformiteitsbeoordelingsprocedure zoals vereist volgens die rechtshandelingen. De in afdeling 2 van dit hoofdstuk beschreven voorschriften zijn van toepassing op die AI-systemen met een hoog risico en maken deel uit van die beoordeling. De punten 4.3, 4.4, 4.5 en de vijfde alinea van punt 4.6 van bijlage VII zijn eveneens van toepassing.<br>
Voor die beoordeling hebben aangemelde instanties die volgens die rechtshandelingen zijn aangemeld het recht de conformiteit van de AI-systemen met een hoog risico met de in afdeling 2 beschreven voorschriften te controleren, mits de overeenstemming van die aangemelde instanties met voorschriften van artikel 31, leden 4, 10 en 11, in de context van de aanmeldingsprocedure volgens die rechtshandelingen is beoordeeld.<br>
Wanneer een in afdeling A van bijlage I vermelde rechtshandeling de productfabrikant in staat stelt zich te onttrekken aan een conformiteitsbeoordeling door een derde partij, mits die fabrikant alle geharmoniseerde normen voor alle relevante voorschriften heeft toegepast, kan de fabrikant alleen van die mogelijkheid gebruikmaken als hij ook geharmoniseerde normen of in voorkomend geval gemeenschappelijke specificaties als bedoeld in artikel 41 heeft toegepast, voor alle in afdeling 2 van dit hoofdstuk beschreven voorschriften.
<br>AI-systemen met een hoog risico die reeds aan een conformiteitsbeoordelingsprocedure zijn onderworpen, ondergaan een nieuwe conformiteitsbeoordelingsprocedure telkens wanneer zij substantieel zijn gewijzigd, ongeacht of het gewijzigde systeem bedoeld is om verder te worden gedistribueerd of door de huidige gebruiksverantwoordelijke gebruikt blijft worden.<br>
Voor AI-systemen met een hoog risico die doorgaan met leren na in de handel te zijn gebracht of in gebruik te zijn gesteld, vormen veranderingen van het AI-systeem met een hoog risico en de prestaties ervan die op het moment van de eerste conformiteitsbeoordeling vooraf door de aanbieder zijn bepaald en deel uitmaken van de informatie in de in punt 2, f), van bijlage IV bedoelde technische documentatie, geen substantiële wijziging.
<br>De Commissie is bevoegd overeenkomstig artikel 97 gedelegeerde handelingen vast te stellen om bijlagen VI en VII te wijzigen teneinde hen te actualiseren in het licht van technologische vooruitgang.
<br>De Commissie is bevoegd overeenkomstig artikel 97 gedelegeerde handelingen vast te stellen om de leden 1 en 2 te wijzigen, teneinde AI-systemen met een hoog risico als bedoeld in de punten 2 tot en met 8 van bijlage III te onderwerpen aan de conformiteitsbeoordelingsprocedure als bedoeld in bijlage VII of delen daarvan. De Commissie stelt zulke gedelegeerde handelingen vast rekening houdend met de doeltreffendheid van de conformiteitsbeoordelingsprocedure op basis van interne controle als bedoeld in bijlage VI bij het voorkomen of minimaliseren van de risico’s voor de gezondheid en veiligheid en de bescherming van grondrechten die zulke systemen inhouden alsook met de beschikbaarheid van voldoende capaciteit en personeel onder aangemelde instanties.
<br><br>
<br>Door aangemelde instanties overeenkomstig bijlage VII afgegeven certificaten worden opgesteld in een taal die de desbetreffende autoriteiten in de lidstaat waar de aangemelde instantie is gevestigd, gemakkelijk kunnen begrijpen.
<br>Certificaten zijn geldig gedurende de daarin aangegeven periode, die niet meer dan vijf jaar mag bedragen voor AI-systemen die onder bijlage I vallen, en niet meer dan vier jaar voor AI-systemen die onder bijlage III vallen. Op verzoek van de aanbieder kan de geldigheidsduur van een certificaat op grond van een herbeoordeling volgens de toepasselijke conformiteitsbeoordelingsprocedures worden verlengd met bijkomende perioden, die elk niet meer dan vijf jaar mogen bedragen voor AI-systemen die onder bijlage I vallen en niet meer dan vier jaar voor AI-systemen die onder bijlage III vallen. Aanvullingen op een certificaat blijven geldig zolang het certificaat dat zij aanvullen geldig blijft.
<br>Indien een aangemelde instantie vaststelt dat een AI-systeem niet meer aan de in afdeling 2 beschreven voorschriften voldoet, gaat zij, rekening houdend met het evenredigheidsbeginsel, over tot schorsing of intrekking van het afgegeven certificaat of legt zij beperkingen op, tenzij de aanbieder van het systeem, met het oog op de naleving van deze voorschriften, binnen een door de aangemelde instantie vastgestelde passende termijn adequate corrigerende actie onderneemt. De aangemelde instantie geeft de redenen voor haar besluit op.<br>
Er wordt voorzien in een beroepsprocedure tegen besluiten van de aangemelde instanties, ook inzake afgegeven conformiteitscertificaten.
<br><br>
<br>Aangemelde instanties brengen de aanmeldende autoriteit op de hoogte van:<br>
a) beoordelingscertificaten van technische documentatie van de Unie, aanvullingen op die certificaten en goedkeuringen voor systemen voor kwaliteitsbeheer afgegeven overeenkomstig de eisen van bijlage VII;<br>
b) weigering, beperking, schorsing of intrekking van een beoordelingscertificaat technische documentatie van de Unie of een goedkeuring voor systemen voor kwaliteitsbeheer afgegeven overeenkomstig de eisen van bijlage VII;<br>
c) omstandigheden die van invloed zijn op het toepassingsgebied van of de voorwaarden voor de aanmelding;<br>
d) verzoeken om informatie over conformiteitsbeoordelingsactiviteiten die zij van markttoezichtautoriteiten ontvangen;<br>
e) op verzoek, de binnen het toepassingsgebied van hun aanmelding verrichte conformiteitsbeoordelingsactiviteiten en andere activiteiten, waaronder grensoverschrijdende activiteiten en onderaanneming.
<br>Elke aangemelde instantie brengt de andere aangemelde instanties op de hoogte van:<br>
a) door haar geweigerde, opgeschorte of ingetrokken goedkeuringen voor kwaliteitsbeheersystemen alsmede, op verzoek, van de door haar verleende goedkeuringen voor systemen voor kwaliteitsbeheer;<br>
b) beoordelingscertificaten van technische documentatie van de Unie of aanvullingen daarop die zij heeft geweigerd, ingetrokken, opgeschort of anderszins beperkt alsmede, op verzoek, de certificaten en/of aanvullingen daarop die zij heeft uitgegeven.
<br>Elke aangemelde instantie verstrekt de andere aangemelde instanties die soortgelijke conformiteitsbeoordelingsactiviteiten voor dezelfde soorten AI-systemen verrichten, relevante informatie over negatieve conformiteitsbeoordelingsresultaten, en op verzoek ook over positieve conformiteitsbeoordelingsresultaten.
<br>Aanmeldende autoriteiten waarborgen dat de door hen verkregen informatie overeenkomstig artikel 78 vertrouwelijk wordt behandeld.
<br><br>
<br>In afwijking van artikel 43 en op naar behoren gemotiveerd verzoek kan een markttoezichtautoriteit het in de handel brengen of het in gebruik stellen van specifieke AI-systemen met een hoog risico binnen het grondgebied van de betrokken lidstaat toelaten, om uitzonderlijke redenen van openbare veiligheid of de bescherming van het leven en de gezondheid van personen, milieubescherming of de bescherming van essentiële industriële en infrastructurele activa. De toelating geldt gedurende een beperkte periode, terwijl de nodige conformiteitsbeoordelingsprocedures worden uitgevoerd, rekening houdend met de uitzonderlijke redenen ter rechtvaardiging van de afwijking. Die procedures worden zo snel mogelijk afgerond.
<br>In een naar behoren gerechtvaardigde situatie van urgentie om uitzonderlijke redenen van openbare veiligheid of in geval van een specifieke, substantiële en imminente dreiging voor het leven of de fysieke veiligheid van natuurlijke personen, kunnen rechtshandhavingsinstanties of civielebeschermingsautoriteiten een specifiek AI-systeem met een hoog risico in gebruik stellen zonder de in lid 1 bedoelde toelating, op voorwaarde dat die toelating tijdens of na het gebruik zonder onnodige vertraging wordt aangevraagd. Indien de in lid 1 bedoelde toelating wordt geweigerd, wordt het gebruik van het AI-systeem met een hoog risico met onmiddellijke ingang stopgezet en worden alle resultaten en outputs van dat gebruik onmiddellijk verwijderd.
<br>De in lid 1 bedoelde toelating wordt alleen verstrekt als de markttoezichtautoriteit concludeert dat het AI-systeem met een hoog risico aan de voorschriften van afdeling 2 voldoet. De markttoezichtautoriteit stelt de Commissie en de andere lidstaten in kennis van op grond van de leden 1 en 2 verstrekte toelatingen. Deze verplichting geldt niet voor gevoelige operationele gegevens met betrekking tot de activiteiten van rechtshandhavingsinstanties.
<br>Indien binnen 15 kalenderdagen na de ontvangst van de in lid 3 bedoelde informatie geen bezwaar is geopperd door een lidstaat of de Commissie tegen een door een markttoezichtautoriteit van een lidstaat overeenkomstig lid 1 verstrekte toelating, wordt die toelating geacht gerechtvaardigd te zijn.
<br>Indien binnen 15 kalenderdagen na de ontvangst van in lid 3 bedoelde kennisgeving door een lidstaat bezwaren worden geopperd tegen een door een markttoezichtautoriteit van een andere lidstaat verstrekte toelating, of wanneer de Commissie de toelating in strijd met het Unierecht acht of de conclusie van de lidstaten ten aanzien van de conformiteit van het systeem als bedoeld in lid 3 ongegrond acht, treedt de Commissie onverwijld in overleg met de relevante lidstaat. De betrokken operatoren worden geraadpleegd en hebben de mogelijkheid hun standpunten uiteen te zetten. Met het oog daarop besluit de Commissie of de toelating gerechtvaardigd is. De Commissie richt haar besluit aan de betrokken lidstaat en de relevante operatoren.
<br>Indien de Commissie de toelating ongerechtvaardigd acht, wordt deze ingetrokken door de markttoezichtautoriteit van de betrokken lidstaat.
<br>Voor AI-systemen met een hoog risico die verband houden met producten die onder de in afdeling A van bijlage I vermelde harmonisatiewetgeving van de Unie vallen, zijn alleen de in die harmonisatiewetgeving van de Unie vastgestelde afwijkingen van de conformiteitsbeoordeling van toepassing.
<br><br>
<br>De aanbieder stelt voor elk AI-systeem met een hoog risico een schriftelijke machineleesbare, fysieke of elektronisch ondertekende EU-conformiteitsverklaring op en houdt deze verklaring tot tien jaar na het in de handel brengen of het in gebruik stellen van het AI-systeem met een hoog risico ter beschikking van de nationale bevoegde autoriteiten. In de EU-conformiteitsverklaring wordt vermeld voor welk AI-systeem met een hoog risico ze is opgesteld. Op verzoek wordt een kopie van de EU-conformiteitsverklaring aan de relevante nationale bevoegde autoriteiten voorgelegd.
<br>In de EU-conformiteitsverklaring wordt vermeld dat het betreffende AI-systeem met een hoog risico aan de in afdeling 2 beschreven voorschriften voldoet. De EU-conformiteitsverklaring bevat de informatie die is vervat in bijlage V en wordt vertaald in een taal die de nationale bevoegde autoriteiten van de lidstaten waarin het AI-systeem met een hoog risico in de handel wordt gebracht of wordt aangeboden, gemakkelijk kunnen begrijpen.
<br>Wanneer AI-systemen met een hoog risico onder andere harmonisatiewetgeving van de Unie vallen, waarvoor ook een EU-conformiteitsverklaring is vereist, wordt één EU-conformiteitsverklaring ten aanzien van alle op het AI-systeem met een hoog risico toepasselijke Uniewetgeving opgesteld. De verklaring bevat alle informatie die vereist is voor de identificatie van de harmonisatiewetgeving van de Unie waarop de verklaring betrekking heeft.
<br>Met het opstellen van de EU-conformiteitsverklaring neemt de aanbieder de verantwoordelijkheid op zich om de in afdeling 2 beschreven voorschriften na te leven. De aanbieder houdt de EU-conformiteitsverklaring voor zover dienstig up-to-date.
<br>De Commissie is bevoegd overeenkomstig artikel 97 gedelegeerde handelingen vast te stellen om bijlage V te wijzigen door het actualiseren van de in die bijlage beschreven inhoud van de EU-conformiteitsverklaring, teneinde elementen in te voeren die noodzakelijk worden in het licht van de technische vooruitgang.
<br><br>
<br>De CE-markering is onderworpen aan de algemene beginselen die zijn neergelegd in artikel 30 van Verordening (EG) nr. 765/2008.
<br>Voor digitaal aangeboden AI-systemen met een hoog risico wordt alleen een digitale CE-markering gebruikt als deze gemakkelijk toegankelijk is via de interface waarmee toegang wordt verkregen tot dat systeem of via een gemakkelijk toegankelijke machineleesbare code of andere elektronische middelen.
<br>De CE-markering wordt zichtbaar, leesbaar en onuitwisbaar op AI-systemen met een hoog risico aangebracht. Wanneer dit gezien de aard van het AI-systeem met een hoog risico niet mogelijk of niet gerechtvaardigd is, wordt de markering naargelang het geval op de verpakking of in de begeleidende documenten aangebracht.
<br>Indien van toepassing, wordt de CE-markering gevolgd door het identificatienummer van de aangemelde instantie die verantwoordelijk is voor de in artikel 43 beschreven conformiteitsbeoordelingsprocedures. Het identificatienummer van de aangemelde instantie wordt aangebracht door die instantie zelf dan wel overeenkomstig haar instructies door de aanbieder of door diens gemachtigde. Het identificatienummer wordt ook vermeld in reclamemateriaal waarin staat dat een AI-systeem met een hoog risico aan de eisen voor de CE-markering voldoet.
<br>Indien AI-systemen met een hoog risico onder andere Uniewetgeving vallen die ook betrekking heeft op het aanbrengen van de CE-markering, vermeldt de CE-markering dat de AI-systemen met een hoog risico tevens aan de voorschriften van die andere wetgeving voldoen.
<br><br>
<br>Alvorens een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van de in punt 2 van bijlage III vermelde AI-systemen met een hoog risico, in de handel te brengen of in gebruik te stellen, registreert de aanbieder of in voorkomend geval de gemachtigde zichzelf en zijn systeem in de in artikel 71 bedoelde EU-databank.
<br>Alvorens een AI-systeem in de handel te brengen of in gebruik te stellen dat naar oordeel van de aanbieder geen hoog risico inhoudt volgens artikel 6, lid 3, registreert die aanbieder of in voorkomend geval de gemachtigde zichzelf en dat systeem in de in artikel 71 bedoelde EU-databank.
<br>Alvorens een in bijlage III vermeld AI-systeem met een hoog risico in gebruik te stellen of te gebruiken, met uitzondering van de in punt 2 van bijlage III vermelde AI-systemen met een hoog risico, registreren gebruiksverantwoordelijken die overheidsinstanties, instellingen, organen of instanties van de Unie, of personen die namens hen optreden, zichzelf en selecteren zij het systeem en registreren zij het gebruik ervan in de in artikel 71 bedoelde EU-databank.
<br>Voor AI-systemen met een hoog risico als bedoeld in de punten 1, 6 en 7 van bijlage III, op het gebied van rechtshandhaving, migratie, asiel en grenstoezichtsbeheer, vindt de in de leden 1, 2 en 3 van dit artikel bedoelde registratie plaats in een beveiligd niet-openbaar gedeelte van de in artikel 71 bedoelde EU-databank en bevat deze alleen de volgende informatie, voor zover van toepassing, als bedoeld in:<br>
a) afdeling A, punten 1 tot en met 10, van bijlage VIII, met uitzondering van punten 6, 8 en 9;<br>
b) afdeling B, punten 1 tot en met 5, en punten 8 en 9 van bijlage VIII;<br>
c) afdeling C, punten 1, 2 en 3, van bijlage VIII;<br>
d) de punten 1, 2, 3 en 5 van bijlage IX.<br>
Alleen de Commissie en de in artikel 74, lid 8, bedoelde nationale autoriteiten hebben toegang tot de respectieve in de eerste alinea van dit lid vermelde beperkt toegankelijke gedeelten van de EU-databank.
<br>AI-systemen met een hoog risico als bedoeld in punt 2 van bijlage III worden op nationaal niveau geregistreerd.
]]></description><link>hoofdstukken/hoofdstuk_3.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_3.md</guid><pubDate>Tue, 13 Aug 2024 13:38:06 GMT</pubDate></item><item><title><![CDATA[hoofdstuk_4]]></title><description><![CDATA[ 
 <br>HOOFDSTUK IV<br>
TRANSPARANTIEVERPLICHTINGEN VOOR AANBIEDERS EN GEBRUIKSVERANTWOORDELIJKEN VAN BEPAALDE AI-SYSTEMEN<br><br>
<br>Aanbieders zorgen ervoor dat AI-systemen die voor directe interactie met natuurlijke personen zijn bedoeld, zodanig worden ontworpen en ontwikkeld dat de betrokken natuurlijke personen worden geïnformeerd dat zij interageren met een AI-systeem, tenzij dit duidelijk is vanuit het oogpunt van een normaal geïnformeerde en redelijk omzichtige en oplettende natuurlijke persoon, rekening houdend met de omstandigheden en de gebruikscontext. Deze verplichting is niet van toepassing op bij wet toegestane AI-systemen voor het opsporen, voorkomen, onderzoeken of vervolgen van strafbare feiten, met inachtneming van passende waarborgen voor de rechten en vrijheden van derden, tenzij die systemen voor het publiek beschikbaar zijn om een strafbaar feit te melden.
<br>Aanbieders van AI-systemen, met inbegrip van AI-systemen voor algemene doeleinden, die synthetische audio-, beeld-, video- of tekstinhoud genereren, zorgen ervoor dat de outputs van het AI-systeem worden gemarkeerd in een machineleesbaar formaat en detecteerbaar zijn als kunstmatig gegenereerd of gemanipuleerd. Aanbieders zorgen ervoor dat hun technische oplossingen doeltreffend, interoperabel, robuust en betrouwbaar zijn voor zover dat technisch haalbaar is, rekening houdend met de specifieke kenmerken en beperkingen van de verschillende soorten content, de uitvoeringskosten en de algemeen erkende stand van de techniek, zoals tot uiting kan komen in relevante technische normen. Deze verplichting is niet van toepassing voor zover de AI-systemen een ondersteunende functie voor standaardbewerking vervullen of de door de gebruiksverantwoordelijke of de semantiek daarvan verstrekte inputdata niet substantieel wijzigen, of wanneer het bij wet is toegestaan strafbare feiten op te sporen, te voorkomen, te onderzoeken of te vervolgen.
<br>Gebruiksverantwoordelijken van een systeem voor het herkennen van emoties of een systeem voor biometrische categorisering informeren de daaraan blootgestelde natuurlijke personen over de werking van het systeem en verwerken de persoonsgegevens in overeenstemming met Verordening (EU) 2016/679, Verordening (EU) 2018/1725 en Richtlijn (EU) 2016/680, indien van toepassing. Deze verplichting is niet van toepassing op voor biometrische categorisering en emotieherkenning gebruikte AI-systemen, die bij wet zijn toegestaan om strafbare feiten op te sporen, te voorkomen of te onderzoeken, met inachtneming van passende waarborgen voor de rechten en vrijheden van derden en overeenkomstig het Unierecht.
<br>Gebruiksverantwoordelijken van een AI-systeem dat beeld-, audio- of videocontent genereert of bewerkt die een deepfake vormt, maken bekend dat de content kunstmatig is gegenereerd of gemanipuleerd. Deze verplichting geldt niet wanneer het gebruik bij wet is toegestaan om strafbare feiten op te sporen, te voorkomen, te onderzoeken of te vervolgen. Wanneer de content deel uitmaakt van een kennelijk artistiek, creatief, satirisch, fictief of analoog werk of programma, zijn de transparantieverplichtingen van dit lid beperkt tot de openbaarmaking van het bestaan van dergelijke gegenereerde of bewerkte content op een passende wijze die de weergave of het genot van het werk niet belemmert.<br>
Gebruiksverantwoordelijken van een AI-systeem dat tekst genereert of bewerkt die wordt gepubliceerd om het publiek te informeren over aangelegenheden van algemeen belang, maken bekend dat de tekst kunstmatig is gegenereerd of bewerkt. Deze verplichting is echter niet van toepassing wanneer het gebruik bij wet is toegestaan om strafbare feiten op te sporen, te voorkomen, te onderzoeken of te vervolgen of wanneer de door AI gegenereerde content een proces van menselijke toetsing of redactionele controle heeft ondergaan en wanneer een natuurlijke of rechtspersoon redactionele verantwoordelijkheid draagt voor de bekendmaking van de content.
<br>De in de leden 1 tot en met 4 bedoelde informatie wordt uiterlijk op het moment van de eerste interactie of blootstelling op duidelijke en te onderscheiden wijze aan de betrokken natuurlijke personen verstrekt. De informatie moet aan de toepasselijke toegankelijkheidseisen voldoen.
<br>De leden 1 tot en met 4 laten de voorschriften en verplichtingen van hoofdstuk III onverlet en doen geen afbreuk aan andere transparantieverplichtingen die zijn vastgelegd in het Unierecht of het nationale recht voor gebruiksverantwoordelijken van AI-systemen.
<br>Het AI-bureau stimuleert en faciliteert de opstelling van praktijkcodes op het niveau van de Unie om de doeltreffende uitvoering van de verplichtingen met betrekking tot de opsporing en het labelen van kunstmatig gegenereerde of bewerkte content te vergemakkelijken. De Commissie kan uitvoeringshandelingen vaststellen om die praktijkcodes overeenkomstig de procedure van artikel 56, lid 6, goed te keuren. Indien zij de code ontoereikend acht, kan de Commissie volgens de onderzoeksprocedure van artikel 98, lid 2, een uitvoeringshandeling vaststellen waarin gemeenschappelijke regels voor de uitvoering van die verplichtingen worden gespecificeerd.
]]></description><link>hoofdstukken/hoofdstuk_4.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_4.md</guid><pubDate>Tue, 13 Aug 2024 13:38:15 GMT</pubDate></item><item><title><![CDATA[hoofdstuk_5]]></title><description><![CDATA[ 
 <br>HOOFDSTUK V<br>
AI-MODELLEN VOOR ALGEMENE DOELEINDEN<br>
AFDELING 1<br>
Classificatieregels<br><br>
<br>Een AI-model voor algemene doeleinden wordt geclassificeerd als een AI-model voor algemene doeleinden met een systeemrisico als het aan één van de volgende voorwaarden voldoet:<br>
a) het beschikt over capaciteiten met een grote impact die worden geëvalueerd op basis van passende technische instrumenten en methoden, met inbegrip van indicatoren en benchmarks;<br>
b) op grond van een besluit van de Commissie, ambtshalve of naar aanleiding van een gekwalificeerde waarschuwing van het wetenschappelijk panel, heeft het AI-model vergelijkbare capaciteiten of een vergelijkbare impact als beschreven in punt a), met inachtneming van de criteria in bijlage XIII.
<br>Een AI-model voor algemene doeleinden wordt geacht capaciteiten met een grote impact overeenkomstig lid 1, punt a), te hebben wanneer de cumulatieve hoeveelheid berekeningen die wordt gebruikt om het model te trainen, gemeten in zwevendekommabewerkingen, groter is dan 1025.
<br>De Commissie stelt overeenkomstig artikel 97 gedelegeerde handelingen vast om de in de leden 1 en 2 van dit artikel genoemde drempelwaarden te wijzigen en benchmarks en indicatoren zo nodig aan te vullen in het licht van veranderende technologische ontwikkelingen, zoals algoritmische verbeteringen of verhoogde efficiëntie van de hardware, zodat deze drempels de stand van de techniek weerspiegelen.
<br><br>
<br>Indien een AI-model voor algemene doeleinden voldoet aan de in artikel 51, lid 1, punt a), bedoelde voorwaarde, stelt de betrokken aanbieder de Commissie daarvan onverwijld in kennis, doch in ieder geval binnen twee weken nadat aan die eis is voldaan of nadat bekend is geworden dat aan die eis zal worden voldaan. Die kennisgeving bevat de informatie die nodig is om aan te tonen dat aan de desbetreffende eis is voldaan. Als de Commissie kennis krijgt van een AI-model voor algemene doeleinden dat systeemrisico’s vertoont waarvan zij niet in kennis is gesteld, kan zij besluiten dit model aan te wijzen als een model met een systeemrisico.
<br>De aanbieder van een AI-model voor algemene doeleinden dat voldoet aan de in artikel 51, lid 1, punt a), bedoelde voorwaarden, kan bij zijn kennisgeving voldoende onderbouwde argumenten aanvoeren om aan te tonen dat het AI-model voor algemene doeleinden, hoewel het voldoet aan die eis, bij wijze van uitzondering, vanwege zijn specifieke kenmerken geen systeemrisico’s vertoont en derhalve niet zou mogen worden geclassificeerd als een AI-model voor algemene doeleinden met een systeemrisico.
<br>Indien de Commissie concludeert dat de uit hoofde van lid 2 aangevoerde argumenten niet voldoende onderbouwd zijn en de desbetreffende aanbieder niet kan aantonen dat het AI-model voor algemene doeleinden vanwege zijn specifieke kenmerken geen systeemrisico’s vertoont, verwerpt zij deze argumenten en wordt het AI-model voor algemene doeleinden beschouwd als een AI-model voor algemene doeleinden met een systeemrisico.
<br>De Commissie kan ambtshalve of na een gekwalificeerde waarschuwing van het wetenschappelijk panel op grond van artikel 90, lid 1, punt a), op basis van de in bijlage XIII vastgestelde criteria een AI-model voor algemene doeleinden aanwijzen als een AI-model dat systeemrisico’s vertoont.<br>
De Commissie is bevoegd overeenkomstig artikel 97 gedelegeerde handelingen vast te stellen om bijlage XIII te wijzigen door de in die bijlage beschreven criteria te specificeren en te actualiseren.
<br>Als een aanbieder wiens model op grond van lid 4 is aangewezen als AI-model voor algemene doeleinden met een systeemrisico een met redenen omkleed verzoek indient, neemt de Commissie dit in overweging en kan zij besluiten om opnieuw te beoordelen of het AI-model voor algemene doeleinden op basis van de criteria van bijlage XIII nog steeds wordt beschouwd als een AI-model dat systeemrisico’s vertoont. Een dergelijk verzoek moet objectieve, gedetailleerde en nieuwe redenen bevatten die na het aanwijzingsbesluit aan het licht zijn gekomen. Aanbieders kunnen ten vroegste zes maanden na het aanwijzingsbesluit om een herbeoordeling verzoeken. Indien de Commissie na haar herbeoordeling besluit de aanwijzing als AI-model voor algemene doeleinden met een systeemrisico te handhaven, kunnen aanbieders pas na zes maanden na dat besluit opnieuw om een herbeoordeling verzoeken.
<br>De Commissie zorgt ervoor dat er een lijst met AI-modellen voor algemene doeleinden met een systeemrisico wordt gepubliceerd en houdt die lijst actueel, onverminderd de noodzaak om intellectuele-eigendomsrechten en vertrouwelijke bedrijfsinformatie of bedrijfsgeheimen te eerbiedigen en te beschermen overeenkomstig het Unierecht en het nationale recht.<br>
AFDELING 2<br>
Verplichtingen voor aanbieders van AI-modellen voor algemene doeleinden
<br><br>
<br>Aanbieders van AI-modellen voor algemene doeleinden moeten:<br>
a) de technische documentatie van het model opstellen en up-to-date houden, inclusief het trainings- en testproces en de resultaten van de evaluatie ervan, die ten minste de in bijlage XI vermelde informatie moet bevatten, zodat deze op verzoek aan het AI-bureau en de nationale bevoegde autoriteiten kunnen worden verstrekt;<br>
b) informatie en documentatie opstellen, up-to-date houden en beschikbaar stellen voor aanbieders van AI-systemen die het AI-model voor algemene doeleinden in hun AI-systemen willen integreren. Onverminderd de noodzaak om intellectuele-eigendomsrechten en vertrouwelijke bedrijfsinformatie of bedrijfsgeheimen overeenkomstig het Unierecht en het nationale recht te eerbiedigen en te beschermen, moet de informatie en documentatie:<br>
i) aanbieders van AI-systemen inzicht geven in de capaciteiten en beperkingen van het AI-model voor algemene doeleinden en ze in staat te stellen aan hun verplichtingen uit hoofde van deze verordening te voldoen, en<br>
ii) ten minste de in bijlage XII uiteengezette elementen bevatten;<br>
c) beleid opstellen ter naleving van het Unierecht inzake auteursrechten en naburige rechten en dan met name ter vaststelling en naleving, onder meer door middel van geavanceerde technologieën, van een op grond van artikel 4, lid 3, van Richtlijn (EU) 2019/790 tot uitdrukking gebracht voorbehoud van rechten.<br>
d) een voldoende gedetailleerde samenvatting opstellen en openbaar maken over de voor het trainen van het AI-model voor algemene doeleinden gebruikte content, volgens een door het AI-bureau verstrekt sjabloon.
<br>De in lid 1, punten a) en b) genoemde verplichtingen gelden niet voor aanbieders van AI-modellen die worden vrijgegeven in het kader van een vrije en opensource licentie die de raadpleging, het gebruik, de wijziging en distributie van het model mogelijk maakt en waarvan de parameters, met inbegrip van de wegingen, de informatie over de modelarchitectuur en de informatie over het gebruik van het model, openbaar worden gemaakt. Deze uitzondering is niet van toepassing op AI-modellen voor algemene doeleinden met systeemrisico's.
<br>Aanbieders van AI-modellen voor algemene doeleinden werken zo nodig samen met de Commissie en de nationale bevoegde autoriteiten bij de uitoefening van hun bevoegdheden uit hoofde van deze verordening.
<br>Aanbieders van AI-modellen voor algemene doeleinden kunnen zich baseren op praktijkcodes in de zin van artikel 56 om de naleving van de in lid 1 van dit artikel vastgestelde verplichtingen aan te tonen, totdat er een geharmoniseerde norm is gepubliceerd. Door Europese geharmoniseerde normen na te leven genieten aanbieders een vermoeden van overeenstemming, voor zover die normen die verplichtingen dekken. Aanbieders van AI-modellen voor algemene doeleinden die zich niet aan een goedgekeurde praktijkcode houden of niet voldoen aan een Europese geharmoniseerde norm, tonen alternatieve passende wijzen van naleving aan die door de Commissie moeten worden beoordeeld.
<br>Om de naleving van bijlage XI, en met name punt 2, d) en e), te vergemakkelijken, is de Commissie bevoegd overeenkomstig artikel 97 gedelegeerde handelingen vast te stellen waarin de meet- en berekeningsmethoden worden gespecificeerd zodat de documentatie vergelijkbaar en verifieerbaar wordt.
<br>De Commissie is bevoegd overeenkomstig artikel 97, lid 2, gedelegeerde handelingen vast te stellen om bijlagen XI en XII te wijzigen in het licht van evoluerende technologische ontwikkelingen.
<br>Uit hoofde van dit artikel verkregen informatie of documentatie, met inbegrip van bedrijfsgeheimen, worden verwerkt overeenkomstig de in artikel 78 vastgelegde vertrouwelijkheidsverplichtingen.
<br><br>
<br>Aanbieders die in derde landen zijn gevestigd, wijzen voordat zij een AI-model voor algemene doeleinden in de Unie in de handel brengen, middels een schriftelijke machtiging een gemachtigde aan die is gevestigd in de Unie.
<br>De aanbieder stelt zijn gemachtigde in staat de taken uit te voeren die staan gespecificeerd in het mandaat dat hij van de aanbieder heeft ontvangen.
<br>De gemachtigde voert de taken uit die staan gespecificeerd in het mandaat dat hij van de aanbieder heeft ontvangen. Hij legt op verzoek een kopie van het mandaat over aan het AI-bureau, in een van de officiële talen van de instellingen van de Unie. Voor de toepassing van deze verordening geeft het mandaat de gemachtigde de bevoegdheid om de volgende taken te verrichten:<br>
a) controleren of de aanbieder de in bijlage XI gespecificeerde technische documentatie heeft opgesteld en aan alle in artikel 53 en, indien van toepassing, artikel 55 bedoelde verplichtingen heeft voldaan;<br>
b) een kopie van de in bijlage XI gespecificeerde technische documentatie beschikbaar houden voor het AI-bureau en de nationale autoriteiten gedurende een periode van tien jaar nadat het AI-model voor algemene doeleinden in de handel is gebracht, en de contactgegevens van de aanbieder door wie de gemachtigde is aangewezen;<br>
c) het verstrekken aan het AI-bureau, na een met redenen omkleed verzoek, van alle informatie en documentatie, waaronder die in punt b), die nodig is om aan te tonen dat de verplichtingen van dit hoofdstuk worden nageleefd;<br>
d) samenwerken met het AI-bureau en de bevoegde autoriteiten, na een met redenen omkleed verzoek, bij alle maatregelen die de autoriteiten nemen in verband met het AI-model voor algemene doeleinden, ook indien het model wordt geïntegreerd in AI-systemen die in de Unie in de handel worden gebracht of in gebruik worden gesteld.
<br>Door het mandaat wordt de gemachtigde aangesteld als aanspreekpunt, naast of in plaats van de aanbieder, voor het AI-bureau of de bevoegde autoriteiten, met betrekking tot alle vraagstukken die verband houden met het waarborgen van de naleving van deze verordening.
<br>De gemachtigde beëindigt het mandaat indien hij van mening is of redenen heeft om aan te nemen dat de aanbieder in strijd met zijn verplichtingen op grond van deze verordening handelt. In dat geval stelt hij tevens het AI-bureau onmiddellijk in kennis van de beëindiging van het mandaat en de redenen daarvoor.
<br>De in dit artikel genoemde verplichting geldt niet voor aanbieders van AI-modellen die worden vrijgegeven in het kader van een vrije en opensource licentie die de raadpleging, het gebruik, de wijziging en distributie van het model mogelijk maakt en waarvan de parameters, met inbegrip van de wegingen, de informatie over de modelarchitectuur en de informatie over het gebruik van het model, openbaar worden gemaakt, tenzij de AI-modellen voor algemene doeleinden systeemrisico’s vertonen.<br>
AFDELING 3<br>
Verplichtingen van aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico
<br><br>
<br>Naast de in de artikelen 53 en 54 genoemde verplichtingen moeten aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico:<br>
a) een modelevaluatie uitvoeren overeenkomstig gestandaardiseerde protocollen en instrumenten die de stand van de techniek weerspiegelen, met inbegrip van het uitvoeren en documenteren van tests gericht op het ontdekken van kwetsbaarheden van het model met als doel om systeemrisico’s in kaart te brengen en te beperken;<br>
b) mogelijke systeemrisico’s op Unieniveau beoordelen en beperken, met inbegrip van de bronnen daarvan, die kunnen voortvloeien uit de ontwikkeling, het in de handel brengen of het gebruik van AI-modellen voor algemene doeleinden met een systeemrisico;<br>
c) relevante informatie over ernstige incidenten en mogelijke corrigerende maatregelen bijhouden, documenteren en onverwijld rapporteren aan het AI-bureau en, in voorkomend geval, aan de nationale bevoegde autoriteiten;<br>
d) zorgen voor een passend niveau van cyberbeveiligingsbescherming voor het AI-model voor algemene doeleinden met een systeemrisico en de fysieke infrastructuur van het model.
<br>Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico kunnen zich baseren op praktijkcodes in de zin van artikel 56 om de naleving van de in lid 1 van dit artikel vastgestelde verplichtingen aan te tonen, totdat er een geharmoniseerde norm is gepubliceerd. Door Europese geharmoniseerde normen na te leven genieten aanbieders een vermoeden van overeenstemming, voor zover die normen ook die verplichtingen dekken. Aanbieders van AI-modellen voor algemene doeleinden met een systeemrisico die zich niet aan een goedgekeurde praktijkcode houden of niet voldoen aan een Europese geharmoniseerde norm, tonen alternatieve passende wijzen van naleving aan die door de Commissie moeten worden beoordeeld.
<br>Uit hoofde van dit artikel verkregen informatie of documentatie, met inbegrip van bedrijfsgeheimen, worden verwerkt overeenkomstig de in artikel 78 vastgelegde vertrouwelijkheidsverplichtingen.<br>
AFDELING 4<br>
Praktijkcodes
<br><br>
<br>Het AI-bureau stimuleert en faciliteert de opstelling van praktijkcodes op Unieniveau als bijdrage aan de correcte toepassing van deze verordening, rekening houdend met internationale benaderingen.
<br>Het AI-bureau en de AI-board streven ernaar ervoor te zorgen dat de praktijkcodes ten minste de verplichtingen omvatten die zijn bepaald in de artikelen 53 en 55, waaronder de volgende zaken:<br>
a) de middelen om ervoor te zorgen dat de in artikel 53, lid 1, punten a) en b), bedoelde informatie up-to-date wordt gehouden in het licht van markt- en technologische ontwikkelingen;<br>
b) de mate van gedetailleerdheid van de samenvatting over de voor het trainen van het AI-model gebruikte content;<br>
c) het in kaart brengen van het type en de aard van de systeemrisico’s op Unieniveau, met inbegrip van de bronnen ervan, indien van toepassing;<br>
d) de maatregelen, procedures en modaliteiten voor de beoordeling en het beheer van de systeemrisico’s op Unieniveau, met inbegrip van de documentatie daarvan, die in verhouding moeten staan tot de risico’s, rekening houden met de ernst en waarschijnlijkheid ervan en met de specifieke uitdagingen om die risico’s aan te pakken in het licht van de mogelijke manieren waarop dergelijke risico’s in de AI-waardeketen kunnen ontstaan en zich voordoen.
<br>Het AI-bureau kan alle aanbieders van AI-modellen voor algemene doeleinden en relevante nationale bevoegde autoriteiten uitnodigen om deel te nemen aan het opstellen van praktijkcodes. Maatschappelijke organisaties, het bedrijfsleven, de academische wereld en andere relevante belanghebbenden, zoals aanbieders verder in de AI-waardeketen en onafhankelijke deskundigen, kunnen het proces ondersteunen.
<br>Het AI-bureau en de AI-board streven ernaar ervoor te zorgen dat hun specifieke doelstellingen in de praktijkcodes duidelijk uiteen worden gezet en toezeggingen of maatregelen bevatten, met inbegrip van, waar passend, kernprestatie-indicatoren, om ervoor te zorgen dat die doelstellingen worden verwezenlijkt, en dat de praktijkcodes naar behoren rekening houden met de behoeften en belangen van alle belanghebbenden, met inbegrip van betrokken personen, op Unieniveau.
<br>Het AI-bureau streeft ernaar ervoor te zorgen dat de deelnemers aan de praktijkcodes regelmatig verslag uitbrengen aan het AI-bureau over de uitvoering van de verbintenissen en de genomen maatregelen en de resultaten daarvan, onder meer waar nodig gemeten aan de hand van de kernprestatie-indicatoren. De kernprestatie-indicatoren en rapportageverplichtingen weerspiegelen de verschillen in omvang en capaciteit tussen de verschillende deelnemers.
<br>Het AI-bureau en de AI-board monitoren en evalueren regelmatig of de deelnemers de doelstellingen van de praktijkcodes verwezenlijken en bijdragen aan de correcte toepassing van deze verordening. Het AI-bureau en de AI-board beoordelen of de praktijkcodes betrekking hebben op de verplichtingen van de artikelen 53 en 55, en monitoren en evalueren regelmatig of de doelstellingen daarvan worden verwezenlijkt. Zij maken hun beoordeling of de praktijkcodes toereikend zijn bekend.<br>
De Commissie kan door middel van een uitvoeringshandeling een praktijkcode goedkeuren en deze binnen de Unie een algemene geldigheid verlenen. Die uitvoeringshandeling wordt vastgesteld volgens de in artikel 98, lid 2, bedoelde onderzoeksprocedure.
<br>Het AI-bureau kan alle aanbieders van AI-modellen voor algemene doeleinden uitnodigen zich aan de praktijkcodes te houden. Voor aanbieders van AI-modellen voor algemene doeleinden die geen systeemrisico’s inhouden, kan deze naleving worden beperkt tot de verplichtingen van artikel 53, tenzij zij uitdrukkelijk verklaren dat zij belangstelling hebben om zich bij de volledige code aan te sluiten.
<br>Het AI-bureau stimuleert en faciliteert in voorkomend geval ook de evaluatie en aanpassing van de praktijkcodes, met name wanneer er nieuwe normen worden ingesteld. Het AI-bureau helpt bij de beoordeling van de beschikbare normen.
<br>De praktijkcodes moeten uiterlijk op 2 mei 2025 gereed zijn. Het AI-bureau neemt de nodige stappen, met inbegrip van het uitnodigen van aanbieders op grond van lid 7.<br>
Als er uiterlijk op 2 augustus 2025 nog geen praktijkcode tot stand is gebracht, of indien het AI-bureau deze na zijn beoordeling uit hoofde van lid 6 van dit artikel ontoereikend acht, kan de Commissie door middel van uitvoeringshandelingen gemeenschappelijke regels vaststellen voor de uitvoering van de verplichtingen waarin de artikelen 53 en 55 voorzien, met inbegrip van de in lid 2 van dit artikel genoemde zaken. Die uitvoeringshandelingen worden vastgesteld volgens de in artikel 98, lid 2, bedoelde onderzoeksprocedure.
]]></description><link>hoofdstukken/hoofdstuk_5.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_5.md</guid><pubDate>Tue, 13 Aug 2024 13:38:19 GMT</pubDate></item><item><title><![CDATA[hoofdstuk_6]]></title><description><![CDATA[ 
 <br>HOOFDSTUK VI<br>
MAATREGELEN TER ONDERSTEUNING VAN INNOVATIE<br><br>
<br>De lidstaten zorgen ervoor dat hun bevoegde autoriteiten ten minste één AI-testomgeving voor regelgeving op nationaal niveau opzetten, die uiterlijk op 2 augustus 2026 operationeel is. Die testomgeving kan ook samen met de bevoegde autoriteiten van andere lidstaten worden opgezet. De Commissie kan technische ondersteuning, advies en instrumenten verstrekken voor de oprichting en werking van AI-testomgevingen voor regelgeving.<br>
Aan de verplichting uit hoofde van de eerste alinea kan ook worden voldaan door deel te nemen aan een bestaande testomgeving, voor zover die deelname de deelnemende lidstaten een gelijkwaardig niveau van nationale dekking biedt.
<br>Er kunnen ook aanvullende AI-testomgevingen voor regelgeving worden ontwikkeld op regionaal of lokaal niveau of samen met de bevoegde autoriteiten van andere lidstaten.
<br>De Europese Toezichthouder voor gegevensbescherming kan ook een AI-testomgeving voor regelgeving opzetten voor de instellingen, organen en instanties van de Unie, en kan de rollen en taken van de nationale bevoegde autoriteiten overeenkomstig dit hoofdstuk uitoefenen.
<br>De lidstaten zorgen ervoor dat de in de leden 1 en 2 bedoelde bevoegde autoriteiten voldoende middelen toewijzen om doeltreffend en tijdig aan dit artikel te voldoen. In voorkomend geval werken de nationale bevoegde autoriteiten samen met andere relevante autoriteiten en kunnen zij de betrokkenheid van andere actoren binnen het AI-ecosysteem toestaan. Dit artikel heeft geen gevolgen voor andere testomgevingen voor regelgeving die zijn ingesteld op grond van het nationale of Unierecht. De lidstaten zorgen ervoor dat de autoriteiten die toezicht houden op die andere testomgevingen en de nationale bevoegde autoriteiten voldoende met elkaar samenwerken.
<br>Uit hoofde van lid 1 opgerichte AI-testomgevingen voor regelgeving voorzien in een gecontroleerde omgeving ter bevordering van innovatie en ter vergemakkelijking van het ontwikkelen, trainen, testen en valideren van innovatieve AI-systemen, volgens een specifiek, tussen de aanbieders of potentiële aanbieders en de bevoegde autoriteit overeengekomen testomgevingsplan, voor een beperkte duur voordat zij in de handel worden gebracht of in gebruik worden gesteld. Dergelijke testomgevingen kunnen inhouden dat er onder reële omstandigheden wordt getest onder toezicht binnen de testomgeving.
<br>De bevoegde autoriteiten verstrekken in voorkomend geval begeleiding, toezicht en ondersteuning binnen de AI-testomgeving voor regelgeving met als doel om risico’s in kaart te brengen, met name met betrekking tot de grondrechten, gezondheid en veiligheid, alsook het testen en beperkende maatregelen, en de doeltreffendheid daarvan met betrekking tot de verplichtingen en eisen van deze verordening, en, in voorkomend geval, ander Unie- en nationaal recht onder toezicht binnen de testomgeving.
<br>De bevoegde autoriteiten begeleiden aanbieders en potentiële aanbieders die deelnemen aan de AI-testomgeving voor regelgeving met betrekking tot verwachtingen die voortvloeien uit de regelgeving en de wijze waarop aan de in deze verordening vastgestelde eisen en verplichtingen moet worden voldaan.<br>
Op verzoek van de aanbieder of potentiële aanbieder van het AI-systeem verstrekt de bevoegde autoriteit een schriftelijk bewijs van de met succes in de testomgeving uitgevoerde activiteiten. De bevoegde autoriteit verstrekt ook een eindverslag waarin de in de testomgeving uitgevoerde activiteiten en de daarmee verband houdende resultaten en leerresultaten worden beschreven. Aanbieders kunnen dergelijke documentatie gebruiken om bij het conformiteitsbeoordelingsproces of relevante markttoezicht-activiteiten aan te tonen dat zij aan deze verordening voldoen. In dit verband houden markttoezichtautoriteiten en aangemelde instanties op een positieve manier rekening met de eindverslagen en de schriftelijke bewijzen die door de nationale bevoegde autoriteit worden verstrekt, teneinde de conformiteitsbeoordelingsprocedures in een redelijke mate te versnellen.
<br>Met inachtneming van de vertrouwelijkheidsbepalingen van artikel 78 en met instemming van de aanbieder of potentiële aanbieder zijn de Commissie en de AI-board gemachtigd om toegang te krijgen tot de eindverslagen en houden zij er in voorkomend geval rekening mee bij de uitoefening van hun taken uit hoofde van deze verordening. Indien zowel de aanbieder of potentiële aanbieder als de nationale bevoegde autoriteit uitdrukkelijk instemmen, mag het eindverslag openbaar worden gemaakt via het in dit artikel bedoelde centrale informatieplatform.
<br>Het opzetten van AI-testomgevingen voor regelgeving is erop gericht bij te dragen aan de volgende doelstellingen:<br>
a) het verbeteren van de rechtszekerheid met betrekking tot het bereiken van naleving van deze verordening of, in voorkomend geval, van ander toepasselijk Unie- en nationaal recht;<br>
b) ondersteunen van de uitwisseling van beste praktijken door middel van samenwerking met de autoriteiten die betrokken zijn bij de AI-testomgeving voor regelgeving;<br>
c) bevorderen van innovatie en concurrentievermogen en faciliteren van de ontwikkeling van een AI-ecosysteem;<br>
d) bijdragen aan empirisch onderbouwd leren op het gebied van regelgeving;<br>
e) vergemakkelijken en versnellen van de toegang tot de markt van de Unie voor AI-systemen, met name wanneer ze worden aangeboden door kmo's, met inbegrip van start-ups.
<br>De nationale bevoegde autoriteiten zorgen ervoor dat voor zover de innovatieve AI-systemen betrekking hebben op de verwerking van persoonsgegevens of anderszins onder het toezicht van andere nationale autoriteiten of bevoegde autoriteiten vallen die toegang tot gegevens verstrekken of ondersteunen, de nationale gegevensbeschermingsautoriteiten en die andere nationale of bevoegde autoriteiten betrokken zijn bij de werking van de AI-testomgeving voor regelgeving en bij het toezicht op de aspecten die onder hun respectieve taken en bevoegdheden vallen.
<br>De AI-testomgevingen voor regelgeving laten de toezichthoudende of corrigerende bevoegdheden van de bevoegde autoriteiten die toezicht houden binnen de testomgevingen onverlet, ook op regionaal of lokaal niveau. Significante risico’s voor de gezondheid en veiligheid en de grondrechten die tijdens het ontwikkelen en testen van dergelijke AI-systemen worden vastgesteld, worden op adequate wijze beperkt. De nationale bevoegde autoriteiten hebben de bevoegdheid om het testproces of de deelname aan de testomgeving tijdelijk of permanent op te schorten indien doeltreffende beperkende maatregelen niet mogelijk zijn, en zij stellen het AI-bureau van een dergelijk besluit in kennis. De nationale bevoegde autoriteiten oefenen hun toezichtsbevoegdheden binnen de grenzen van het toepasselijk recht uit, waarbij zij gebruikmaken van hun discretionaire bevoegdheden bij de uitvoering van wettelijke bepalingen met betrekking tot een specifiek project inzake een AI-testomgeving voor regelgeving, met als doel innovatie op het gebied van AI in de Unie te ondersteunen.
<br>Aanbieders en potentiële aanbieders die deelnemen aan de AI-testomgeving voor regelgeving blijven aansprakelijk uit hoofde van het toepasselijke Unie- en nationale aansprakelijkheidsrecht voor aan derden toegebrachte schade als gevolg van de experimenten in de testomgeving. Als de potentiële aanbieders echter het specifieke plan alsmede de voorwaarden voor hun deelname eerbiedigen en zich te goeder trouw houden aan de richtsnoeren van de nationale bevoegde autoriteit, leggen de autoriteiten geen administratieve boetes op voor de schending van deze verordening. Wanneer andere bevoegde autoriteiten die verantwoordelijk zijn voor ander Unierecht en nationaal recht actief betrokken waren bij het toezicht op het AI-systeem in de testomgeving en richtsnoeren voor naleving hebben verstrekt, worden met betrekking tot dat recht geen administratieve geldboetes opgelegd.
<br>De AI-testomgevingen voor regelgeving worden zodanig ontworpen en uitgevoerd dat zij desgevallend de grensoverschrijdende samenwerking tussen nationale bevoegde autoriteiten vergemakkelijken.
<br>De nationale bevoegde autoriteiten coördineren hun activiteiten en werken samen binnen het kader van de AI-board.
<br>De nationale bevoegde autoriteiten stellen het AI-bureau en de AI-board in kennis van de oprichting van een testomgeving en kunnen hen om ondersteuning en begeleiding verzoeken. Er wordt door het AI-bureau een lijst van geplande en bestaande testomgevingen openbaar gemaakt en up-to-date gehouden om meer interactie in de AI-testomgevingen voor regelgeving en grensoverschrijdende samenwerking aan te moedigen.
<br>De nationale bevoegde autoriteiten dienen vanaf één jaar na de oprichting van de AI-testomgeving voor regelgeving en vervolgens elk jaar tot de beëindiging ervan, bij het AI-bureau en de AI-board jaarverslagen in, alsook een afsluitend verslag. In deze verslagen wordt informatie verstrekt over de vooruitgang en de resultaten met betrekking tot de uitvoering van die testomgevingen, met inbegrip van goede praktijken, incidenten, geleerde lessen en aanbevelingen over de opzet ervan en, waar relevant, over de toepassing en mogelijke herziening van deze verordening, met inbegrip van de gedelegeerde en uitvoeringshandelingen daarvan, en over de toepassing van andere regelgeving van de Unie onder toezicht van de bevoegde autoriteiten binnen de testomgeving. De nationale bevoegde autoriteiten stellen die jaarverslagen of de samenvattingen daarvan online beschikbaar voor het publiek. De Commissie houdt in voorkomend geval rekening met de jaarverslagen bij de uitoefening van haar taken uit hoofde van deze verordening.
<br>De Commissie ontwikkelt één specifieke interface met alle relevante informatie over AI-testomgevingen voor regelgeving waar belanghebbenden kunnen te communiceren met de AI-testomgevingen voor regelgeving, vragen kunnen stellen aan de bevoegde autoriteiten en niet-bindend advies kunnen krijgen over de conformiteit van innovatieve producten, diensten of bedrijfsmodellen waarin AI-technologieën zijn verwerkt, in overeenstemming met artikel 62, lid 1, punt c). De Commissie draagt in voorkomend geval zorg voor proactieve coördinatie met de nationale bevoegde autoriteiten.
<br><br>
<br>Om versnippering in de Unie te voorkomen, stelt de Commissie uitvoeringshandelingen vast waarin de gedetailleerde regelingen worden gespecificeerd voor de instelling, de ontwikkeling, de uitvoering en de werking van AI-testomgevingen voor regelgeving en voor het toezicht erop. De uitvoeringshandelingen bevatten gemeenschappelijke beginselen met betrekking tot de volgende punten:<br>
a) toelatings- en selectiecriteria voor deelname aan de AI-testomgeving voor regelgeving;<br>
b) procedures voor de toepassing, deelname, monitoring, uittreding uit en beëindiging van de AI-testomgeving voor regelgeving, met inbegrip van het testomgevingsplan en het eindverslag;<br>
c) de voor de deelnemers geldende voorwaarden.<br>
Die uitvoeringshandelingen worden vastgesteld volgens de in artikel 98, lid 2, bedoelde onderzoeksprocedure.
<br>De in lid 1 bedoelde uitvoeringshandelingen waarborgen dat:<br>
a) AI-testomgevingen voor regelgeving open staan voor elke aanbieder of potentiële aanbieder van een AI-systeem die voldoet aan de toelatings- en selectiecriteria, die transparant en eerlijk moeten zijn, en dat de nationale bevoegde autoriteiten aanvragers binnen drie maanden na de aanvraag in kennis stellen van hun besluit;<br>
b) AI-testomgevingen voor regelgeving brede en gelijke toegang bieden en de vraag om toestemming voor deelname aankunnen; aanbieders en potentiële aanbieders ook aanvragen kunnen indienen in samenwerking met gebruiksverantwoordelijken en andere relevante derden;<br>
c) de gedetailleerde regelingen en voorwaarden voor AI-testomgevingen voor regelgeving zo veel mogelijk flexibiliteit bieden voor nationale bevoegde autoriteiten om hun AI-testomgevingen voor regelgeving op te richten en te exploiteren;<br>
d) de toegang tot de AI-testomgevingen voor regelgeving voor kmo’s, waaronder start-ups, kosteloos is, onverminderd uitzonderlijke kosten die de nationale bevoegde autoriteiten op billijke en evenredige wijze mogen verhalen;<br>
e) zij het voor aanbieders en potentiële aanbieders, door middel van de leerresultaten van de AI-testomgevingen voor regelgeving, vergemakkelijken om de conformiteitsbeoordelingsverplichtingen uit hoofde van deze verordening na te komen en de in artikel 95 bedoelde gedragscodes vrijwillig toe te passen;<br>
f) AI-testomgevingen voor regelgeving de betrokkenheid vergemakkelijken van andere relevante actoren binnen het AI-ecosysteem, zoals aangemelde instanties en normalisatieorganisaties, kmo’s, met inbegrip van start-ups, ondernemingen, innovatoren, test- en experimenteerfaciliteiten, onderzoeks- en testlaboratoria en Europese digitale-innovatiehubs, kenniscentra en individuele onderzoekers, teneinde samenwerking met de publieke en particuliere sectoren mogelijk te maken en te vergemakkelijken;<br>
g) de procedures, processen en administratieve eisen voor de aanvraag, de selectie, de deelname en het vertrek uit de AI-testomgeving voor regelgeving eenvoudig en gemakkelijk te begrijpen zijn en duidelijk worden gecommuniceerd, om de deelname van kmo’s, waaronder start-ups, met beperkte juridische en administratieve capaciteiten te vergemakkelijken, en in de hele Unie worden gestroomlijnd, om versnippering te voorkomen, en dat de deelname aan een door een lidstaat of de Europese Toezichthouder voor gegevensbescherming opgerichte AI-testomgeving voor regelgeving wederzijds en uniform wordt erkend en in de hele Unie dezelfde rechtsgevolgen heeft;<br>
h) de deelname aan de AI-testomgeving voor regelgeving beperkt wordt tot een termijn die passend is gezien de complexiteit en de omvang van het project, en die door de nationale bevoegde autoriteit kan worden verlengd;<br>
i) AI-testomgevingen voor regelgeving de ontwikkeling bevorderen van instrumenten en infrastructuur voor het testen, benchmarken, beoordelen en verklaren van de voor leren op regelgevingsgebied relevante aspecten van AI-systemen, zoals nauwkeurigheid, robuustheid en cyberbeveiliging, alsook minimalisering van de risico’s voor de grondrechten, het milieu en de maatschappij in het algemeen.
<br>Potentiële aanbieders in de AI-testomgevingen voor regelgeving, met name kmo’s en start-ups, worden, indien van toepassing, gewezen op diensten die aan het inzetten voorafgaan, zoals begeleiding bij de uitvoering van deze verordening, op andere diensten die waarde toevoegen, zoals hulp bij normalisatiedocumenten en certificering, test- en experimenteervoorzieningen, Europese digitale-innovatiehubs en kenniscentra.
<br>Indien nationale bevoegde autoriteiten overwegen toestemming te geven voor het testen onder reële omstandigheden, onder toezicht in het kader van een op grond van dit artikel op te richten AI-testomgeving voor regelgeving, komen zij specifiek met de deelnemers de voorwaarden voor die tests overeen, en met name de passende waarborgen ter bescherming van de grondrechten, de gezondheid en de veiligheid. In voorkomend geval werken zij samen met andere nationale bevoegde autoriteiten om de praktijken in de hele Unie consistent te houden.
<br><br>
<br>In de aI-testomgeving voor regelgeving mogen rechtmatig voor andere doeleinden verzamelde persoonsgegevens uitsluitend worden verwerkt ten behoeve van het ontwikkelen, trainen en testen van bepaalde AI-systemen in de testomgeving indien aan alle volgende voorwaarden is voldaan:<br>
a) Er worden AI-systemen ontwikkeld zodat een overheidsinstantie of een andere natuurlijke of rechtspersoon een aanzienlijk openbaar belang kan waarborgen op een of meer van de volgende gebieden:<br>
i) openbare veiligheid en volksgezondheid, met inbegrip van opsporing, diagnosticering, preventie, bestrijding en behandeling van ziekten en verbetering van gezondheidszorgstelsels;<br>
ii) een hoog niveau van bescherming en verbetering van de kwaliteit van het milieu, bescherming van de biodiversiteit, bescherming tegen vervuiling, maatregelen voor de groene transitie en maatregelen ter beperking van en aanpassing aan klimaatverandering;<br>
iii)<br>
energieduurzaamheid;<br>
iv) de veiligheid en veerkracht van vervoerssystemen en mobiliteit, kritieke vervoersinfrastructuur en vervoersnetwerken;<br>
v) doeltreffendheid en kwaliteit van het openbaar bestuur en de openbare diensten;<br>
b) de verwerkte data zijn nodig om te voldoen aan een of meer van de in hoofdstuk III, afdeling 2, bedoelde eisen wanneer die eisen niet doeltreffend kunnen worden vervuld door het verwerken van geanonimiseerde, synthetische of andere niet persoonsgebonden data;<br>
c) er zijn doeltreffende monitoringmechanismen om vast te stellen of zich tijdens de experimenten in de testomgeving hoge risico’s voor de rechten en vrijheden van de betrokkenen als bedoeld in artikel 35 van Verordening (EU) 2016/679 en in artikel 39 van Verordening (EU) 2018/1725 kunnen voordoen evenals responsmechanismen om die risico’s onmiddellijk te beperken en indien nodig de verwerking stop te zetten;<br>
d) in het kader van de testomgeving te verwerken persoonsgegevens bevinden zich in een functioneel gescheiden, geïsoleerde en beschermde omgeving voor dataverwerking onder de controle van de potentiële aanbieder, waarbij alleen bevoegde personen toegang hebben tot deze data;<br>
e) aanbieders kunnen de oorspronkelijk verzamelde gegevens alleen verder delen in overeenstemming met het Unierecht inzake gegevensbescherming; persoonsgegevens die in de testomgeving worden aangemaakt mogen niet buiten de testomgeving worden gedeeld;<br>
f) de verwerking van persoonsgegevens in het kader van de testomgeving mag niet leiden tot maatregelen of besluiten die gevolgen hebben voor de betrokkenen, noch gevolgen hebben voor de toepassing van hun rechten die zijn vastgelegd in het Unierecht inzake de bescherming van persoonsgegevens;<br>
g) in het kader van de testomgeving verwerkte persoonsgegevens worden beschermd met passende technische en organisatorische maatregelen en worden gewist nadat de deelname aan de testomgeving is beëindigd of de periode van bewaring van de persoonsgegevens ten einde is gekomen;<br>
h) de logbestanden van de verwerking van persoonsgegevens in het kader van de testomgeving worden bijgehouden voor de duur van de deelname aan de testomgeving, tenzij anders is bepaald in het Unierecht of het nationale recht;<br>
i) een volledige en gedetailleerde beschrijving van het proces en de onderbouwing van het trainen, testen en valideren van het AI-systeem wordt samen met de testresultaten bewaard als onderdeel van de in bijlage IV bedoelde technische documentatie;<br>
j) een korte samenvatting van het in de testomgeving ontwikkelde AI-project en de doelstellingen en verwachte resultaten ervan worden op de website van de bevoegde autoriteiten gepubliceerd; deze verplichting heeft geen betrekking op gevoelige operationele gegevens in verband met de activiteiten van rechtshandhavingsinstanties en grenstoezichts-, immigratie- of asielautoriteiten.
<br>Met het oog op de voorkoming, het onderzoek, de opsporing en de vervolging van strafbare feiten of de tenuitvoerlegging van straffen, met inbegrip van de bescherming tegen en de voorkoming van bedreigingen voor de openbare veiligheid, onder de controle en de verantwoordelijkheid van rechtshandhavingsinstanties, is de verwerking van persoonsgegevens in AI-testomgevingen voor regelgeving gebaseerd op specifiek Unie- of nationaal recht en onderworpen aan dezelfde cumulatieve voorwaarden als bedoeld in lid 1.
<br>Lid 1 doet geen afbreuk aan het Unie- of nationale recht waarin verwerking voor andere doeleinden dan die uitdrukkelijk vermeld in die wetgeving wordt uitgesloten, noch aan het Unie- of nationale recht tot vaststelling van de grondslag voor de verwerking van persoonsgegevens die noodzakelijk is voor het ontwikkelen, testen of trainen van innovatieve AI-systemen of een andere rechtsgrondslag, met naleving van het Unierecht inzake de bescherming van persoonsgegevens.
<br><br>
<br>AI-systemen met een hoog risico kunnen onder reële omstandigheden buiten AI-testomgevingen voor regelgeving worden getest door aanbieders of potentiële aanbieders van in bijlage III vermelde AI-systemen met een hoog risico in overeenstemming met dit artikel en het in dit artikel bedoelde plan voor tests onder reële omstandigheden, onverminderd de verbodsbepalingen krachtens artikel 5.<br>
De Commissie specificeert, door middel van uitvoeringshandelingen, de precieze onderdelen van het plan voor tests onder reële omstandigheden. Die uitvoeringshandelingen worden vastgesteld volgens de in artikel 98, lid 2, bedoelde onderzoeksprocedure.<br>
Dit lid doet geen afbreuk aan Unie- of nationale wetgeving voor het testen onder reële omstandigheden van AI-systemen met een hoog risico die verband houden met producten die onder de in bijlage I vermelde harmonisatiewetgeving van de Unie vallen.
<br>Aanbieders of potentiële aanbieders kunnen zelf of in samenwerking met een of meer gebruiksverantwoordelijken of potentiële gebruiksverantwoordelijken onder reële omstandigheden tests uitvoeren op in bijlage III bedoelde AI-systemen met een hoog risico op elk moment vóór het in de handel brengen of in gebruik nemen van het AI-systeem.
<br>Het testen van AI-systemen met een hoog risico onder reële omstandigheden uit hoofde van dit artikel doet geen afbreuk aan de ethische toetsing die op grond van het Unie- of nationale recht is vereist.
<br>Aanbieders of potentiële aanbieders mogen alleen testen onder reële omstandigheden als is voldaan aan alle volgende voorwaarden:<br>
a) de aanbieder of potentiële aanbieder heeft een plan voor tests onder reële omstandigheden opgesteld en ingediend bij de markttoezichtautoriteit in de lidstaat waar onder reële omstandigheden moet worden getest;<br>
b) de markttoezichtautoriteit in de lidstaat waar onder reële omstandigheden moet worden getest, heeft het testen onder reële omstandigheden en het plan voor tests onder reële omstandigheden goedgekeurd; indien de markttoezichtautoriteit binnen dertig dagen geen antwoord heeft gegeven, worden het testen onder reële omstandigheden en het plan voor tests onder reële omstandigheden geacht te zijn goedgekeurd; indien het nationale recht niet voorziet in een stilzwijgende goedkeuring, blijft het testen onder reële omstandigheden onderworpen aan een toestemming;<br>
c) de aanbieder of potentiële aanbieder, met uitzondering van aanbieders of potentiële aanbieders van in de punten 1, 6 en 7 van bijlage III bedoelde AI-systemen met een hoog risico op de gebieden rechtshandhaving, migratie, asiel en grenstoezichtsbeheer en AI-systemen met een hoog risico als bedoeld in punt 2 van bijlage III, heeft het testen onder reële omstandigheden geregistreerd overeenkomstig artikel 71, lid 4, met een Uniebreed uniek identificatienummer en de in bijlage IX gespecificeerde informatie; de aanbieder of potentiële aanbieder van in de punten 1, 6 en 7 van bijlage III bedoelde AI-systemen met een hoog risico op de gebieden van rechtshandhaving, migratie, asiel en grenstoezichtsbeheer, heeft het testen onder reële omstandigheden geregistreerd in het beveiligde niet-openbare gedeelte van de EU-databank overeenkomstig artikel 49, lid 4, punt d), met een Uniebreed uniek identificatienummer en de daarin gespecificeerde informatie; de aanbieder of potentiële aanbieder van in punt 2 van bijlage III bedoelde AI-systemen met een hoog risico heeft het testen onder reële omstandigheden geregistreerd overeenkomstig artikel 49, lid 5;<br>
d) de aanbieder of potentiële aanbieder die onder reële omstandigheden test, is in de Unie gevestigd of heeft een in de Unie gevestigde wettelijke vertegenwoordiger aangewezen;<br>
e) gegevens die zijn verzameld en verwerkt met het oog op het testen onder reële omstandigheden mogen alleen aan derde landen worden doorgegeven mits er passende en toepasselijke waarborgen uit hoofde van het Unierecht worden toegepast;<br>
f) het testen onder reële omstandigheden duurt niet langer dan nodig is om de doelstellingen ervan te verwezenlijken en in geen geval langer dan zes maanden, met een mogelijke verlenging van nog eens zes maanden indien de aanbieder of potentiële aanbieder de markttoezichtautoriteit daar vooraf van in kennis stelt, met een uitleg waarom een dergelijke verlenging noodzakelijk is;<br>
g) proefpersonen die onder reële omstandigheden worden getest en die tot kwetsbare groepen behoren vanwege hun leeftijd of handicap, worden naar behoren beschermd;<br>
h) indien een aanbieder of potentiële aanbieder het testen onder reële omstandigheden organiseert in samenwerking met een of meer gebruiksverantwoordelijken of potentiële gebruiksverantwoordelijken, worden zij geïnformeerd over alle aspecten van het testen die relevant zijn voor hun beslissing om deel te nemen, en krijgen zij de relevante gebruiksinstructies van het AI-systeem als bedoeld in artikel 13; de aanbieder of potentiële aanbieder en de gebruiksverantwoordelijke of potentiële gebruiksverantwoordelijke sluiten een overeenkomst waarin hun taken en verantwoordelijkheden worden gespecificeerd teneinde te waarborgen dat de bepalingen voor het testen onder reële omstandigheden uit hoofde van deze verordening en ander toepasselijk Unie- en nationaal recht worden nageleefd;<br>
i) de proefpersonen die onder reële omstandigheden worden getest, hebben geïnformeerde toestemming gegeven overeenkomstig artikel 61, of, in het geval van rechtshandhaving, indien het vragen om geïnformeerde toestemming het testen van het AI-systeem onder reële omstandigheden onmogelijk zou maken, de test zelf en het resultaat van de test onder reële omstandigheden hebben geen negatieve gevolgen voor de proefpersonen en hun persoonsgegevens worden na de uitvoering van test gewist;<br>
j) op het testen onder reële omstandigheden wordt daadwerkelijk toezicht gehouden door de aanbieder of potentiële aanbieder, alsook door gebruiksverantwoordelijken of potentiële gebruiksverantwoordelijken via personen die voldoende zijn gekwalificeerd op het relevante gebied en beschikken over de nodige capaciteiten, opleiding en bevoegdheden om hun taken uit te voeren;<br>
k) de voorspellingen, aanbevelingen of beslissingen van het AI-systeem kunnen daadwerkelijk worden teruggedraaid en genegeerd.
<br>Proefpersonen van het testen onder reële omstandigheden of hun wettelijke vertegenwoordiger, al naargelang het geval, kunnen zich, zonder nadelige gevolgen en zonder enige rechtvaardiging, te allen tijde uit het testen terugtrekken door hun geïnformeerde toestemming in te trekken, waarna zij om de onmiddellijke en permanente verwijdering van hun persoonsgegevens kunnen verzoeken. De intrekking van de geïnformeerde toestemming heeft geen gevolgen voor de reeds uitgevoerde activiteiten.
<br>Overeenkomstig artikel 75 verlenen de lidstaten hun markttoezichtautoriteiten de bevoegdheid om aanbieders en potentiële aanbieders te verplichten informatie te verstrekken, om onaangekondigde inspecties op afstand of ter plaatse uit te voeren en om toezicht te houden op de uitvoering van het testen onder reële omstandigheden en de aanverwante AI-systemen met een hoog risico. Markttoezichtautoriteiten gebruiken deze bevoegdheden om ervoor te zorgen dat het testen onder reële omstandigheden zich veilig kan ontwikkelen.
<br>Elk ernstig incident dat tijdens het testen onder reële omstandigheden wordt vastgesteld, wordt gemeld bij de nationale markttoezichtautoriteit overeenkomstig artikel 73. De aanbieder of potentiële aanbieder neemt onmiddellijke risicobeperkende maatregelen of, bij gebreke daarvan, schorst het testen onder reële omstandigheden totdat dergelijke risicobeperkende maatregelen zijn getroffen, of beëindigt anders het testen. De aanbieder of potentiële aanbieder stelt een procedure vast voor het onmiddellijk terugroepen van het AI-systeem bij een dergelijke beëindiging van het testen onder reële omstandigheden.
<br>Aanbieders of potentiële aanbieders stellen de nationale markttoezichtautoriteit in de lidstaat waar er onder reële omstandigheden moet worden getest, in kennis van de opschorting of beëindiging van het testen onder reële omstandigheden en van de eindresultaten.
<br>De aanbieder of potentiële aanbieder zijn aansprakelijk op grond van het toepasselijke Unie- en nationale aansprakelijkheidsrecht voor schade die tijdens het testen onder reële omstandigheden wordt veroorzaakt.
<br><br>
<br>Met het oog op het testen onder reële omstandigheden overeenkomstig artikel 60 moet van de proefpersonen vrijwillig gegeven geïnformeerde toestemming worden verkregen voorafgaand aan hun deelname aan het testen en nadat zij naar behoren zijn geïnformeerd en beknopte, duidelijke, relevante en begrijpelijke informatie hebben gekregen over:<br>
a) de aard en de doelstellingen van het testen onder reële omstandigheden en de mogelijke ongemakken die verband kunnen houden met hun deelname;<br>
b) de voorwaarden waaronder in reële omstandigheden moet worden getest, met inbegrip van de verwachte duur van de deelname van de proefpersoon of proefpersonen;<br>
c) hun rechten en de garanties met betrekking tot hun deelname, met name hun recht om te weigeren deel te nemen aan, en het recht om zich te allen tijde terug te trekken uit, het testen onder reële omstandigheden zonder daarvan enig nadeel te ondervinden en zonder zich te hoeven rechtvaardigen;<br>
d) de afspraken met betrekking tot het aanvragen van het terugdraaien of negeren van de voorspellingen, aanbevelingen of beslissingen van het AI-systeem;<br>
e) het Uniebrede unieke identificatienummer van het testen onder reële omstandigheden overeenkomstig artikel 60, lid 4, punt c), en de contactgegevens van de aanbieder of zijn wettelijke vertegenwoordiger bij wie nadere informatie kan worden verkregen.
<br>De geïnformeerde toestemming wordt gedateerd en gedocumenteerd en er wordt een kopie verstrekt aan de proefpersonen of hun wettelijke vertegenwoordiger.
<br><br>
<br>De lidstaten ondernemen de volgende acties:<br>
a) kmo's, met inbegrip van start-ups, die een maatschappelijke zetel of een bijkantoor in de Unie hebben, prioritaire toegang verlenen tot de AI-testomgevingen voor regelgeving voor zover zij aan de toelatingsvoorwaarden en selectiecriteria voldoen; de prioritaire toegang sluit niet uit dat andere dan de in dit lid bedoelde kmo’s, met inbegrip van start-ups, toegang krijgen tot de AI-testomgeving voor regelgeving, mits zij ook aan de toelatingsvoorwaarden en selectiecriteria voldoen;<br>
b) specifieke bewustmakings- en opleidingsactiviteiten organiseren over de toepassing van deze verordening, afgestemd op de behoeften van kmo’s, met inbegrip van start-ups, gebruiksverantwoordelijken en, in voorkomend geval, lokale overheidsinstanties;<br>
c) bestaande specifieke communicatiekanalen benutten en, waar passend, nieuwe opzetten voor communicatie met kmo’s, met inbegrip van start-ups, gebruiksverantwoordelijken, andere innovatoren en, in voorkomend geval, lokale overheidsinstanties, om advies te verstrekken en te reageren op vragen over de uitvoering van deze verordening, onder meer met betrekking tot deelname aan AI-testomgevingen voor regelgeving;<br>
d) de deelname van kmo’s en andere relevante belanghebbenden aan het proces voor de ontwikkeling van normen faciliteren.
<br>De specifieke belangen en behoeften van aanbieders die kmo’s zijn, met inbegrip van start-ups, worden in aanmerking genomen bij het bepalen van de vergoedingen voor conformiteitsbeoordelingen krachtens artikel 43, waarbij die vergoedingen naar evenredigheid van hun omvang, de omvang van de markt en andere relevante indicatoren worden verlaagd.
<br>Het AI-bureau onderneemt de volgende acties:<br>
a) het verstrekken van gestandaardiseerde sjablonen voor de gebieden die onder deze verordening vallen, zoals gespecificeerd door de AI-board in zijn verzoek;<br>
b) het ontwikkelen en in stand houden van een centraal informatieplatform dat gemakkelijk te gebruiken informatie met betrekking tot deze verordening biedt aan alle operatoren in de hele Unie;<br>
c) het organiseren van passende voorlichtingscampagnes om meer bekendheid te geven aan de uit deze verordening voortvloeiende verplichtingen;<br>
d) het evalueren en bevorderen van de convergentie van beste praktijken bij openbare aanbestedingsprocedures met betrekking tot AI-systemen.
<br><br>
<br>Micro-ondernemingen in de zin van Aanbeveling 2003/361/EG kunnen op vereenvoudigde wijze voldoen aan bepaalde elementen van het bij artikel 17 van deze verordening vereiste systeem voor kwaliteitsbeheer, mits zij geen partnerondernemingen of verbonden ondernemingen in de zin van die aanbeveling hebben. Daartoe ontwikkelt de Commissie richtsnoeren over de elementen van het systeem voor kwaliteitsbeheer waaraan op vereenvoudigde wijze kan worden voldaan, rekening houdend met de behoeften van micro-ondernemingen, zonder afbreuk te doen aan het beschermingsniveau of de noodzaak om de verplichtingen voor AI-systemen met een hoog risico na te leven.
<br>Lid 1 van dit artikel wordt niet zodanig geïnterpreteerd dat die operatoren worden vrijgesteld van de naleving van andere in deze verordening vastgelegde eisen of verplichtingen, met inbegrip van die welke zijn vastgelegd in de artikelen 9, 10, 11, 12, 13, 14, 15, 72 en 73.
]]></description><link>hoofdstukken/hoofdstuk_6.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_6.md</guid><pubDate>Tue, 13 Aug 2024 13:38:23 GMT</pubDate></item><item><title><![CDATA[hoofdstuk_7]]></title><description><![CDATA[ 
 <br>HOOFDSTUK VII<br>
GOVERNANCE<br>
AFDELING 1<br>
Governance op Unieniveau<br><br>
<br>De Commissie ontwikkelt deskundigheid en capaciteiten op Unieniveau op het gebied van AI via het AI-bureau.
<br>De lidstaten faciliteren de aan het AI-bureau toevertrouwde taken, zoals weergegeven in deze verordening.
<br><br>
<br>Hierbij wordt een Europese raad voor artificiële intelligentie (European Artificial Intelligence Board — de “AI-board”) opgericht.
<br>De AI-board bestaat uit één vertegenwoordiger per lidstaat. De Europese Toezichthouder voor gegevensbescherming neemt deel als waarnemer. Het AI-bureau woont ook de vergaderingen van de AI-board bij zonder aan de stemmingen deel te nemen. De AI-board kan per geval andere autoriteiten, organen of deskundigen van de lidstaten en de Unie voor de vergaderingen uitnodigen, indien de besproken zaken voor hen van belang zijn.
<br>Elke vertegenwoordiger wordt door zijn lidstaat aangewezen voor een periode van drie jaar, die eenmaal kan worden verlengd.
<br>De lidstaten zorgen ervoor dat hun vertegenwoordigers in de AI-board:<br>
a) in hun lidstaat over de toepasselijke bevoegdheden beschikken om actief bij te dragen tot de vervulling van de in artikel 66 genoemde taken van de AI-board;<br>
b) worden aangewezen als één contactpunt voor de AI-board en, in voorkomend geval, rekening houdend met de behoeften van de lidstaten, als één contactpunt voor belanghebbenden;<br>
c) bevoegd zijn om de samenhang en coördinatie tussen de nationale bevoegde autoriteiten in hun lidstaat met betrekking tot de uitvoering van deze verordening te vergemakkelijken, onder meer door het verzamelen van relevante gegevens en informatie met het oog op de vervulling van hun taken in de AI-board.
<br>De aangewezen vertegenwoordigers van de lidstaten stellen het reglement van orde van de AI-board met een tweederdemeerderheid vast. In het reglement van orde worden met name procedures vastgelegd voor de selectieprocedure, de duur van het mandaat van en de specificaties van de taken van de voorzitter, gedetailleerde stemprocedures en de organisatie van de activiteiten van de AI-board en van zijn subgroepen.
<br>De AI-board richt twee permanente subgroepen op om een platform te bieden voor samenwerking en uitwisseling tussen markttoezichtautoriteiten en aanmeldende autoriteiten over kwesties betreffende respectievelijk markttoezicht en aangemelde instanties.<br>
De permanente subgroep voor markttoezicht moet fungeren als de administratieve-samenwerkingsgroep (ADCO) voor deze verordening in de zin van artikel 30 van Verordening (EU) 2019/1020.<br>
De AI-board kan in voorkomend geval andere permanente of tijdelijke subgroepen oprichten om specifieke kwesties te onderzoeken. In voorkomend geval kunnen vertegenwoordigers van het in artikel 67 bedoelde adviesforum als waarnemer worden uitgenodigd voor dergelijke subgroepen of voor specifieke vergaderingen van die subgroepen.
<br>De AI-board is zodanig georganiseerd en functioneert zodanig dat de objectiviteit en onpartijdigheid van zijn activiteiten gewaarborgd zijn.
<br>De AI-board wordt voorgezeten door een van de vertegenwoordigers van de lidstaten. Het AI-bureau verzorgt het secretariaat van de AI-board, roept op verzoek van de voorzitter de vergaderingen bijeen en stelt de agenda op overeenkomstig de taken van de AI-board krachtens deze verordening en overeenkomstig zijn reglement.
<br><br>De AI-board adviseert en assisteert de Commissie en de lidstaten teneinde de consistente en doeltreffende toepassing van deze verordening te vergemakkelijken. Daartoe kan de AI-board met name:<br>
a) bijdragen aan de coördinatie tussen de nationale bevoegde autoriteiten die verantwoordelijk zijn voor de toepassing van deze verordening en, in samenwerking met en met instemming van de betrokken markttoezichtautoriteiten, de in artikel 74, lid 11, bedoelde gezamenlijke activiteiten van de markttoezichtautoriteiten ondersteunen;<br>
b) technische en regelgevingsexpertise en beste praktijken onder de lidstaten verzamelen en delen;<br>
c) advies verstrekken over de uitvoering van deze verordening, met name wat betreft de handhaving van de regels inzake AI-modellen voor algemene doeleinden;<br>
d) bijdragen tot de harmonisatie van de administratieve praktijken in de lidstaten, onder meer met betrekking tot de in artikel 46 bedoelde afwijking van de conformiteits-beoordelingsprocedures, de werking van AI-testomgevingen voor regelgeving en het testen onder reële omstandigheden als bedoeld in de artikelen 57, 59 en 60;<br>
e) op verzoek van de Commissie of op eigen initiatief aanbevelingen en schriftelijke adviezen uitbrengen over alle relevante aangelegenheden in verband met de uitvoering van deze verordening en de consistente en doeltreffende toepassing ervan, waaronder:<br>
i) over de ontwikkeling en toepassing van praktijkcodes en praktijkcodes op grond van deze verordening, alsmede van de richtsnoeren van de Commissie;<br>
ii) over de evaluatie en toetsing van deze verordening op grond van artikel 112, onder meer met betrekking tot de in artikel 73 bedoelde meldingen van ernstige incidenten en de werking van de in artikel 71 bedoelde EU-databank, de voorbereiding van de gedelegeerde of uitvoeringshandelingen, en met betrekking tot mogelijke afstemming van deze verordening op de in bijlage I vermelde harmonisatiewetgeving van de Unie;<br>
iii)<br>
over technische specificaties of bestaande normen ten aanzien van de in hoofdstuk III, afdeling 2, beschreven eisen;<br>
iv) over het gebruik van geharmoniseerde normen of gemeenschappelijke specificaties als bedoeld in de artikelen 40 en 41;<br>
v) over trends, bijvoorbeeld met betrekking tot het Europese mondiale concurrentievermogen op het gebied van AI, de invoering van AI in de Unie en de ontwikkeling van digitale vaardigheden;<br>
vi) over trends met betrekking tot de steeds veranderende typologie van AI-waardeketens, met name wat de daaruit voortvloeiende gevolgen voor de verantwoordingsplicht betreft;<br>
vii)<br>
over de eventuele noodzaak van een wijziging van bijlage III overeenkomstig artikel 7, en over de eventuele noodzaak van een mogelijke herziening van artikel 5 op grond van artikel 112, rekening houdend met de op dat gebied beschikbare gegevens en de meest recente technologische ontwikkelingen;<br>
f) de Commissie ondersteunen bij het promoten van AI-geletterdheid en het brede publiek beter bekendmaken met en meer inzicht verschaffen in de voordelen, de risico’s, de waarborgen en de rechten en plichten in verband met het gebruik van AI-systemen;<br>
g) de ontwikkeling bevorderen van gemeenschappelijke criteria en een gedeeld begrip tussen marktdeelnemers en bevoegde autoriteiten met betrekking tot de relevante concepten waarin deze verordening voorziet, onder meer door bij te dragen aan de ontwikkeling van benchmarks;<br>
h) waar passend samenwerken met andere instellingen, organen en instanties van de Unie, alsook relevante deskundigengroepen en -netwerken van de Unie, met name op het gebied van productveiligheid, cyberbeveiliging, mededinging, digitale en mediadiensten, financiële diensten, consumentenbescherming, gegevensbescherming en bescherming van de grondrechten;<br>
i) bijdragen aan doeltreffende samenwerking met de bevoegde autoriteiten van derde landen en met internationale organisaties;<br>
j) de nationale bevoegde autoriteiten en de Commissie bijstaan bij de ontwikkeling van de organisatorische en technische deskundigheid die nodig zijn voor de uitvoering van deze verordening, onder meer door bij te dragen aan de beoordeling van de opleidingsbehoeften voor personeel van de lidstaten dat betrokken is bij de uitvoering van deze verordening;<br>
k) het AI-bureau bijstaan bij het ondersteunen van nationale bevoegde autoriteiten bij het opzetten en ontwikkelen van AI-testomgevingen voor regelgeving, en samenwerking en informatie-uitwisseling tussen AI-testomgevingen voor regelgeving vergemakkelijken;<br>
l) bijdragen aan of relevant advies verstrekken over de ontwikkeling van richtsnoeren;<br>
m) de Commissie adviseren over internationale aangelegenheden op het gebied van AI;<br>
n) adviezen verstrekken aan de Commissie over de gekwalificeerde waarschuwingen met betrekking tot AI-modellen voor algemene doeleinden;<br>
o) adviezen van de lidstaten ontvangen over gekwalificeerde waarschuwingen met betrekking tot AI-modellen voor algemene doeleinden, en over nationale ervaringen en praktijken met betrekking tot de monitoring en handhaving van AI-systemen, met name systemen waarin de AI-modellen voor algemene doeleinden zijn geïntegreerd.<br><br>
<br>Er wordt een adviesforum opgericht om technische expertise te verstrekken en de AI-board en de Commissie te adviseren, alsook bij te dragen aan hun taken uit hoofde van deze verordening.
<br>De samenstelling van het adviesforum vertegenwoordigt een evenwichtige selectie van belanghebbenden, waaronder het bedrijfsleven, start-ups, kmo’s, het maatschappelijk middenveld en de academische wereld. Bij de samenstelling van het adviesforum wordt een evenwicht in acht genomen tussen commerciële en niet-commerciële belangen en, binnen de categorie commerciële belangen, tussen kmo’s en andere ondernemingen.
<br>De Commissie benoemt de leden van het adviesforum, overeenkomstig de criteria van lid 2, uit belanghebbenden met erkende deskundigheid op het gebied van AI.
<br>De ambtstermijn van de leden van het adviesforum bedraagt twee jaar en kan met ten hoogste vier jaar worden verlengd.
<br>Het Bureau voor de grondrechten, Enisa, het Europees Comité voor normalisatie (CEN), het Europees Comité voor elektrotechnische normalisatie (Cenelec) en het Europees Instituut voor telecommunicatienormen (ETSI) zijn permanente leden van het adviesforum.
<br>Het adviesforum stelt zijn reglement vast. Het kiest uit zijn leden twee covoorzitters, op basis van de criteria van lid 2. De ambtstermijn van de covoorzitters bedraagt twee jaar en kan één keer worden verlengd.
<br>Het adviesforum belegt minstens twee keer per jaar een vergadering. Het adviesforum kan deskundigen en andere belanghebbenden uitnodigen om zijn vergaderingen bij te wonen.
<br>Het adviesforum kan op verzoek van de AI-board of de Commissie adviezen, aanbevelingen en schriftelijke bijdragen opstellen.
<br>Het adviesforum kan in voorkomend geval permanente of tijdelijke subgroepen oprichten om specifieke vraagstukken met betrekking tot de doelstellingen van deze verordening te onderzoeken.
<br>Het adviesforum stelt een jaarverslag over zijn activiteiten op. Dat verslag wordt openbaar gemaakt.
<br><br>
<br>De Commissie stelt door middel van een uitvoeringshandeling bepalingen vast betreffende de oprichting van een wetenschappelijk panel van onafhankelijke deskundigen (het “wetenschappelijke panel”) ter ondersteuning van de handhavingsactiviteiten in het kader van deze verordening. Die uitvoeringshandeling wordt vastgesteld volgens de in artikel 98, lid 2, bedoelde onderzoeksprocedure.
<br>Het wetenschappelijk panel bestaat uit deskundigen die door de Commissie zijn geselecteerd op basis van de actuele wetenschappelijke of technische deskundigheid op het gebied van AI die nodig is voor de in lid 3 bedoelde taken. Het wetenschappelijk panel kan aantonen dat het voldoet aan alle volgende voorwaarden:<br>
a) beschikken over bijzondere deskundigheid en competenties en wetenschappelijke of technische deskundigheid op het gebied van AI;<br>
b) onafhankelijkheid van aanbieders van AI-systemen of AI-modellen voor algemene doeleinden;<br>
c) het vermogen om activiteiten zorgvuldig, nauwkeurig en objectief uit te voeren.<br>
De Commissie bepaalt in overleg met de AI-board het aantal deskundigen in het panel in overeenstemming met de vereiste behoeften en zorgt voor een eerlijke gender- en geografische vertegenwoordiging.
<br>Het wetenschappelijk panel adviseert en ondersteunt het AI-bureau, met name op het gebied van de volgende taken:<br>
a) het ondersteunen van de uitvoering en handhaving van deze verordening met betrekking tot AI-modellen en -systemen voor algemene doeleinden, met name door:<br>
i) het AI-bureau te waarschuwen voor mogelijke systeemrisico’s op Unieniveau van AI-modellen voor algemene doeleinden, overeenkomstig artikel 90;<br>
ii) bij te dragen aan de ontwikkeling van instrumenten en methoden voor de evaluatie van de capaciteiten van AI-modellen en -systemen voor algemene doeleinden, onder meer door middel van benchmarks;<br>
iii)<br>
advies te verstrekken over de classificatie van AI-modellen voor algemene doeleinden met een systeemrisico;<br>
iv) advies te verstrekken over de classificatie van verschillende AI-modellen en -systemen voor algemene doeleinden;<br>
v) bij te dragen aan de ontwikkeling van instrumenten en sjablonen;<br>
b) het ondersteunen van de werkzaamheden van markttoezichtautoriteiten op hun verzoek;<br>
c) het ondersteunen van in artikel 74, lid 11, bedoelde grensoverschrijdende markttoezichtactiviteiten, onverminderd de bevoegdheden van de markttoezichtautoriteiten;<br>
d) het ondersteunen van het AI-bureau bij de uitvoering van haar taken in het kader van de vrijwaringsprocedure van de Unie uit hoofde van artikel 81.
<br>De deskundigen in het wetenschappelijk panel voeren hun taken onpartijdig en objectief uit en waarborgen de vertrouwelijkheid van de informatie en gegevens die zij bij de uitvoering van hun taken en activiteiten verkrijgen. Zij vragen noch aanvaarden instructies van wie dan ook bij de uitoefening van hun taken uit hoofde van lid 3. Elke deskundige stelt een belangenverklaring op, die openbaar wordt gemaakt. Het AI-bureau zorgt voor systemen en procedures voor het actief beheren en voorkomen van mogelijke belangenconflicten.
<br>De in lid 1 bedoelde uitvoeringshandeling bevat bepalingen over de voorwaarden, procedures en gedetailleerde regelingen voor het wetenschappelijk panel en de leden daarvan om waarschuwingen af te geven en om het AI-bureau om bijstand te verzoeken voor de uitvoering van de taken van het wetenschappelijk panel.
<br><br>
<br>De lidstaten kunnen een beroep doen op deskundigen van het wetenschappelijk panel ter ondersteuning van hun handhavingsactiviteiten in het kader van deze verordening.
<br>De lidstaten kan worden voorgeschreven dat zij een vergoeding betalen voor het advies en de ondersteuning van de deskundigen. De structuur en de hoogte van de vergoedingen en de schaal en structuur van de invorderbare kosten worden in de in artikel 68, lid 1 bedoelde uitvoeringshandeling vermeld, rekening houdend met de doelstellingen van een Adequate uitvoering van deze verordening, de kosteneffectiviteit en de noodzaak ervoor te zorgen dat alle lidstaten daadwerkelijk toegang tot de deskundigen hebben.
<br>De Commissie vergemakkelijkt de tijdige toegang van de lidstaten tot de deskundigen, voor zover nodig, en zorgt ervoor dat de combinatie van ondersteunende activiteiten door Europese ondersteunende structuren voor AI-testen op grond van artikel 84 en deskundigen uit hoofde van dit artikel uitvoeren, efficiënt wordt georganiseerd en de best mogelijke toegevoegde waarde oplevert.<br>
AFDELING 2<br>
Nationale bevoegde autoriteiten
<br><br>
<br>Elke lidstaat moet voor de toepassing van deze verordening ten minste één aanmeldende autoriteit en ten minste één markttoezichtautoriteit instellen of aanwijzen als nationale bevoegde autoriteiten. Die nationale bevoegde autoriteiten moeten hun bevoegdheden onafhankelijk, onpartijdig en onbevooroordeeld uitoefenen, teneinde de objectiviteit van hun activiteiten en taken te waarborgen en de toepassing en uitvoering van deze verordening te verzekeren. De leden van die autoriteiten onthouden zich van handelingen die onverenigbaar zijn met hun ambt. Op voorwaarde dat deze beginselen in acht worden genomen, kunnen die activiteiten en taken door een of meer aangewezen autoriteiten worden uitgevoerd, in overeenstemming met de organisatorische behoeften van de lidstaat.
<br>De lidstaten verstrekken de Commissie informatie over de identiteit en de taken van de aanmeldende autoriteiten en de markttoezichtautoriteiten, alsook over eventuele latere wijzigingen daarin. De lidstaten maken uiterlijk op 2 augustus 2025 via elektronische communicatiemiddelen informatie bekend over de wijze waarop met de bevoegde autoriteiten en centrale contactpunten contact kan worden opgenomen. De lidstaten wijzen een markttoezichtautoriteit aan die optreedt als centraal contactpunt voor deze verordening en stellen de Commissie in kennis van de identiteit van het centrale contactpunt. De Commissie maakt een lijst van de centrale contactpunten openbaar.
<br>De lidstaten zorgen ervoor dat hun nationale bevoegde autoriteiten over voldoende technische, financiële en personele middelen en over passende infrastructuur beschikken om hun taken krachtens deze verordening op doeltreffende wijze uit te voeren. De nationale bevoegde autoriteiten beschikken met name over voldoende permanent beschikbaar personeel waarvan de competenties en expertise bestaan uit een grondig inzicht in AI-technologieën, gegevens en gegevensverwerking, bescherming van persoonsgegevens, cyberbeveiliging, grondrechten, gezondheids- en veiligheidsrisico’s en kennis van bestaande normen en wettelijke eisen. De lidstaten beoordelen en, indien nodig, actualiseren de in dit lid bedoelde benodigde competenties en middelen jaarlijks.
<br>De nationale bevoegde autoriteiten nemen passende maatregelen om te zorgen voor een adequaat niveau van cyberbeveiliging.
<br>Bij de uitvoering van hun taken voldoen de nationale bevoegde autoriteiten aan de in artikel 78 vastgelegde vertrouwelijkheidsverplichtingen.
<br>Uiterlijk op 2 augustus 2025 en vervolgens om de twee jaar, brengen de lidstaten aan de Commissie verslag uit over de stand van zaken met betrekking tot de financiële en personele middelen van de nationale bevoegde autoriteiten, met een beoordeling van de toereikendheid ervan. De Commissie bezorgt die informatie ter bespreking en voor mogelijke aanbevelingen aan de AI-board.
<br>De Commissie bevordert de uitwisseling van ervaringen tussen de nationale bevoegde autoriteiten.
<br>Nationale bevoegde autoriteiten kunnen begeleiding bij en advies over de uitvoering van deze verordening verstrekken, met name aan kmo’s, met inbegrip van start-ups, rekening houdend met de begeleiding en het advies van de AI-board en, indien nodig, de Commissie. Wanneer nationale bevoegde autoriteiten van plan zijn te voorzien in begeleiding en advies ten aanzien van een AI-systeem op gebieden die onder ander Unierecht vallen, worden in voorkomend geval de nationale bevoegde autoriteiten onder dat Unierecht geraadpleegd.
<br>Indien instellingen, organen of instanties van de Unie binnen het toepassingsgebied van deze verordening vallen, treedt de Europese Toezichthouder voor gegevensbescherming op als de bevoegde autoriteit voor het toezicht daarop.
]]></description><link>hoofdstukken/hoofdstuk_7.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_7.md</guid><pubDate>Tue, 13 Aug 2024 13:38:27 GMT</pubDate></item><item><title><![CDATA[hoofdstuk_8]]></title><description><![CDATA[ 
 <br>HOOFDSTUK VIII<br>
EU-DATABANK VOOR AI-SYSTEMEN MET EEN HOOG RISICO<br><br>
<br>De Commissie zorgt in samenwerking met de lidstaten voor het opzetten en onderhouden van een EU-databank met de in de leden 2 en 3 van dit artikel bedoelde informatie betreffende in artikel 6, lid 2, bedoelde AI-systemen met een hoog risico die overeenkomstig de artikelen 49 en 60 zijn geregistreerd en AI-systemen die niet als AI-systemen met een hoog risico worden beschouwd op grond van artikel 6, lid 3, en die zijn geregistreerd overeenkomstig artikel 6, lid 4 en artikel 49. Bij het vaststellen van de functionele specificaties van een dergelijke databank raadpleegt de Commissie de deskundigen ter zake, en bij het bijwerken van die functionele specificaties raadpleegt de Commissie de AI-board.
<br>De in afdelingen A en B van bijlage VIII vermelde gegevens worden in de EU-databank ingevoerd door de aanbieder of, in voorkomend geval, de gemachtigde.
<br>De in afdeling C van bijlage VIII vermelde gegevens worden in de EU-databank ingevoerd door de gebruiksverantwoordelijke die, overeenkomstig artikel 49, leden 3 en 4, een overheidsinstantie, agentschap of orgaan is of namens hen optreedt.
<br>Uitgezonderd voor het in artikel 49, lid 4, en artikel 60, lid 4, punt c), bedoelde deel is de informatie in de overeenkomstig artikel 49 geregistreerde EU-databank op gebruikersvriendelijke wijze openbaar toegankelijk. De informatie moet gemakkelijk te doorzoeken en machineleesbaar zijn. De overeenkomstig artikel 60 geregistreerde informatie is alleen toegankelijk voor markttoezichtautoriteiten en de Commissie, tenzij de aanbieder of potentiële aanbieder toestemming heeft gegeven om de informatie ook toegankelijk te maken voor het publiek.
<br>De EU-databank bevat alleen persoonsgegevens voor zover die nodig zijn voor het verzamelen en verwerken van informatie overeenkomstig deze verordening. Die informatie bevat de namen en contactgegevens van natuurlijke personen die verantwoordelijk zijn voor de registratie van het systeem en wettelijk gemachtigd zijn de aanbieder of de gebruiksverantwoordelijke, naargelang het geval, te vertegenwoordigen.
<br>De Commissie is voor de EU-databank de verantwoordelijke voor de verwerking. Zij stelt adequate technische en administratieve ondersteuning ter beschikking van aanbieders, potentiële aanbieders en gebruiksverantwoordelijken. De EU-databank voldoet aan de toepasselijke toegankelijkheidseisen.
]]></description><link>hoofdstukken/hoofdstuk_8.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_8.md</guid><pubDate>Tue, 13 Aug 2024 13:38:31 GMT</pubDate></item><item><title><![CDATA[hoofdstuk_9]]></title><description><![CDATA[ 
 <br>HOOFDSTUK IX<br>
MONITORING NA HET IN DE HANDEL BRENGEN, INFORMATIE-UITWISSELING EN MARKTTOEZICHT<br>
AFDELING 1<br>
Monitoring na het in de handel brengen<br><br>
<br>Aanbieders moeten een systeem voor monitoring na het in de handel brengen vaststellen en documenteren op een manier die evenredig is aan de aard van de AI-technologieën en de risico’s van het AI-systeem met een hoog risico.
<br>Het systeem voor monitoring na het in de handel brengen verzamelt, documenteert en analyseert actief en systematisch relevante data die door gebruiksverantwoordelijken kunnen zijn verstrekt of via andere bronnen kunnen zijn verzameld, over de prestaties van AI-systemen met een hoog risico gedurende hun hele levensduur, en die de aanbieder in staat stellen na te gaan of AI-systemen blijvend voldoen aan de in hoofdstuk III, afdeling 2, vermelde voorschriften. In voorkomend geval omvat de monitoring na het in de handel brengen een analyse van de interactie met andere AI-systemen. Deze verplichting geldt niet voor gevoelige operationele gegevens van gebruiksverantwoordelijken die rechtshandhavingsinstanties zijn.
<br>Het systeem voor monitoring na het in de handel brengen is gebaseerd op een plan voor monitoring na het in de handel brengen. Het plan voor monitoring na het in de handel brengen maakt deel uit van de in bijlage IV bedoelde technische documentatie. De Commissie stelt uiterlijk op 2 februari 2026 een uitvoeringshandeling vast met gedetailleerde bepalingen voor het opstellen van een model voor het plan voor monitoring na het in de handel brengen en de lijst van elementen die in het plan moeten worden opgenomen. De uitvoeringshandeling wordt volgens de in artikel 98, lid 2, bedoelde onderzoeksprocedure vastgesteld.
<br>Voor AI-systemen met een hoog risico die onder de in afdeling A van bijlage I vermelde harmonisatiewetgeving van de Unie vallen, hebben aanbieders, indien er krachtens die wetgeving reeds een systeem en een plan voor monitoring na het in de handel brengen zijn vastgesteld, ten behoeve van de consistentie, ter vermijding van doublures en om extra lasten tot een minimum te beperken, de keuze om de noodzakelijke in de leden 1, 2 en 3 beschreven elementen te integreren, met gebruikmaking van het in lid 3 bedoelde model, in systemen en plannen die reeds bestaan op grond van die wetgeving, mits dat een gelijkwaardig beschermingsniveau garandeert.<br>
De eerste alinea van dit lid is ook van toepassing op in punt 5 van bijlage III bedoelde aI-systemen met een hoog risico die in de handel worden gebracht of in gebruik worden gesteld door financiële instellingen waarvoor krachtens het Unierecht inzake financiële diensten vereisten met betrekking tot hun interne governance, regelingen of processen gelden.<br>
AFDELING 2<br>
Delen van informatie over ernstige incidenten
<br><br>
<br>Aanbieders van in de Unie in de handel gebrachte AI-systemen met een hoog risico melden ernstige incidenten bij de markttoezichtautoriteiten van de lidstaten waarin dat incident heeft plaatsgevonden.
<br>De in lid 1 bedoelde melding wordt gedaan onmiddellijk nadat de aanbieder een oorzakelijk verband tussen het AI-systeem en het ernstige incident of de redelijke waarschijnlijkheid van een dergelijk verband heeft vastgesteld en in ieder geval uiterlijk 15 dagen nadat de aanbieder of, in voorkomend geval, de gebruiksverantwoordelijke zich bewust wordt van het ernstige incident.<br>
Bij de in de eerste alinea bedoelde meldingstermijn wordt rekening gehouden met de ernst van het ernstige incident.
<br>Niettegenstaande lid 2 van dit artikel wordt bij een wijdverbreide inbreuk of een ernstig incident, zoals gedefinieerd in artikel 3, punt 49), b), de in lid 1 van dit artikel bedoelde melding onmiddellijk gedaan, doch uiterlijk twee dagen nadat de aanbieder of, in voorkomend geval, de gebruiksverantwoordelijke zich bewust wordt van dat incident.
<br>Niettegenstaande lid 2 wordt bij overlijden van een persoon de melding gedaan onmiddellijk nadat de aanbieder of de gebruiksverantwoordelijke een oorzakelijk verband heeft vastgesteld, of zodra hij of zij dit vermoedt, tussen het AI-systeem met een hoog risico en het ernstige incident, doch uiterlijk tien dagen na de datum waarop de aanbieder of, in voorkomend geval, de gebruiksverantwoordelijke zich bewust wordt van het ernstige incident.
<br>Indien dit nodig is om tijdige melding te waarborgen, kan de aanbieder of, in voorkomend geval, de gebruiksverantwoordelijke een eerste, onvolledige, melding doen die wordt gevolgd door een volledige melding.
<br>Na de melding van een ernstig incident op grond van lid 1 verricht de aanbieder onverwijld het nodige onderzoek in verband met het ernstige incident en het betrokken AI-systeem. Dit omvat een risicobeoordeling van het incident en corrigerende maatregelen.<br>
De aanbieder werkt tijdens het in de eerste alinea genoemde onderzoek samen met de bevoegde autoriteiten en, in voorkomend geval, met de betrokken aangemelde instantie, en verricht geen onderzoek waarbij het AI-systeem wordt gewijzigd op een wijze die van invloed kan zijn op de latere evaluatie van de oorzaken van het incident, zonder de bevoegde autoriteiten daarvan vooraf in kennis te stellen.
<br>Na ontvangst van een melding met betrekking tot een ernstig incident als bedoeld in artikel 3, punt 49), c), stelt de betrokken markttoezichtautoriteit de in artikel 77, lid 1, bedoelde nationale overheidsinstanties of -organen in kennis. De Commissie ontwikkelt specifieke richtsnoeren om nakoming van de in lid 1 van dit artikel vermelde verplichtingen te vergemakkelijken. Die richtsnoeren worden uiterlijk op 2 augustus 2025 uitgevaardigd en worden regelmatig geëvalueerd.
<br>De markttoezichtautoriteit neemt passende maatregelen, zoals bedoeld in artikel 19 van Verordening (EU) 2019/1020, binnen zeven dagen na de datum waarop zij de in lid 1 van dit artikel bedoelde kennisgeving heeft ontvangen, en volgt de kennisgevingsprocedures waarin die verordening voorziet.
<br>Voor in bijlage III vermelde AI-systemen met een hoog risico die in de handel zijn gebracht of in gebruik zijn gesteld door aanbieders die onderworpen zijn aan rechtsinstrumenten van de Unie met meldingsverplichtingen die gelijkwaardig zijn aan die van deze verordening, is de melding van ernstige incidenten beperkt tot de in artikel 3, punt 49), c), bedoelde incidenten.
<br>Voor AI-systemen met een hoog risico die veiligheidscomponenten van apparaten zijn of zelf apparaten zijn die onder de Verordeningen (EU) 2017/745 en (EU) 2017/746 vallen, wordt de melding van ernstige incidenten beperkt tot de in artikel 3, punt 49), c), van de onderhavige verordening bedoelde incidenten, en wordt het incident gemeld bij de nationale bevoegde autoriteit die daartoe is aangewezen door de lidstaten waar dat incident zich heeft voorgedaan.
<br>De nationale bevoegde autoriteiten stellen de Commissie onmiddellijk in kennis van elk ernstig incident, ongeacht of zij al dan niet maatregelen hebben getroffen, overeenkomstig artikel 20 van Verordening (EU) 2019/1020.<br>
AFDELING 3<br>
Handhaving
<br><br>
<br>Verordening (EU) 2019/1020 is van toepassing op AI-systemen die onder deze verordening vallen. Ten behoeve van de doeltreffende handhaving van deze verordening geldt echter het volgende:<br>
a) verwijzingen naar een marktdeelnemer krachtens Verordening (EU) 2019/1020 worden begrepen als verwijzingen naar alle in artikel 2, lid 1, van deze verordening geïdentificeerde operators;<br>
b) verwijzingen naar een product krachtens Verordening (EU) 2019/1020 worden begrepen als verwijzingen naar alle AI-systemen die binnen het toepassingsgebied van deze verordening vallen.
<br>In het kader van hun rapportageverplichtingen krachtens artikel 34, lid 4, van Verordening (EU) 2019/1020 brengen de markttoezichtautoriteiten jaarlijks aan de Commissie en de bevoegde nationale mededingingsautoriteiten verslag uit over alle informatie die in het kader van markttoezichtactiviteiten is verkregen en die van belang kan zijn voor de toepassing van het Unierecht inzake mededingingsregels. Daarnaast brengen zij de Commissie jaarlijks verslag uit over het gebruik van verboden praktijken in de loop van dat jaar en over de maatregelen die genomen zijn.
<br>Voor AI-systemen met een hoog risico met betrekking tot producten waarop de in afdeling A van bijlage I vermelde harmonisatiewetgeving van de Unie van toepassing is, is voor de toepassing van deze verordening de markttoezichtautoriteit de autoriteit die verantwoordelijk is voor markttoezichtactiviteiten uit hoofde van die rechtshandelingen.<br>
In afwijking van de eerste alinea kunnen de lidstaten in passende omstandigheden een andere relevante autoriteit aanwijzen om als markttoezichtautoriteit op te treden, mits zij zorgen voor coördinatie met de relevante sectorale markttoezichtautoriteiten die verantwoordelijk zijn voor de handhaving van de in bijlage I vermelde harmonisatiewetgeving van de Unie.
<br>De in de artikelen 79 tot en met 83 van deze verordening bedoelde procedures zijn niet van toepassing op AI-systemen die verband houden met producten waarop in de in afdeling A van bijlage I vermelde harmonisatiewetgeving van de Unie van toepassing is, indien de betrokken rechtshandelingen reeds voorzien in procedures die een gelijkwaardig niveau van bescherming waarborgen en hetzelfde doel hebben. In dergelijke gevallen zijn in plaats daarvan de betrokken sectorale procedures van toepassing.
<br>Onverminderd de bevoegdheden van markttoezichtautoriteiten krachtens artikel 14 van Verordening (EU) 2019/1020 kunnen markttoezichtautoriteiten met het oog op de doeltreffende handhaving van deze verordening de in artikel 14, lid 4, punten d) en j), van die verordening bedoelde bevoegdheden naargelang van het geval op afstand uitoefenen.
<br>Voor AI-systemen met een hoog risico die in de handel worden gebracht, in gebruik worden gesteld of worden gebruikt door financiële instellingen die onder het Unierecht inzake financiële diensten vallen, is de markttoezichtautoriteit voor de toepassing van deze verordening de relevante nationale autoriteit die verantwoordelijk is voor het financiële toezicht op die instellingen krachtens die wetgeving, voor zover het in de handel brengen, in gebruik stellen of gebruik van het AI-systeem rechtstreeks verband houdt met de verlening van die financiële diensten.
<br>In afwijking van lid 6 kan in gerechtvaardigde omstandigheden en op voorwaarde dat er coördinatie wordt gewaarborgd, een andere relevante autoriteit door de lidstaat als markttoezichtautoriteit worden aangewezen voor de toepassing van deze verordening.<br>
Nationale markttoezichtautoriteiten die toezicht houden op gereglementeerde kredietinstellingen die onder Richtlijn 2013/36/EU vallen en die deelnemen aan het bij Verordening (EU) nr. 1024/2013 ingestelde gemeenschappelijk toezichtsmechanisme, moeten onverwijld bij de Europese Centrale Bank alle informatie melden die zij bij hun markttoezichtactiviteiten hebben verkregen en die potentieel van belang kan zijn voor de in die verordening nader bepaalde prudentiële-toezichtstaken van de Europese Centrale Bank.
<br>Voor AI-systemen met een hoog risico die zijn vermeld in punt 1 van bijlage III, bij deze verordening, voor zover die systemen worden gebruikt voor rechtshandhavingsdoeleinden, grenstoezicht en rechtsbedeling en democratie, en voor AI-systemen met een hoog risico die zijn vermeld in de punten 6, 7 en 8 van bijlage III, bij deze verordening wijzen de lidstaten als markttoezichtautoriteiten voor de toepassing van deze verordening hetzij de bevoegde toezichthoudende autoriteiten voor gegevensbescherming krachtens Verordening (EU) 2016/679 of Richtlijn (EU) 2016/680 aan, hetzij een andere autoriteit die is aangewezen onder dezelfde voorwaarden van de artikelen 41 tot en met 44 van Richtlijn (EU) 2016/680. De markttoezichtactiviteiten mogen geenszins afbreuk doen aan de onafhankelijkheid van gerechtelijke instanties of anderszins afbreuk doen aan hun activiteiten wanneer zij optreden in hun gerechtelijke hoedanigheid.
<br>Indien instellingen, organen of instanties van de Unie binnen het toepassingsgebied van deze verordening vallen, treedt de Europese Toezichthouder voor gegevensbescherming als hun markttoezichtautoriteit op, behalve ten aanzien van het Hof van Justitie van de Europese Unie in zijn gerechtelijke hoedanigheid.
<br>De lidstaten faciliteren de coördinatie tussen krachtens deze verordening aangewezen markttoezichtautoriteiten en andere relevante nationale autoriteiten of instanties die toezicht houden op de toepassing van de in bijlage I vermelde harmonisatiewetgeving van de Unie of andere Unieregels, die mogelijk relevant kunnen zijn voor de in bijlage III vermelde AI-systemen met een hoog risico.
<br>Markttoezichtautoriteiten en de Commissie kunnen gezamenlijke activiteiten, waaronder gezamenlijke onderzoeken, voorstellen die door markttoezichtautoriteiten alleen of gezamenlijk met de Commissie moeten worden uitgevoerd, met als doel de naleving te bevorderen, niet-naleving vast te stellen, bewustmaking of richtsnoeren met betrekking tot deze verordening te verstrekken over specifieke categorieën AI-systemen met een hoog risico die in twee of meer lidstaten een ernstig risico blijken te vormen, overeenkomstig artikel 9 van Verordening (EU) 2019/1020. Het AI-bureau draagt zorg voor coördinerende ondersteuning van gezamenlijke onderzoeken.
<br>Onverminderd de bevoegdheden krachtens Verordening (EU) 2019/1020, en voor zover relevant en beperkt tot wat nodig is om hun taken uit te voeren, verlenen aanbieders de markttoezichtautoriteiten volledige toegang tot de documentatie en tot de datasets voor het trainen, valideren en testen die worden gebruikt voor de ontwikkeling van AI-systemen met een hoog risico, onder meer, in voorkomend geval en met inachtneming van beveiligingswaarborgen, via applicatieprogramma-interfaces (“API’s”) of andere relevante technische middelen en instrumenten die toegang op afstand mogelijk maken.
<br>Markttoezichtautoriteiten wordt toegang tot de broncode van het AI-systeem met een hoog risico verleend op een met redenen omkleed verzoek en uitsluitend als aan beide onderstaande voorwaarden wordt voldaan:<br>
a) toegang tot de broncode is noodzakelijk om te beoordelen of een AI-systeem met een hoog risico overeenstemt met de voorschriften van afdeling 2 van hoofdstuk III, en<br>
b) de test- of auditprocedures en verificaties op basis van de door de aanbieder verstrekte gegevens en documentatie zijn uitgeput of ontoereikend gebleken.
<br>De door de markttoezichtautoriteiten verkregen informatie of documentatie worden verwerkt overeenkomstig de in artikel 78 vastgelegde vertrouwelijkheidsverplichtingen.
<br><br>
<br>Indien een AI-systeem gebaseerd is op een AI-model voor algemene doeleinden en het model en het systeem door dezelfde aanbieder worden ontwikkeld, moet het AI-bureau bevoegd zijn om de naleving van de verplichtingen krachtens deze verordening door dat AI-systeem te monitoren en te bewaken. Om zijn monitoring- en toezichttaken uit te voeren, moet het AI-bureau beschikken over alle in deze afdeling en Verordening (EU) 2019/1020 bepaalde bevoegdheden van een markttoezichtautoriteit.
<br>Indien de relevante markttoezichtautoriteiten voldoende reden hebben om van mening te zijn dat AI-systemen voor algemene doeleinden die door gebruiksverantwoordelijken rechtstreeks kunnen worden gebruikt voor ten minste één doel dat op grond van deze verordening naar hoog risico is ingedeeld, niet in overeenstemming zijn met de voorschriften van deze verordening, werken zij samen met het AI-bureau om nalevingsevaluaties te verrichten, en stellen zij de AI-board en andere markttoezichtautoriteiten daarvan in kennis.
<br>Indien een markttoezichtautoriteit haar onderzoek naar het AI-systeem met een hoog risico niet kan afronden omdat zij geen toegang heeft tot bepaalde informatie met betrekking tot het AI-model voor algemene doeleinden, hoewel zij al het nodige heeft gedaan om die informatie te verkrijgen, kan zij een met redenen omkleed verzoek indienen bij het AI-bureau, waarmee de toegang tot die informatie wordt afgedwongen. In dat geval verstrekt het AI-bureau de verzoekende autoriteit onverwijld, en in ieder geval binnen dertig dagen, alle informatie die het relevant acht om vast te stellen of een AI-systeem met een hoog risico non-conform is. Markttoezichtautoriteiten waarborgen dat de door hen verkregen informatie overeenkomstig artikel 78 van deze verordening vertrouwelijk wordt behandeld. De procedure van hoofdstuk VI van Verordening (EU) 2019/1020 is van overeenkomstige toepassing.
<br><br>
<br>De markttoezichtautoriteiten hebben de bevoegdheden om ervoor te zorgen dat tests onder reële omstandigheden in overeenstemming zijn met deze verordening.
<br>Indien AI-systemen waarop toezicht wordt uitgeoefend binnen een AI-testomgeving voor regelgeving krachtens artikel 58, onder reële omstandigheden worden getest, controleren de markttoezichtautoriteiten of artikel 60 wordt nageleefd als onderdeel van hun toezichthoudende rol voor de AI-testomgeving voor regelgeving. Deze autoriteiten kunnen, in voorkomend geval, toestaan dat de aanbieder of potentiële aanbieder in afwijking van de voorwaarden van artikel 60, lid 4, punten f) en g), onder reële omstandigheden test.
<br>Een markttoezichtautoriteit die door de aanbieder, de potentiële aanbieder of een derde van een ernstig incident op de hoogte is gebracht of andere redenen heeft om aan te nemen dat niet aan de in de artikelen 60 en 61 bepaalde voorwaarden wordt voldaan, kan op haar grondgebied een van de volgende besluiten nemen, naargelang van het geval:<br>
a) de tests onder reële omstandigheden opschorten of beëindigen;<br>
b) aanbieders of potentiële aanbieders en gebruiksverantwoordelijken of potentiële gebruiksverantwoordelijken voorschrijven dat zij een aspect van de test onder reële omstandigheden wijzigen.
<br>Indien een markttoezichtautoriteit een besluit als bedoeld in lid 3 van dit artikel heeft genomen of een bezwaar in de zin van artikel 60, lid 4, punt b), heeft ingediend, worden in het besluit of het bezwaar vermeld wat de redenen daarvoor zijn en onder welke voorwaarden de aanbieder of potentiële aanbieder het besluit of het bezwaar kan aanvechten.
<br>Indien, in voorkomend geval, een markttoezichtautoriteit een besluit als bedoeld in lid 3 heeft genomen, deelt zij de redenen daarvoor mee aan de markttoezichtautoriteiten van de andere lidstaten waar het AI-systeem overeenkomstig het testplan is getest.
<br><br>
<br>Nationale overheidsinstanties of -organen die de nakoming van verplichtingen krachtens Unierecht ter bescherming van grondrechten, waaronder het recht op non-discriminatie, met betrekking tot het gebruik van de in bijlage III vermelde AI-systemen met een hoog risico controleren of handhaven, zijn bevoegd om krachtens deze verordening opgestelde of bijgehouden documentatie in een toegankelijke taal en een toegankelijk formaat aan te vragen en in te zien wanneer toegang tot die documentatie nodig is voor het doeltreffend uitoefenen van de bevoegdheden onder hun mandaat binnen de grenzen van hun rechtsgebied. De overheidsinstantie of het overheidsorgaan in kwestie stelt de markttoezichtautoriteit van de betrokken lidstaat van een dergelijke aanvraag in kennis.
<br>Uiterlijk op 2 november 2024 stelt elke lidstaat de in lid 1 bedoelde overheidsinstanties of -organen vast en maakt de lijst openbaar. De lidstaten stellen de Commissie en de andere lidstaten in kennis van de lijst en houden deze up-to-date.
<br>Indien de in lid 1 bedoelde documentatie ontoereikend is om vast te stellen of sprake is geweest van een inbreuk op verplichtingen krachtens het Unierecht ter bescherming van grondrechten, kunnen de in lid 1 bedoelde overheidsinstanties of -organen een met redenen omkleed verzoek bij de markttoezichtautoriteit indienen om het AI-systeem met een hoog risico met technische middelen te mogen testen. De markttoezichtautoriteit organiseert de testprocedure binnen een redelijke termijn na het verzoek en met nauwe betrokkenheid van de verzoekende overheidsinstantie of het verzoekende overheidsorgaan.
<br>Informatie of documentatie die op grond van dit artikel door de in lid 1 van dit artikel bedoelde overheidsinstanties of -organen wordt verkregen, wordt verwerkt overeenkomstig de in artikel 78 beschreven vertrouwelijkheidsverplichtingen.
<br><br>
<br>De Commissie, de markttoezichtautoriteiten en de aangemelde instanties, en alle andere natuurlijke of rechtspersonen die bij de toepassing van deze verordening betrokken zijn, eerbiedigen overeenkomstig het Unierecht of het nationale recht de vertrouwelijke aard van informatie en gegevens die zij hebben verkregen tijdens het uitvoeren van hun taken en activiteiten, met name ter bescherming van:<br>
a) de intellectuele-eigendomsrechten, en vertrouwelijke bedrijfsinformatie of bedrijfsgeheimen van een natuurlijke of rechtspersoon, waaronder de broncode, uitgezonderd de gevallen bedoeld in artikel 5 van Richtlijn (EU) 2016/943 van het Europees Parlement en de Raad <a class="internal-link" data-href="#ntr57-L_202401689NL.000101-E0057" href="about:blank#ntr57-L_202401689NL.000101-E0057" target="_self" rel="noopener">(57)</a>;<br>
b) de doeltreffende uitvoering van deze verordening, met name in verband met inspecties, onderzoeken of audits;<br>
c) publieke en nationale veiligheidsbelangen;<br>
d) het voeren van strafrechtelijke of administratieve procedures;<br>
e) informatie die op grond van het Unierecht of het nationale recht gerubriceerd is.
<br>De autoriteiten die op grond van lid 1 bij de toepassing van deze verordening betrokken zijn, verzoeken alleen om gegevens die strikt noodzakelijk zijn ter beoordeling van het risico van AI-systemen en ter uitoefening van hun bevoegdheden in overeenstemming met deze verordening en met Verordening (EU) 2019/1020. Zij treffen adequate en doeltreffende cyberbeveiligingsmaatregelen ter bescherming van de veiligheid en de vertrouwelijkheid van de verkregen informatie en gegevens en wissen de verzamelde gegevens zodra die niet langer nodig zijn voor het doel waarvoor zij zijn verkregen, overeenkomstig het toepasselijke Unierecht of nationale recht.
<br>Onverminderd de leden 1 en 2, mag op vertrouwelijke basis tussen de nationale bevoegde autoriteiten of tussen nationale bevoegde autoriteiten en de Commissie uitgewisselde informatie niet openbaar worden gemaakt zonder voorafgaande raadpleging van de nationale bevoegde autoriteit waarvan de informatie afkomstig is en de gebruiksverantwoordelijke wanneer in punt 1, 6 of 7 van bijlage III vermelde AI-systemen met een hoog risico worden gebruikt door rechtshandhavingsinstanties en grenstoezichts-, immigratie- of asielautoriteiten, wanneer die openbaarmaking openbare en nationale veiligheidsbelangen in gevaar zou brengen. Deze informatie-uitwisseling behelst geen gevoelige operationele gegevens in verband met de activiteiten van rechtshandhavings-, grenstoezichts-, immigratie- of asielautoriteiten.<br>
Indien de rechtshandhavingsinstanties of immigratie- of asielautoriteiten aanbieders van in punt 1, 6 of 7 van bijlage III bedoelde AI-systemen met een hoog risico zijn, blijft de in bijlage IV vermelde technische documentatie in de gebouwen van die autoriteiten. Die autoriteiten waarborgen dat de in artikel 74, leden 8 en 9, bedoelde markttoezichtautoriteiten zo nodig op verzoek onmiddellijk toegang tot de documentatie kunnen krijgen of een kopie ervan kunnen ontvangen. Alleen personeel van de markttoezichtautoriteit met een passende veiligheidsmachtiging mag die documentatie of kopieën ervan inzien.
<br>De leden 1, 2 en 3 laten de rechten en verplichtingen van de Commissie, de lidstaten en hun bevoegde autoriteiten, alsmede die van de aangemelde instanties, met betrekking tot de uitwisseling van informatie en de verspreiding van waarschuwingen, ook in het kader van grensoverschrijdende samenwerking, evenals de verplichtingen van de betrokken partijen om in het kader van het strafrecht van de lidstaten informatie te verstrekken, onverlet.
<br>De Commissie en de lidstaten kunnen zo nodig en met inachtneming van de relevante bepalingen van internationale overeenkomsten en handelsakkoorden vertrouwelijke informatie uitwisselen met regelgevingsinstanties van derde landen waarmee zij bilaterale of multilaterale vertrouwelijkheidsovereenkomsten hebben gesloten die een passend niveau van vertrouwelijkheid waarborgen.
<br><br>
<br>Onder AI-systemen die een risico inhouden, worden verstaan “producten die een risico vormen”, zoals gedefinieerd in artikel 3, punt 19, van Verordening (EU) 2019/1020, voor zover die een risico vormen voor de gezondheid, de veiligheid of de grondrechten van personen.
<br>Indien de markttoezichtautoriteit van een lidstaat voldoende reden heeft om van mening te zijn dat een AI-systeem een risico vormt, zoals bedoeld in lid 1 van dit artikel, verricht zij een evaluatie van het betrokken AI-systeem ten aanzien van de overeenstemming ervan met alle eisen en verplichtingen van deze verordening. Er wordt bijzondere aandacht besteed aan AI-systemen die een risico vormen voor kwetsbare groepen. Indien er risico’s voor de grondrechten worden vastgesteld, stelt de markttoezichtautoriteit tevens de in artikel 77, lid 1, bedoelde relevante nationale overheidsinstanties of -organen in kennis en verleent zij hun haar volledige medewerking. De relevante gebruiksverantwoordelijken werken voor zover noodzakelijk samen met de markttoezichtautoriteit en met de andere in artikel 77, lid 1, bedoelde nationale overheidsinstanties of -organen.<br>
Indien de markttoezichtautoriteit, in voorkomend geval in samenwerking met de in artikel 77, lid 1, bedoelde nationale overheidsinstantie, bij deze evaluatie vaststelt dat het AI-systeem niet aan de eisen en verplichtingen van deze verordening voldoet, gelast zij de betrokken operator zonder onnodige vertraging passende corrigerende maatregelen te nemen om het AI-systeem binnen een termijn die door de markttoezichtautoriteit kan worden vastgesteld, en in elk geval binnen 15 werkdagen of binnen de termijn die is vastgelegd in de van toepassing zijnde relevante harmonisatiewetgeving van de Unie, indien die korter is, conform te maken, uit de handel te nemen of terug te roepen.<br>
De markttoezichtautoriteit stelt de relevante aangemelde instantie daarvan in kennis. Op de in de tweede alinea van dit lid genoemde maatregelen is artikel 18 van Verordening (EU) 2019/1020 van toepassing.
<br>Indien de markttoezichtautoriteit van mening is dat de non-conformiteit niet beperkt blijft tot haar nationale grondgebied, brengt zij de Commissie en de andere lidstaten zonder onnodige vertraging op de hoogte van de resultaten van de evaluatie en van de maatregelen die zij de operator heeft opgelegd.
<br>De operators zorgen ervoor dat alle betrokken AI-systemen die zij op de Uniemarkt hebben aangeboden aan alle passende corrigerende maatregelen worden onderworpen.
<br>Indien de operator van een AI-systeem niet binnen de in lid 2 bedoelde termijn doeltreffende corrigerende actie onderneemt, neemt de markttoezichtautoriteit alle passende voorlopige maatregelen om het op haar nationale markt aanbieden of in gebruik stellen van het AI-systeem te verbieden of te beperken, het product of het op zichzelf staande AI-systeem in de betrokken lidstaat uit de handel te nemen of terug te roepen. Die autoriteit stelt de Commissie en de andere lidstaten zonder onnodige vertraging van deze maatregelen in kennis.
<br>De in lid 5 bedoelde kennisgeving omvat alle bekende bijzonderheden, met name de informatie die nodig is om het non-conforme AI-systeem te identificeren en om de oorsprong van het AI-systeem en de toeleveringsketen, de aard van de beweerde non-conformiteit en van het risico, en de aard en de duur van de nationale maatregelen vast te stellen, evenals de argumenten die worden aangevoerd door de betrokken operator. De markttoezichtautoriteiten vermelden met name of de non-conformiteit een of meer van de volgende redenen heeft:<br>
a) niet-naleving van het verbod op de in artikel 5 bedoelde AI-praktijken;<br>
b) het AI-systeem met een hoog risico voldoet niet aan vereisten van hoofdstuk III, afdeling 2;<br>
c) tekortkomingen in de in de artikelen 40 en 41 bedoelde geharmoniseerde normen of gemeenschappelijke specificaties die een vermoeden van conformiteit rechtvaardigen;<br>
d) niet-naleving van artikel 50.
<br>De andere markttoezichtautoriteiten dan de markttoezicht-autoriteit van de lidstaat die de procedure heeft geïnitieerd, brengen de Commissie en de andere lidstaten zonder onnodige vertraging op de hoogte van door hen genomen maatregelen en van aanvullende informatie over de non-conformiteit van het AI-systeem waarover zij beschikken, en van hun bezwaren indien zij het niet eens zijn met de aangemelde nationale maatregel.
<br>Indien er binnen drie maanden na ontvangst van de in lid 5 van dit artikel bedoelde kennisgeving door een markttoezichtautoriteit van een lidstaat of door de Commissie geen bezwaar tegen een voorlopige maatregel van een markttoezichtautoriteit van een andere lidstaat is ingediend, wordt die maatregel geacht gerechtvaardigd te zijn. Dit geldt onverminderd de procedurele rechten van de betrokken operator overeenkomstig artikel 18 van Verordening (EU) 2019/1020. De in dit lid bedoelde termijn van drie maanden wordt verkort tot dertig dagen in geval van niet-naleving van het verbod op de in artikel 5 van deze verordening bedoelde AI-praktijken.
<br>De markttoezichtautoriteiten zorgen ervoor dat ten aanzien van het betrokken product of AI-systeem zonder onnodige vertraging de passende beperkende maatregelen worden genomen, zoals het uit de handel nemen van het product of het AI-systeem op hun markt.
<br><br>
<br>Indien een markttoezichtautoriteit voldoende reden heeft om van mening te zijn dat een AI-systeem dat door de aanbieder is ingedeeld als een AI-systeem dat geen hoog risico met zich meebrengt op grond van artikel 6, lid 3, wél een hoog risico vormt, toetst zij het betrokken AI-systeem aan de classificatie ervan als AI-systeem met een hoog risico op grond van de voorwaarden van artikel 6, lid 3, en de richtsnoeren van de Commissie.
<br>Indien de markttoezichtautoriteit bij die toetsing vaststelt dat het betrokken AI-systeem een hoog risico vormt, eist zij zonder onnodige vertraging van de betrokken aanbieder dat deze alle nodige maatregelen neemt om het AI-systeem in overeenstemming te brengen met de vereisten en verplichtingen van deze verordening, en binnen een termijn die de markttoezichtautoriteit kan voorschrijven passende corrigerende maatregelen neemt.
<br>Indien de markttoezichtautoriteit van mening is dat de het gebruik van het AI-systeem niet beperkt blijft tot haar nationale grondgebied, brengt zij de Commissie en de andere lidstaten zonder onnodige vertraging op de hoogte van de resultaten van de toetsing en van de maatregelen die zij de aanbieder heeft opgelegd.
<br>De aanbieder zorgt ervoor dat alle nodige maatregelen worden genomen om het AI-systeem in overeenstemming te brengen met de vereisten en verplichtingen van deze verordening. Indien de aanbieder van een betrokken AI-systeem dat AI-systeem niet binnen de in lid 2 van dit artikel bedoelde termijn in overeenstemming brengt met die vereisten en verplichtingen, worden aan de aanbieder overeenkomstig artikel 99 geldboeten opgelegd.
<br>De aanbieder zorgt ervoor dat alle betrokken AI-systemen die zij op de Uniemarkt hebben aangeboden aan alle passende corrigerende maatregelen worden onderworpen.
<br>Indien de aanbieder van het betrokken AI-systeem niet binnen de in lid 2 van dit artikel bedoelde termijn adequate corrigerende maatregelen neemt, is artikel 79, leden 5 tot en met 9, van toepassing.
<br>Indien de markttoezichtautoriteit bij de toetsing op grond van lid 1 van dit artikel vaststelt dat het AI-systeem door de aanbieder ten onrechte als geen hoog risico vormend systeem is ingedeeld om de toepassing van de vereisten van hoofdstuk III, afdeling 2, te omzeilen, worden aan de aanbieder overeenkomstig artikel 99 geldboeten opgelegd.
<br>Bij de uitoefening van hun bevoegdheid om op de toepassing van dit artikel toe te zien, en overeenkomstig artikel 11 van Verordening (EU) 2019/1020, kunnen markttoezichtautoriteiten passende controles verrichten waarbij zij met name informatie die is opgeslagen in de in artikel 71 van deze verordening bedoelde EU-databank in aanmerking nemen.
<br><br>
<br>Indien de markttoezichtautoriteit van een lidstaat binnen drie maanden na ontvangst van de in artikel 79, lid 5, bedoelde kennisgeving, of binnen dertig dagen in geval van niet-naleving van het verbod op de in artikel 5 bedoelde AI-praktijken, bezwaar maakt tegen een door een andere markttoezichtautoriteit genomen maatregel, of indien de Commissie de maatregel in strijd acht met het Unierecht, treedt de Commissie zonder onnodige vertraging in overleg met de markttoezichtautoriteit van de betrokken lidstaat en de operator(s), en evalueert zij de nationale maatregel. Op grond van de resultaten van die evaluatie besluit de Commissie binnen zes maanden, of binnen zestig dagen in geval van niet-naleving van het verbod op de in artikel 5 bedoelde AI-praktijken, met ingang van de in artikel 79, lid 5, bedoelde kennisgeving of de nationale maatregel gerechtvaardigd is, en deelt zij haar besluit aan de markttoezichtautoriteit van de betrokken lidstaat mee. De Commissie stelt ook alle andere markttoezichtautoriteiten van haar besluit in kennis.
<br>Indien de Commissie de maatregel van de betrokken lidstaat gerechtvaardigd acht, zorgen alle lidstaten ervoor dat zij passende beperkende maatregelen ten aanzien van het betrokken AI-systeem nemen, zoals het zonder onnodige vertraging uit de handel nemen van het AI-systeem op hun markt, en stellen zij de Commissie daarvan in kennis. Indien de Commissie de nationale maatregel ongerechtvaardigd acht, trekt de betrokken lidstaat de maatregel in en stelt hij de Commissie daarvan in kennis.
<br>Indien de nationale maatregel gerechtvaardigd wordt geacht en de non-conformiteit van het AI-systeem wordt toegeschreven aan tekortkomingen in de in de artikelen 40 en 41 van deze verordening bedoelde geharmoniseerde normen of gemeenschappelijke specificaties, past de Commissie de procedure van artikel 11 van Verordening (EU) nr. 1025/2012 toe.
<br><br>
<br>Indien de markttoezichtautoriteit van een lidstaat na uitvoering van een evaluatie overeenkomstig artikel 79 en na raadpleging van de in artikel 77, lid 1, bedoelde relevante nationale overheidsinstantie vaststelt dat een AI-systeem met een hoog risico dat weliswaar voldoet aan deze verordening, toch een risico inhoudt voor de gezondheid of veiligheid van personen, voor de grondrechten of voor andere aspecten van de bescherming van algemene belangen, schrijft zij de betrokken operator voor dat deze binnen een termijn die zij kan vaststellen, alle passende maatregelen neemt om er zonder onnodige vertraging voor te zorgen dat het betrokken AI-systeem dat risico niet meer inhoudt wanneer het in de handel wordt gebracht of in gebruik wordt gesteld.
<br>De aanbieder of andere relevante operator zorgt ervoor dat er binnen de in lid 1 bedoelde door de markttoezichtautoriteit van de lidstaat vastgestelde termijn corrigerende maatregelen worden genomen ten aanzien van alle betrokken AI-systemen die deze op de Uniemarkt heeft aangeboden.
<br>De lidstaten brengen de Commissie en de andere lidstaten onmiddellijk op de hoogte van een vaststelling op grond van lid 1. Die informatie omvat alle bekende bijzonderheden, met name de gegevens die nodig zijn om het betrokken AI-systeem te identificeren en om de oorsprong en de toeleveringsketen van het AI-systeem, de aard van het betrokken risico en de aard en de duur van de nationale maatregelen vast te stellen.
<br>De Commissie treedt zonder onnodige vertraging in overleg met de betrokken lidstaten en de betrokken operators en evalueert de genomen nationale maatregelen. Aan de hand van die evaluatie besluit de Commissie of de maatregel gerechtvaardigd is, en stelt zij zo nodig andere passende maatregelen voor.
<br>De Commissie deelt haar besluit onmiddellijk aan de betrokken lidstaat en de betrokken operators mee. Zij licht ook de andere lidstaten in.
<br><br>
<br>Indien de markttoezichtautoriteit van een lidstaat een van de onderstaande feiten vaststelt, schrijft zij de betrokken aanbieder voor dat deze binnen een door haar vast te stellen termijn een einde maakt aan deze non-conformiteit:<br>
a) de CE-markering is in strijd met artikel 48 aangebracht;<br>
b) er is geen CE-markering aangebracht;<br>
c) er is geen in artikel 47 bedoelde EU-conformiteitsverklaring opgesteld;<br>
d) de in artikel 47 bedoelde EU-conformiteitsverklaring is niet correct opgesteld;<br>
e) er heeft geen registratie in de in artikel 71 bedoelde EU-databank plaatsgevonden;<br>
f) indien van toepassing, er is geen gemachtigde aangewezen;<br>
g) er is geen technische documentatie beschikbaar.
<br>Indien de in lid 1 bedoelde non-conformiteit voortduurt, neemt de markttoezichtautoriteit van de betrokken lidstaat passende en evenredige maatregelen om het op de markt aanbieden van het AI-systeem met een hoog risico te beperken of te verbieden, of het AI-systeem onverwijld terug te roepen of uit de handel te nemen.
<br><br>
<br>De Commissie wijst een of meer ondersteunende AI-teststructuren van de Unie aan om op het gebied van AI de in artikel 21, lid 6, van Verordening (EU) 2019/1020 vermelde taken uit te voeren.
<br>Onverminderd de in lid 1 bedoelde taken, verstrekken de ondersteunende AI-teststructuren van de Unie ook onafhankelijk technisch of wetenschappelijk advies op verzoek van de AI-board, de Commissie of markttoezichtautoriteiten.<br>
AFDELING 4<br>
Rechtsmiddelen
<br><br>Onverminderd andere administratieve of gerechtelijke rechtsmiddelen kan elke natuurlijke of rechtspersoon die redenen heeft om van mening te zijn dat er inbreuk is gepleegd op de bepalingen van deze verordening, klachten indienen bij de relevante markttoezichtautoriteit.<br>
Overeenkomstig Verordening (EU) 2019/1020 worden dergelijke klachten in aanmerking genomen ter uitvoering van markttoezichtactiviteiten en worden zij behandeld in overeenstemming met de specifieke procedures die de markttoezichtautoriteiten daartoe hebben vastgesteld.<br><br>
<br>Elke getroffen persoon op wie een besluit van toepassing is dat door de gebruiksverantwoordelijke wordt genomen op basis van de output van een in bijlage III vermeld AI-systeem met een hoog risico, met uitzondering van systemen die in punt 2 van die bijlage zijn vermeld, en dat rechtsgevolgen heeft voor die persoon, of op deze op vergelijkbare wijze aanzienlijke invloed heeft die hij of zij als nadelige gevolgen voor zijn of haar gezondheid, veiligheid of grondrechten beschouwt, heeft het recht om van de gebruiksverantwoordelijke duidelijke, inhoudelijke uitleg te verkrijgen bij de rol van het AI-systeem in de besluitvormingsprocedure en de voornaamste elementen van het genomen besluit.
<br>Lid 1 is niet van toepassing op het gebruik van AI-systemen waarvoor uitzonderingen op of beperkingen van de verplichting krachtens dat lid voortvloeien uit het Unierecht of het nationale recht in naleving van het Unierecht.
<br>Dit artikel is enkel van toepassing voor zover het Unierecht niet anderszins in het in lid 1 bedoelde recht voorziet.
<br><br>Richtlijn (EU) 2019/1937 is van toepassing op het melden van inbreuken op deze verordening en op de bescherming van personen die dergelijke inbreuken melden.<br>
AFDELING 5<br>
Toezicht, onderzoek, handhaving en monitoring ten aanzien van aanbieders van AI-modellen voor algemene doeleinden<br><br>
<br>De Commissie heeft exclusieve bevoegdheden voor toezicht op en handhaving van hoofdstuk V, rekening houdend met de procedurele waarborgen krachtens artikel 94. De Commissie belast het AI-bureau met de uitvoering van deze taken, onverminderd de organisatiebevoegdheden van de Commissie en de bevoegdheidsverdeling tussen de lidstaten en de Unie op grond van de Verdragen.
<br>Onverminderd artikel 75, lid 3, kunnen markttoezichtautoriteiten de Commissie verzoeken de in deze afdeling vastgestelde bevoegdheden uit te oefenen indien dat noodzakelijk en evenredig is om te helpen bij de uitvoering van hun taken krachtens deze verordening.
<br><br>
<br>Voor de uitvoering van de taken die hem uit hoofde van deze afdeling zijn toegewezen, kan het AI-bureau de nodige maatregelen nemen de daadwerkelijke uitvoering en naleving van deze verordening, inclusief hun inachtneming van goedgekeurde praktijkcodes, door aanbieders van AI-modellen voor algemene doeleinden te monitoren.
<br>Aanbieders verder in de AI-waardeketen hebben het recht een klacht in te dienen wegens inbreuk op deze verordening. Klachten moeten terdege worden gemotiveerd en moeten ten minste het volgende vermelden of bevatten:<br>
a) het contactpunt van de aanbieder van het betrokken AI-model voor algemene doeleinden;<br>
b) een beschrijving van de relevante feiten, de desbetreffende bepalingen van deze verordening en de reden waarom de aanbieder verder in de AI-waardeketen van mening is dat de aanbieder van het betrokken AI-model voor algemene doeleinden inbreuk op deze verordening heeft gemaakt;<br>
c) alle overige informatie die de aanbieder verder in de AI-waardeketen die het verzoek heeft ingediend, relevant acht, in voorkomend geval ook op eigen initiatief verzamelde informatie.
<br><br>
<br>Het wetenschappelijk panel kan het AI-bureau een gekwalificeerde waarschuwing geven indien het redenen heeft om te vermoeden dat:<br>
a) een AI-model voor algemene doeleinden een concreet aanwijsbaar risico op Unieniveau vormt, of<br>
b) een AI-model voor algemene doeleinden aan de in artikel 51 bedoelde voorwaarden beantwoordt.
<br>Naar aanleiding van een dergelijke gekwalificeerde waarschuwing kan de Commissie via het AI-Bureau, na de AI-board in kennis gesteld te hebben, de in deze afdeling vastgelegde bevoegdheden uitoefenen om de aangelegenheid te beoordelen. Het AI-bureau stelt de AI-board in kennis van elke maatregel overeenkomstig de artikelen 91 tot en met 94.
<br>Gekwalificeerde waarschuwingen moeten terdege worden gemotiveerd en ten minste het volgende vermelden of bevatten:<br>
a) het contactpunt van de aanbieder van het betrokken AI-model voor algemene doeleinden dat een systeemrisico vormt;<br>
b) een beschrijving van de relevante feiten en de redenen voor de waarschuwing door het wetenschappelijk panel;<br>
c) alle overige informatie die het wetenschappelijk panel relevant acht, in voorkomend geval ook op eigen initiatief verzamelde informatie.
<br><br>
<br>De Commissie kan de aanbieder van het betrokken AI-model voor algemene doeleinden verzoeken de door de aanbieder overeenkomstig de artikelen 53 en 55 opgestelde documentatie of eventuele aanvullende informatie te verstrekken die nodig is om te beoordelen of hij deze verordening naleeft.
<br>Alvorens het verzoek om informatie te verzenden, kan het AI-bureau een gestructureerde dialoog met de aanbieder van het AI-model voor algemene doeleinden aangaan.
<br>Op een terdege gemotiveerd verzoek van het wetenschappelijk panel kan de Commissie een verzoek om informatie tot een aanbieder van een AI-model voor algemene doeleinden richten, indien de toegang tot informatie noodzakelijk en evenredig is voor de uitvoering van de taken van het wetenschappelijk panel op grond van artikel 68, lid 2.
<br>Het verzoek om informatie vermeldt de rechtsgrondslag en het doel van het verzoek, om wat voor informatie wordt verzocht, de termijn waarbinnen de informatie moet worden verstrekt, en de in artikel 101 bepaalde geldboeten voor het verstrekken van onjuiste, onvolledige of misleidende informatie.
<br>De aanbieders van het betrokken AI-model voor algemene doeleinden of hun vertegenwoordiger verstrekken de gevraagde informatie. In het geval van rechtspersonen, bedrijven of firma’s, of indien de aanbieder geen rechtspersoonlijkheid heeft, verstrekken de personen die krachtens de wet of hun statuten gemachtigd zijn om hen te vertegenwoordigen, de gevraagde informatie namens de aanbieder van het betrokken AI-model voor algemene doeleinden. De informatie kan door naar behoren gemachtigde advocaten namens hun cliënten worden verstrekt. De cliënten blijven niettemin volledig verantwoordelijk indien de verstrekte informatie onvolledig, onjuist of misleidend is.
<br><br>
<br>Het AI-bureau kan na raadpleging van de AI-board evaluaties van het betrokken AI-model voor algemene doeleinden verrichten teneinde:<br>
a) te beoordelen of de aanbieder voldoet aan de verplichtingen van deze verordening indien de op grond van artikel 91 verzamelde informatie ontoereikend is, of<br>
b) onderzoek te doen naar systeemrisico’s op Unieniveau van AI-modellen voor algemene doeleinden met systeemrisico’s, met name naar aanleiding van een gekwalificeerde melding van het wetenschappelijk panel overeenkomstig artikel 90, lid 1, punt a).
<br>De Commissie kan besluiten om, onder meer uit het krachtens artikel 68 opgericht wetenschappelijk panel, onafhankelijke deskundigen aan te wijzen om namens haar evaluaties te verrichten. Voor deze taak aangewezen onafhankelijke deskundigen moeten voldoen aan de criteria van artikel 68, lid 2.
<br>Voor de toepassing van lid 1 kan de Commissie verzoeken om toegang tot het betrokken AI-model voor algemene doeleinden via API’s of andere passende technische middelen en instrumenten, waaronder de broncode.
<br>Het verzoek om informatie vermeldt de rechtsgrondslag en het doel en de redenen van het verzoek, de termijn waarbinnen de toegang moet worden verleend, en de in artikel 101 bepaalde geldboeten voor het niet bieden van toegang.
<br>De aanbieders van AI-modellen voor algemene doeleinden of hun vertegenwoordiger verstrekken de gevraagde informatie. In het geval van rechtspersonen, bedrijven of firma’s of indien de aanbieder geen rechtspersoonlijkheid heeft, verlenen de personen die krachtens de wet of hun statuten gemachtigd zijn om hen te vertegenwoordigen, de gevraagde toegang namens de aanbieder van het betrokken AI-model voor algemene doeleinden.
<br>De Commissie stelt uitvoeringshandelingen vast met de gedetailleerde regelingen en voorwaarden voor de evaluaties, met inbegrip van de gedetailleerde regelingen voor het betrekken van onafhankelijke deskundigen, en de selectieprocedure daarvoor. Die uitvoeringshandelingen worden volgens de in artikel 98, lid 2, bedoelde onderzoeksprocedure vastgesteld.
<br>Alvorens om toegang tot het betrokken AI-model voor algemene doeleinden te verzoeken, kan het AI-bureau een gestructureerde dialoog met de aanbieder van het AI-model voor algemene doeleinden aangaan om meer informatie te verzamelen over de interne tests van het model, de interne waarborgen ter voorkoming van systeemrisico’s en andere interne procedures en maatregelen die de aanbieder heeft genomen om dergelijke risico’s te beperken.
<br><br>
<br>Indien nodig en passend kan de Commissie aanbieders erom verzoeken:<br>
a) passende maatregelen te nemen om te voldoen aan de verplichtingen van de artikelen 53 en 54;<br>
b) risicobeperkende maatregelen te nemen indien de overeenkomstig artikel 92 verrichte evaluatie aanleiding heeft gegeven tot ernstige en concrete aanwijzingen voor een systeemrisico op Unieniveau;<br>
c) het op de markt aanbieden van het model te beperken, dan wel het uit de handel te nemen of terug te roepen.
<br>Alvorens om een maatregel te verzoeken kan het AI-bureau een gestructureerde dialoog met de aanbieder van het AI-model voor algemene doeleinden aangaan.
<br>Indien de aanbieder van het AI-model voor algemene doeleinden dat een systeemrisico vormt, tijdens de in lid 2 bedoelde gestructureerde dialoog toezeggingen doet om risicobeperkende maatregelen uit te voeren om een systeemrisico op Unieniveau aan te pakken, kan de Commissie die toezeggingen bij besluit bindend maken en verklaren dat er geen verdere gronden voor actie zijn.
<br><br>Artikel 18 van Verordening (EU) 2019/1020 is van overeenkomstige toepassing op de aanbieders van het AI-model voor algemene doeleinden, onverminderd specifiekere procedurele rechten waarin deze verordening voorziet.]]></description><link>hoofdstukken/hoofdstuk_9.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_9.md</guid><pubDate>Tue, 13 Aug 2024 13:38:35 GMT</pubDate></item><item><title><![CDATA[hoofdstuk_10]]></title><description><![CDATA[ 
 <br>HOOFDSTUK X<br>
GEDRAGSCODES EN RICHTSNOEREN<br><br>
<br>Het AI-bureau en de lidstaten stimuleren en faciliteren de opstelling van gedragscodes, met inbegrip van gerelateerde governancemechanismen, die bedoeld zijn om de vrijwillige toepassing van sommige of alle voorschriften van hoofdstuk III, afdeling 2, op andere AI-systemen dan AI-systemen met een hoog risico te bevorderen, rekening houdend met de beschikbare technische oplossingen en beste praktijken van de sector die de toepassing van dergelijke voorschriften mogelijk maken.
<br>Het AI-bureau en de lidstaten faciliteren de opstelling van gedragscodes met betrekking tot de vrijwillige toepassing, onder meer door gebruiksverantwoordelijken, van specifieke voorschriften voor alle AI-systemen, op basis van duidelijke doelstellingen en kernprestatie-indicatoren om de verwezenlijking van die doelstellingen te meten, met inbegrip van elementen zoals, maar niet beperkt tot:<br>
a) toepasselijke elementen waarin de ethische richtsnoeren van de Unie voor betrouwbare AI voorzien;<br>
b) het beoordelen en tot een minimum beperken van het effect van AI-systemen op de milieuduurzaamheid, onder meer wat betreft energie-efficiënte programmering en technieken voor het op efficiënte wijze ontwerpen, trainen en gebruiken van AI;<br>
c) het bevorderen van AI-geletterdheid, met name die van personen die te maken hebben met de ontwikkeling, de werking en het gebruik van AI;<br>
d) het faciliteren van een inclusief en divers ontwerp van AI-systemen, onder meer door de oprichting van inclusieve en diverse ontwikkelingsteams en de bevordering van de deelname van belanghebbenden aan dat proces;<br>
e) het beoordelen en voorkomen van de negatieve gevolgen van AI-systemen voor kwetsbare personen of groepen van kwetsbare personen, ook wat betreft de toegankelijkheid voor personen met een handicap, en voor gendergelijkheid.
<br>Gedragscodes kunnen door individuele aanbieders of gebruiksverantwoordelijken van AI-systemen of door organisaties die hen vertegenwoordigen, of allebei, worden opgesteld, ook met betrokkenheid van geïnteresseerde belanghebbenden en hun representatieve organisaties, met inbegrip van maatschappelijke organisaties en de academische wereld. Gedragscodes kunnen betrekking hebben op een of meer AI-systemen, gelet op de gelijkenis qua beoogd doel van de betrokken systemen.
<br>Het AI-bureau en de lidstaten houden rekening met de specifieke belangen en behoeften van kmo’s, waaronder start-ups, bij het stimuleren en faciliteren van het opstellen van gedragscodes.
<br><br>
<br>De Commissie ontwikkelt richtsnoeren over de praktische uitvoering van deze verordening, en met name over:<br>
a) de toepassing van de in de artikelen 8 tot en met 15 en artikel 25 bedoelde vereisten en verplichtingen;<br>
b) de in artikel 5 bedoelde verboden praktijken;<br>
c) de praktische uitvoering van de bepalingen in verband met substantiële wijziging;<br>
d) de praktische uitvoering van de in artikel 50 vastgelegde transparantieverplichtingen;<br>
e) gedetailleerde informatie over het verband van deze verordening met de in bijlage I vermelde harmonisatiewetgeving van de Unie en met andere relevante onderdelen van het Unierecht, onder meer wat betreft de consistentie bij de handhaving ervan;<br>
f) de toepassing van de definitie van een AI-systeem als gedefinieerd in artikel 3, punt 1).<br>
Bij het uitvaardigen van dergelijke richtsnoeren besteedt de Commissie bijzondere aandacht aan de behoeften van kmo’s, met inbegrip van start-ups, lokale overheidsinstanties en sectoren die het waarschijnlijkst door deze verordening zullen worden beïnvloed.<br>
In de in de eerste alinea van dit lid bedoelde richtsnoeren wordt terdege rekening gehouden met de algemeen erkende stand van de techniek op het gebied van AI en met de relevante in de artikelen 40 en 41 bedoelde geharmoniseerde normen en gemeenschappelijke specificaties, dan wel met de krachtens de harmonisatiewetgeving van de Unie vastgestelde geharmoniseerde normen of technische specificaties.
<br>Op verzoek van de lidstaten of het AI-bureau of op eigen initiatief actualiseert de Commissie eerder vastgestelde richtsnoeren wanneer dit nodig wordt geacht.
]]></description><link>hoofdstukken/hoofdstuk_10.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_10.md</guid><pubDate>Tue, 13 Aug 2024 13:38:39 GMT</pubDate></item><item><title><![CDATA[hoofdstuk_11]]></title><description><![CDATA[ 
 <br>HOOFDSTUK XI<br>
BEVOEGDHEIDSDELEGATIE EN COMITÉPROCEDURE<br><br>
<br>De bevoegdheid om gedelegeerde handelingen vast te stellen, wordt aan de Commissie toegekend onder de in dit artikel neergelegde voorwaarden.
<br>De in artikel 6, leden 6 en 7, artikel 7, leden 1 en 3, artikel 11, lid 3, artikel 43, leden 5 en 6, artikel 47, lid 5, artikel 51, lid 3, artikel 52, lid 4, en artikel 53, leden 5 en 6, bedoelde bevoegdheid om gedelegeerde handelingen vast te stellen, wordt aan de Commissie toegekend voor een termijn van vijf jaar met ingang van 1 augustus 2024. De Commissie stelt uiterlijk negen maanden voor het einde van de termijn van vijf jaar een verslag op over de bevoegdheidsdelegatie. De bevoegdheidsdelegatie wordt stilzwijgend met termijnen van dezelfde duur verlengd, tenzij het Europees Parlement of de Raad zich uiterlijk drie maanden voor het einde van elke termijn tegen deze verlenging verzet.
<br>Het Europees Parlement of de Raad kan de in artikel 6, leden 6 en 7, artikel 7, leden 1 en 3, artikel 11, lid 3, artikel 43, leden 5 en 6, artikel 47, lid 5, artikel 51, lid 3, artikel 52, lid 4, en artikel 53, leden 5 en 6, bedoelde bevoegdheidsdelegatie te allen tijde intrekken. Het besluit tot intrekking beëindigt de delegatie van de in dat besluit genoemde bevoegdheid. Het wordt van kracht op de dag na die van de bekendmaking ervan in het Publicatieblad van de Europese Unie of op een daarin genoemde latere datum. Het laat de geldigheid van de reeds van kracht zijnde gedelegeerde handelingen onverlet.
<br>Vóór de vaststelling van een gedelegeerde handeling raadpleegt de Commissie de door elke lidstaat aangewezen deskundigen overeenkomstig de beginselen die zijn neergelegd in het Interinstitutioneel Akkoord van 13 april 2016 over beter wetgeven.
<br>Zodra de Commissie een gedelegeerde handeling heeft vastgesteld, doet zij daarvan gelijktijdig kennisgeving aan het Europees Parlement en de Raad.
<br>Een op grond van artikel 6, lid 6 of lid 7, artikel 7, lid 1 of lid 3, artikel 11, lid 3, artikel 43, lid 5 of lid 6, artikel 47, lid 5, artikel 51, lid 3, artikel 52, lid 4, of artikel 53, lid 5 of lid 6, vastgestelde gedelegeerde handeling treedt alleen in werking indien het Europees Parlement noch de Raad daartegen binnen een termijn van drie maanden na de kennisgeving van de handeling aan het Europees Parlement en de Raad bezwaar heeft gemaakt, of indien zowel het Europees Parlement als de Raad voor het verstrijken van die termijn de Commissie hebben meegedeeld dat zij daartegen geen bezwaar zullen maken. Die termijn wordt op initiatief van het Europees Parlement of de Raad met drie maanden verlengd.
<br><br>
<br>De Commissie wordt bijgestaan door een comité. Dat comité is een comité in de zin van Verordening (EU) nr. 182/2011.
<br>Wanneer naar dit lid wordt verwezen, is artikel 5 van Verordening (EU) nr. 182/2011 van toepassing.
]]></description><link>hoofdstukken/hoofdstuk_11.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_11.md</guid><pubDate>Tue, 13 Aug 2024 13:38:43 GMT</pubDate></item><item><title><![CDATA[HOOFDSTUK XII SANCTIES]]></title><description><![CDATA[ 
 <br><br><br>
<br>Overeenkomstig de voorwaarden van deze verordening stellen de lidstaten de voorschriften vast voor sancties en andere handhavingsmaatregelen, die ook waarschuwingen en niet-monetaire maatregelen kunnen omvatten, die van toepassing zijn op inbreuken op deze verordening door operatoren, en nemen zij alle nodige maatregelen om ervoor te zorgen dat deze naar behoren en doeltreffend worden uitgevoerd, daarbij rekening houdend met de richtsnoeren die de Commissie op grond van artikel 96 heeft uitgevaardigd. De sancties moeten doeltreffend, evenredig en afschrikkend zijn. Hierbij wordt rekening gehouden met de belangen van kmo’s, met inbegrip van start-ups, en hun economische levensvatbaarheid.
<br>De lidstaten stellen de Commissie onverwijld en uiterlijk op de datum van toepassing in kennis van de in lid 1 bedoelde voorschriften voor sancties en andere handhavingsmaatregelen en delen haar onverwijld alle latere wijzigingen daarvan mee.
<br>Voor de niet-naleving van het verbod op de in artikel 5 bedoelde AI-praktijken gelden administratieve geldboeten tot 35 000 000 EUR of, indien de overtreder een onderneming is, tot 7 % van haar totale wereldwijde jaarlijkse omzet voor het voorafgaande boekjaar, indien dat hoger is.
<br>Voor de niet-naleving van een van de volgende bepalingen in verband met operatoren of aangemelde instanties, uitgezonderd die welke zijn neergelegd in artikel 5, gelden administratieve geldboeten tot 15 000 000 EUR of, indien de overtreder een onderneming is, tot 3 % van haar totale wereldwijde jaarlijkse omzet voor het voorafgaande boekjaar, indien dat hoger is:<br>
a) verplichtingen voor aanbieders op grond van artikel 16;<br>
b) verplichtingen voor gemachtigden op grond van artikel 22;<br>
c) verplichtingen voor importeurs op grond van artikel 23;<br>
d) verplichtingen voor distributeurs op grond van artikel 24;<br>
e) verplichtingen voor gebruiksverantwoordelijken op grond van artikel 26;<br>
f) eisen en verplichtingen voor aangemelde instanties op grond van artikel 31, artikel 33, lid 1, 3 of 4, of artikel 34;<br>
g) transparantieverplichtingen voor aanbieders en gebruiksverantwoordelijken op grond van artikel 50.
<br>Voor de verstrekking van onjuiste, onvolledige of misleidende informatie aan aangemelde instanties of nationale bevoegde autoriteiten naar aanleiding van een verzoek, gelden administratieve geldboeten tot 7 500 000 EUR of, indien de overtreder een onderneming is, tot 1 % van haar totale wereldwijde jaarlijkse omzet voor het voorafgaande boekjaar, indien dat hoger is.
<br>In het geval van kmo’s, met inbegrip van start-ups, komt elke in dit artikel bedoelde boete neer op de percentages of, indien dat lager is, het bedrag als bedoeld in de leden 3, 4 en 5.
<br>Bij het besluiten om al dan niet een administratieve geldboete op te leggen en bij het bepalen van het bedrag van de administratieve geldboete in elk individueel geval worden alle relevante omstandigheden van de specifieke situatie in aanmerking genomen en wordt naargelang van het geval rekening gehouden met het volgende:<br>
a) de aard, ernst en duur van de inbreuk en de gevolgen ervan, rekening houdend met het doel van het AI-systeem en, indien passend, het aantal getroffen personen en de omvang van de door hen geleden schade;<br>
b) of administratieve geldboeten reeds door andere markttoezichtautoriteiten voor dezelfde inbreuk op dezelfde operator zijn toegepast;<br>
c) of administratieve geldboeten reeds door andere autoriteiten op dezelfde operator zijn toegepast voor inbreuken op andere bepalingen van het Unierecht of van nationaal recht, wanneer dergelijke inbreuken het resultaat zijn van hetzelfde handelen of nalaten dat een relevante inbreuk op deze verordening vormt;<br>
d) de omvang, de jaaromzet en het marktaandeel van de operator die de inbreuk pleegt;<br>
e) elke andere op de omstandigheden van de zaak toepasselijke verzwarende of verzachtende factor, zoals gemaakte financiële winsten, of vermeden verliezen, die al dan niet rechtstreeks uit de inbreuk voortvloeien;<br>
f) de mate waarin er met de nationale bevoegde autoriteiten is samengewerkt om de inbreuk te verhelpen en de mogelijke negatieve gevolgen daarvan te beperken;<br>
g) de mate waarin de operator verantwoordelijk is, rekening houdend met de technische en organisatorische maatregelen die hij heeft genomen;<br>
h) de wijze waarop de nationale bevoegde autoriteiten kennis hebben gekregen van de inbreuk, met name of, en zo ja in hoeverre, de operator de inbreuk heeft gemeld;<br>
i) de opzettelijke of nalatige aard van de inbreuk;<br>
j) door de operator genomen maatregelen om de door de getroffen personen geleden schade te beperken.
<br>Elke lidstaat stelt regels vast betreffende de vraag in hoeverre administratieve geldboeten kunnen worden opgelegd aan in die lidstaat gevestigde overheidsinstanties of -organen.
<br>Afhankelijk van het rechtsstelsel van de lidstaten kunnen de regels voor administratieve geldboeten zodanig worden toegepast dat de boeten worden opgelegd door bevoegde nationale rechters of andere instanties, naargelang van het geval in die lidstaten. De toepassing van zulke regels in die lidstaten heeft een gelijkwaardig effect.
<br>De uitoefening van bevoegdheden uit hoofde van dit artikel is onderworpen aan passende procedurele waarborgen overeenkomstig het Unierecht en het nationale recht, waaronder een doeltreffende voorziening in rechte en een eerlijke rechtsbedeling.
<br>De lidstaten brengen jaarlijks verslag uit aan de Commissie over de administratieve geldboeten die zij in de loop van dat jaar overeenkomstig dit artikel hebben opgelegd, en over alle daarmee verband houdende geschil- of gerechtelijke procedures.
<br><br>
<br>De Europese Toezichthouder voor gegevensbescherming kan administratieve geldboeten opleggen aan instellingen, organen en instanties van de Unie die binnen het toepassingsgebied van deze verordening vallen. Bij het besluiten om al dan niet een Administratieve geldboete op te leggen en het bepalen van het bedrag van de administratieve geldboete in elk individueel geval worden alle relevante omstandigheden van de specifieke situatie in aanmerking genomen en wordt terdege rekening gehouden met het volgende:<br>
a) de aard, ernst en duur van de inbreuk en de gevolgen ervan, rekening houdend met het doel van het AI-systeem in kwestie, alsmede, waar dit passend is, het aantal getroffen personen en de omvang van de door hen geleden schade;<br>
b) de mate van verantwoordelijkheid van de instelling, het orgaan of de instantie van de Unie, rekening houdend met de technische en organisatorische maatregelen die zij hebben genomen;<br>
c) maatregelen die de instelling, het orgaan of de instantie van de Unie heeft genomen om de door de getroffen personen geleden schade te beperken;<br>
d) de mate van samenwerking met de Europese Toezichthouder voor gegevensbescherming om de inbreuk te verhelpen en de mogelijke nadelige gevolgen van de inbreuk te beperken, waaronder naleving van eventuele maatregelen die eerder door de Europese Toezichthouder voor gegevensbescherming ten aanzien van dezelfde kwestie aan de instelling, het orgaan of de instantie in kwestie van de Unie zijn opgelegd;<br>
e) soortgelijke eerdere inbreuken door de instelling, het orgaan of de instantie van de Unie;<br>
f) de wijze waarop de Europese Toezichthouder voor gegevensbescherming kennis heeft gekregen van de inbreuk, met name of, en zo ja in hoeverre, de instelling, het orgaan of de instantie van de Unie de inbreuk heeft gemeld;<br>
g) de jaarlijkse begroting van de instelling, het orgaan of de instantie van de Unie.
<br>Voor de niet-naleving van het verbod op de in artikel 5 bedoelde AI-praktijken gelden administratieve geldboeten tot 1 500 000 EUR.
<br>Voor de non-conformiteit van het AI-systeem met eisen of verplichtingen krachtens deze verordening, uitgezonderd die bepaald in artikel 5, gelden administratieve geldboeten tot 750 000 EUR.
<br>Alvorens een besluit op grond van dit artikel te nemen, stelt de Europese Toezichthouder voor gegevensbescherming de instelling, het orgaan of de instantie van de Unie ten aanzien waarvan hij een procedure voert, in de gelegenheid om te worden gehoord over de mogelijke inbreuk. De Europese Toezichthouder voor gegevens-bescherming baseert zijn besluiten uitsluitend op elementen en omstandigheden waarover de betrokken partijen opmerkingen hebben kunnen maken. Eventuele indieners van klachten worden nauw betrokken bij de procedure.
<br>Het recht van verdediging van de partijen wordt in de loop van de procedure ten volle geëerbiedigd. Zij hebben recht op toegang tot het dossier van de Europese Toezichthouder voor gegevensbescherming, onder voorbehoud van het gerechtvaardigde belang van andere natuurlijke personen of ondernemingen bij de bescherming van hun persoonsgegevens of bedrijfsgeheimen.
<br>De bedragen die worden geïnd door het opleggen van de geldboeten van dit artikel, dragen bij aan de algemene begroting van de Unie. De geldboeten doen geen afbreuk aan de doeltreffende werking van de instelling, het orgaan of de instantie van de Unie waaraan een geldboete is opgelegd.
<br>De Europese Toezichthouder voor gegevensbescherming stelt de Commissie jaarlijks in kennis van de administratieve geldboeten die hij op grond van dit artikel heeft opgelegd en van alle geschil- of gerechtelijke procedures die hij heeft ingeleid.
<br><br>
<br>De Commissie kan aanbieders van AI-modellen voor algemene doeleinden geldboeten opleggen van ten hoogste 3 % van hun jaarlijkse totale wereldwijde omzet in het voorgaande boekjaar of 15 000 000 EUR, indien dat hoger is, wanneer de Commissie vaststelt dat de aanbieder opzettelijk of uit onachtzaamheid:<br>
a) inbreuk heeft gepleegd op de desbetreffende bepalingen van deze verordening;<br>
b) niet heeft voldaan aan een verzoek om een document of om informatie op grond van artikel 91, of onjuiste, onvolledige of misleidende informatie heeft verstrekt;<br>
c) een op grond van artikel 93 gevraagde maatregel niet heeft nageleefd;<br>
d) de Commissie geen toegang tot het AI-model voor algemene doeleinden of het AI-model voor algemene doeleinden met een systeemrisico heeft gegeven voor de doeleinden van de evaluatie op grond van artikel 92.<br>
Bij de vaststelling van het bedrag van de geldboete of de dwangsom wordt met de aard, de ernst en de duur van de inbreuk rekening gehouden, met inachtneming van de beginselen van evenredigheid en redelijkheid. De Commissie houdt ook rekening met verbintenissen die zijn aangegaan overeenkomstig artikel 93, lid 3, of die zijn aangegaan in relevante praktijkcodes overeenkomstig artikel 56.
<br>Alvorens het besluit op grond van lid 1 vast te stellen, deelt de Commissie haar voorlopige bevindingen mee aan de aanbieder van het AI-model voor algemene doeleinden, en stelt zij hem in de gelegenheid te worden gehoord.
<br>De overeenkomstig dit artikel opgelegde geldboeten zijn doeltreffend, evenredig en afschrikkend.
<br>Informatie over geldboeten die uit hoofde van dit artikel zijn opgelegd, wordt in voorkomend geval ook aan de AI-board meegedeeld.
<br>Het Hof van Justitie van de Europese Unie heeft volledige rechtsmacht ter zake van beroep tegen besluiten waarbij de Commissie krachtens dit artikel een geldboete vaststelt. Het kan de opgelegde geldboete vernietigen, verlagen of verhogen.
<br>De Commissie stelt uitvoeringshandelingen vast met gedetailleerde regelingen en procedurele waarborgen voor procedures met het oog op de eventuele vaststelling van besluiten op grond van lid 1 van dit artikel. Die uitvoeringshandelingen worden vastgesteld volgens de in artikel 98, lid 2, bedoelde onderzoeksprocedure.
]]></description><link>hoofdstukken/hoofdstuk_12.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_12.md</guid><pubDate>Tue, 13 Aug 2024 13:56:16 GMT</pubDate></item><item><title><![CDATA[HOOFDSTUK XIII SLOTBEPALINGEN]]></title><description><![CDATA[ 
 <br><br><br>Aan artikel 4, lid 3, van Verordening (EG) nr. 300/2008 wordt de volgende alinea toegevoegd:<br>
“Bij het vaststellen van gedetailleerde maatregelen met betrekking tot technische specificaties en procedures voor de goedkeuring en het gebruik van veiligheidsuitrusting betreffende artificiële-intelligentiesystemen in de zin van Verordening (EU) 2024/1689 van het Europees Parlement en de Raad <a class="internal-link" data-href="#ntr*1-L_202401689NL.000101-E0058" href="about:blank#ntr*1-L_202401689NL.000101-E0058" target="_self" rel="noopener">(*1)</a>, worden de eisen van hoofdstuk III, afdeling 2, van die verordening in aanmerking genomen.<br><br>Aan artikel 17, lid 5, van Verordening (EU) nr. 167/2013 wordt de volgende alinea toegevoegd:<br>
“Bij het vaststellen van gedelegeerde handelingen krachtens de eerste alinea betreffende artificiële-intelligentiesystemen die veiligheidscomponenten zijn in de zin van Verordening (EU) 2024/1689 van het Europees Parlement en de Raad <a class="internal-link" data-href="#ntr*2-L_202401689NL.000101-E0059" href="about:blank#ntr*2-L_202401689NL.000101-E0059" target="_self" rel="noopener">(*2)</a>, worden de eisen van hoofdstuk III, afdeling 2, van die verordening in aanmerking genomen.<br><br>Aan artikel 22, lid 5, van Verordening (EU) nr. 168/2013 wordt de volgende alinea toegevoegd:<br>
“Bij het vaststellen van gedelegeerde handelingen krachtens de eerste alinea betreffende artificiële-intelligentiesystemen die veiligheidscomponenten zijn in de zin van Verordening (EU) 2024/1689 van het Europees Parlement en de Raad <a class="internal-link" data-href="#ntr*3-L_202401689NL.000101-E0060" href="about:blank#ntr*3-L_202401689NL.000101-E0060" target="_self" rel="noopener">(*3)</a>, worden de eisen van hoofdstuk III, afdeling 2, van die verordening in aanmerking genomen.<br><br>Aan artikel 8 van Richtlijn 2014/90/EU wordt het volgende lid toegevoegd:<br>
“5. Voor artificiële-intelligentiesystemen die veiligheidscomponenten zijn in de zin van Verordening (EU) 2024/1689 van het Europees Parlement en de Raad <a class="internal-link" data-href="#ntr*4-L_202401689NL.000101-E0061" href="about:blank#ntr*4-L_202401689NL.000101-E0061" target="_self" rel="noopener">(*4)</a>, neemt de Commissie bij het uitvoeren van haar activiteiten krachtens lid 1 en bij het vaststellen van technische specificaties en testnormen overeenkomstig de leden 2 en 3 de eisen van hoofdstuk III, hoofdstuk 2, van die verordening in aanmerking.<br><br>Aan artikel 5 van Richtlijn (EU) 2016/797 wordt het volgende lid toegevoegd:<br>
“12. Bij het vaststellen van gedelegeerde handelingen krachtens lid 1 en uitvoeringshandelingen krachtens lid 11 betreffende artificiële-intelligentiesystemen die veiligheidscomponenten zijn in de zin van Verordening (EU) 2024/1689 van het Europees Parlement en de Raad <a class="internal-link" data-href="#ntr*5-L_202401689NL.000101-E0062" href="about:blank#ntr*5-L_202401689NL.000101-E0062" target="_self" rel="noopener">(*5)</a>, worden de eisen van hoofdstuk III, afdeling 2, van die verordening in aanmerking genomen.<br><br>Aan artikel 5 van Verordening (EU) 2018/858 wordt het volgende lid toegevoegd:<br>
“4. Bij het vaststellen van gedelegeerde handelingen krachtens lid 3 betreffende artificiële-intelligentiesystemen die veiligheidscomponenten zijn in de zin van Verordening (EU) 2024/1689 van het Europees Parlement en de Raad <a class="internal-link" data-href="#ntr*6-L_202401689NL.000101-E0063" href="about:blank#ntr*6-L_202401689NL.000101-E0063" target="_self" rel="noopener">(*6)</a>, worden de eisen van hoofdstuk III, afdeling 2, van die verordening in aanmerking genomen.<br><br>Verordening (EU) 2018/1139 wordt als volgt gewijzigd:<br>
<br>Aan artikel 17 wordt het volgende lid toegevoegd:<br>
“3. Onverminderd lid 2 worden bij het vaststellen van uitvoeringshandelingen krachtens lid 1 betreffende artificiële-intelligentiesystemen die veiligheidscomponenten zijn in de zin van Verordening (EU) 2024/1689 van het Europees Parlement en de Raad <a class="internal-link" data-href="#ntr*7-L_202401689NL.000101-E0064" href="about:blank#ntr*7-L_202401689NL.000101-E0064" target="_self" rel="noopener">(*7)</a>, de eisen van hoofdstuk III, afdeling 2, van die verordening in aanmerking genomen.<br>
<a class="internal-link" data-href="#ntc*7-L_202401689NL.000101-E0064" href="about:blank#ntc*7-L_202401689NL.000101-E0064" target="_self" rel="noopener">(*7)</a> Verordening (EU) 2024/1689 van het Europees Parlement en de Raad van 13 juni 2024 tot vaststelling van geharmoniseerde regels betreffende artificiële intelligentie en tot wijziging van de Verordeningen (EG) nr. 300/2008, (EU) nr. 167/2013, (EU) nr. 168/2013, (EU) 2018/858, (EU) 2018/1139 en (EU) 2019/2144 en de Richtlijnen 2014/90/EU, (EU) 2016/797 en (EU) 2020/1828 (verordening artificiële intelligentie) (<a data-tooltip-position="top" aria-label="http://data.europa.eu/eli/reg/2024/1689/oj" rel="noopener" class="external-link" href="http://data.europa.eu/eli/reg/2024/1689/oj" target="_blank">PB L, 2024/1689, 12.7.2024, ELI: http://data.europa.eu/eli/reg/2024/1689/oj</a>).”."
<br>Aan artikel 19 wordt het volgende lid toegevoegd:<br>
“4. Bij het vaststellen van gedelegeerde handelingen krachtens de leden 1 en 2 betreffende artificiële-intelligentiesystemen die veiligheidscomponenten zijn in de zin van Verordening (EU) 2024/1689, worden de eisen van hoofdstuk III, afdeling 2, van die verordening in aanmerking genomen.”.
<br>Aan artikel 43 wordt het volgende lid toegevoegd:<br>
“4. Bij het vaststellen van uitvoeringshandelingen krachtens lid 1 betreffende artificiële-intelligentiesystemen die veiligheidscomponenten zijn in de zin van Verordening (EU) 2024/1689, worden de eisen van hoofdstuk III, afdeling 2, van die verordening in aanmerking genomen.”.
<br>Aan artikel 47 wordt het volgende lid toegevoegd:<br>
“3. Bij het vaststellen van gedelegeerde handelingen krachtens de leden 1 en 2 betreffende artificiële-intelligentiesystemen die veiligheidscomponenten zijn in de zin van Verordening (EU) 2024/1689, worden de eisen van hoofdstuk III, afdeling 2, van die verordening in aanmerking genomen.”.
<br>Aan artikel 57 wordt de volgende alinea toegevoegd:<br>
“Bij het vaststellen van die uitvoeringshandelingen betreffende artificiële-intelligentiesystemen die veiligheidscomponenten zijn in de zin van Verordening (EU) 2024/1689, worden de eisen van hoofdstuk III, afdeling 2, van die verordening in aanmerking genomen.”.
<br>Aan artikel 58 wordt het volgende lid toegevoegd:<br>
“3. Bij het vaststellen van gedelegeerde handelingen krachtens de leden 1 en 2 betreffende artificiële-intelligentiesystemen die veiligheidscomponenten zijn in de zin van Verordening (EU) 2024/1689, worden de eisen van hoofdstuk III, afdeling 2, van die verordening in aanmerking genomen.”.
<br><br>Aan artikel 11 van Verordening (EU) 2019/2144 wordt het volgende lid toegevoegd:<br>
“3. Bij het vaststellen van de uitvoeringshandelingen krachtens lid 2 betreffende artificiële-intelligentiesystemen die veiligheidscomponenten zijn in de zin van Verordening (EU) 2024/1689 van het Europees Parlement en de Raad <a class="internal-link" data-href="#ntr*8-L_202401689NL.000101-E0065" href="about:blank#ntr*8-L_202401689NL.000101-E0065" target="_self" rel="noopener">(*8)</a>, worden de eisen van hoofdstuk III, afdeling 2, van die verordening in aanmerking genomen.<br><br>In bijlage I bij Richtlijn (EU) 2020/1828 van het Europees Parlement en de Raad <a class="internal-link" data-href="#ntr58-L_202401689NL.000101-E0066" href="about:blank#ntr58-L_202401689NL.000101-E0066" target="_self" rel="noopener">(58)</a> wordt het volgende punt toegevoegd:<br>
“68)<br>
Verordening (EU) 2024/1689 van het Europees Parlement en de Raad van 13 juni 2024 tot vaststelling van geharmoniseerde regels betreffende artificiële intelligentie en tot wijziging van de Verordeningen (EG) nr. 300/2008, (EU) nr. 167/2013, (EU) nr. 168/2013, (EU) 2018/858, (EU) 2018/1139 en (EU) 2019/2144 en de Richtlijnen 2014/90/EU, (EU) 2016/797 en (EU) 2020/1828 (verordening artificiële intelligentie) (<a data-tooltip-position="top" aria-label="http://data.europa.eu/eli/reg/2024/1689/oj" rel="noopener" class="external-link" href="http://data.europa.eu/eli/reg/2024/1689/oj" target="_blank">PB L, 2024/1689, 12.7.2024, ELI: http://data.europa.eu/eli/reg/2024/1689/oj</a>).”.<br><br>
<br>Onverminderd de toepassing van artikel 5 als bedoeld in artikel 113, lid 3, punt a), worden AI-systemen die componenten zijn van de bij de in bijlage X vermelde rechtshandelingen opgezette grootschalige IT-systemen die vóór 2 augustus 2027 in de handel zijn gebracht of in gebruik zijn gesteld, uiterlijk op 31 december 2030 in overeenstemming met deze verordening gebracht.<br>
De in deze verordening vastgelegde eisen worden in aanmerking genomen bij de evaluatie van elk volgens de in bijlage X vermelde rechtshandelingen opgezet grootschalig IT-systeem die moet worden uitgevoerd zoals bepaald in die rechtshandelingen en wanneer die rechtshandelingen worden vervangen of gewijzigd.
<br>Onverminderd de toepassing van artikel 5 als bedoeld in artikel 113, lid 3, punt a), is deze verordening alleen van toepassing op operatoren van AI-systemen met een hoog risico, met uitzondering van de in lid 1 van dit artikel bedoelde systemen, die vóór 2 augustus 2026 in de handel zijn gebracht of in gebruik zijn gesteld indien die systemen vanaf die datum aanzienlijke wijzigingen in hun ontwerp ondergaan. In ieder geval ondernemen de aanbieders en gebruiksverantwoordelijken van AI-systemen met een hoog risico die bedoeld zijn om door overheidsinstanties te worden gebruikt, de nodige stappen om uiterlijk op 2 augustus 2030 aan de eisen en verplichtingen van deze verordening te voldoen.
<br>Aanbieders van AI-modellen voor algemene doeleinden die vóór 2 augustus 2025 in de handel zijn gebracht, ondernemen de nodige stappen om uiterlijk op 2 augustus 2027 aan de verplichtingen van deze verordening te voldoen.
<br><br>
<br>De Commissie beoordeelt vanaf de inwerkingtreding van deze verordening en tot het einde van de in artikel 97 vermelde periode van de bevoegdheidsdelegatie eenmaal per jaar of de lijst van bijlage III en de lijst van de verboden AI-praktijken in artikel 5 moeten worden gewijzigd. De Commissie deelt de bevindingen van die beoordeling mee aan het Europees Parlement en de Raad.
<br>Uiterlijk op 2 augustus 2028 en vervolgens om de vier jaar verricht de Commissie een evaluatie en brengt zij verslag uit bij het Europees Parlement en de Raad over het volgende:<br>
a) de noodzaak om bestaande gebiedsrubrieken uit te breiden of nieuwe gebiedsrubrieken toe te voegen aan bijlage III;<br>
b) wijzigingen van de lijst van AI-systemen die aanvullende transparantiemaatregelen vereisen krachtens artikel 50;<br>
c) wijzigingen ter verbetering van de doeltreffendheid van het toezicht- en governancesysteem.
<br>Uiterlijk op 2 augustus 2029 en vervolgens om de vier jaar dient de Commissie bij het Europees Parlement en de Raad een verslag in over de evaluatie en de toetsing van deze verordening. Het verslag bevat een beoordeling van de structuur van de handhaving en de eventuele noodzaak van een Agentschap van de Unie om vastgestelde tekortkomingen op te lossen. Op basis van de bevindingen gaat dat verslag indien passend vergezeld van een voorstel tot wijziging van deze verordening. De verslagen worden openbaar gemaakt.
<br>In de in lid 2 bedoelde verslagen wordt specifieke aandacht besteed aan het volgende:<br>
a) de status van de financiële, technische en personele middelen van de nationale bevoegde autoriteiten teneinde de hun krachtens deze verordening toegewezen taken doeltreffend uit te voeren;<br>
b) de stand van zaken wat betreft sancties, met name administratieve geldboeten als bedoeld in artikel 99, lid 1, die door lidstaten zijn toegepast wegens inbreuken op deze verordening;<br>
c) ter ondersteuning van deze verordening aangenomen geharmoniseerde normen en ontwikkelde gemeenschappelijke specificaties;<br>
d) het aantal ondernemingen, met daarbij ook het aantal kmo’s, dat nadat deze verordening van toepassing is geworden, tot de markt toetreedt.
<br>Uiterlijk op 2 augustus 2028 evalueert de Commissie de werking van het AI-bureau, de vraag of het Bureau voldoende bevoegdheden heeft gekregen om zijn taken uit te voeren en of het voor de correcte uitvoering en handhaving van deze verordening relevant en noodzakelijk zou zijn om het AI-bureau en zijn handhavingsbevoegdheden op te schalen en zijn middelen uit te breiden. De Commissie dient dit evaluatieverslag in bij het Europees Parlement en bij de raad.
<br>Uiterlijk op 2 augustus 2028 en vervolgens om de vier jaar dient de Commissie een verslag in met een evaluatie van de vooruitgang bij de ontwikkeling van normalisatieproducten met betrekking tot de energie-efficiënte ontwikkeling van AI-modellen voor algemene doeleinden, en beoordeelt zij of verdere al dan niet bindende maatregelen of acties nodig zijn. Dit verslag wordt toegezonden aan het Europees Parlement en de Raad en openbaar gemaakt.
<br>Uiterlijk op 2 augustus 2028 en vervolgens om de drie jaar evalueert de Commissie de impact en de doeltreffendheid van vrijwillige gedragscodes om de toepassing van de eisen van hoofdstuk III, afdeling 2, voor AI-systemen die geen AI-systemen met een hoog risico zijn en eventuele andere aanvullende eisen voor AI-systemen die geen AI-systemen met een hoog risico zijn te bevorderen, ook wat betreft milieuduurzaamheid.
<br>Voor de toepassing van de leden 1 tot en met 7 verstrekken de AI-board, de lidstaten en nationale bevoegde autoriteiten onverwijld informatie aan de Commissie op haar verzoek.
<br>Bij de uitvoering van de in de leden 1 tot en met 7 vermelde evaluaties en toetsingen neemt de Commissie de standpunten en bevindingen van de AI-board, het Europees Parlement, de Raad en van andere relevante instanties of bronnen in aanmerking.
<br>Indien nodig dient de Commissie passende voorstellen in teneinde deze verordening te wijzigen, met name rekening houdend met ontwikkelingen in de technologie, het effect van AI-systemen op gezondheid en veiligheid, en op de grondrechten, en de voortgang in de informatiemaatschappij.
<br>Om de evaluaties en toetsingen als bedoeld in de leden 1 tot en met 7 van dit artikel uit te voeren, ontwikkelt het AI-bureau een objectieve en participatieve methodologie voor de evaluatie van de risiconiveaus, op basis van de in de desbetreffende artikelen beschreven criteria en opname van nieuwe systemen in:<br>
a) de lijst in bijlage III, waaronder de uitbreiding van bestaande gebiedsrubrieken of de toevoeging van nieuwe rubrieken in die bijlage;<br>
b) de lijst van verboden praktijken als vastgelegd in artikel 5, en<br>
c) de lijst van AI-systemen die aanvullende transparantieverplichtingen met zich meebrengen op grond van artikel 50.
<br>Elke wijziging van deze verordening op grond van lid 10, of relevante gedelegeerde handelingen of uitvoeringshandelingen, die betrekking heeft op sectorale harmonisatie-wetgeving van de Unie zoals vermeld in bijlage I, afdeling B, wordt rekening gehouden met de regelgevingsspecificaties van elke sector, met de bestaande mechanismen voor governance, conformiteitsbeoordeling en handhaving en met de autoriteiten die daarin zijn vastgesteld.
<br>Uiterlijk op 2 augustus 2031 voert de Commissie een beoordeling uit van de handhaving van deze verordening en brengt hierover verslag uit aan het Europees Parlement, de Raad en het Europees Economisch en Sociaal Comité, waarbij de eerste jaren van toepassing van deze verordening worden meegenomen. Op basis van de bevindingen gaat dit verslag, indien van toepassing, vergezeld van een voorstel tot wijziging van deze verordening met betrekking tot de handhavingsstructuur en de behoefte aan een agentschap van de Unie om eventueel vastgestelde tekortkomingen op te lossen.
<br><br>Deze verordening treedt in werking op de twintigste dag na die van de bekendmaking ervan in het Publicatieblad van de Europese Unie.<br>
Zij is van toepassing met ingang van 2 augustus 2026.<br>
Evenwel zijn:<br>
a) de hoofdstukken I en II van toepassing met ingang van 2 februari 2025;<br>
b) hoofdstuk III, afdeling 4, hoofdstuk V, hoofdstuk VII en hoofdstuk XII en artikel 78 van toepassing met ingang van 2 augustus 2025, met uitzondering van artikel 101;<br>
c) artikel 6, lid 1, en de overeenkomstige verplichtingen van deze verordening van toepassing met ingang van 2 augustus 2027.<br>
Deze verordening is verbindend in al haar onderdelen en is rechtstreeks toepasselijk in elke lidstaat.<br><br><a class="internal-link" data-href="#ntc1-L_202401689NL.000101-E0001" href="about:blank#ntc1-L_202401689NL.000101-E0001" target="_self" rel="noopener">(1)</a> <a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:C:2021:517:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:C:2021:517:TOC" target="_self" rel="noopener">PB C 517 van 22.12.2021, blz. 56</a>.<br>
<a class="internal-link" data-href="#ntc2-L_202401689NL.000101-E0002" href="about:blank#ntc2-L_202401689NL.000101-E0002" target="_self" rel="noopener">(2)</a> <a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:C:2022:115:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:C:2022:115:TOC" target="_self" rel="noopener">PB C 115 van 11.3.2022, blz. 5</a>.<br>
<a class="internal-link" data-href="#ntc3-L_202401689NL.000101-E0003" href="about:blank#ntc3-L_202401689NL.000101-E0003" target="_self" rel="noopener">(3)</a> <a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:C:2022:097:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:C:2022:097:TOC" target="_self" rel="noopener">PB C 97 van 28.2.2022, blz. 60</a>.<br>
<a class="internal-link" data-href="#ntc4-L_202401689NL.000101-E0004" href="about:blank#ntc4-L_202401689NL.000101-E0004" target="_self" rel="noopener">(4)</a> Standpunt van het Europees Parlement van 13 maart 2024 (nog niet bekendgemaakt in het Publicatieblad) en besluit van de Raad van 21 mei 2024.<br>
<a class="internal-link" data-href="#ntc5-L_202401689NL.000101-E0005" href="about:blank#ntc5-L_202401689NL.000101-E0005" target="_self" rel="noopener">(5)</a> Europese Raad, buitengewone bijeenkomst van de Europese Raad (1 en 2 oktober 2020) — Conclusies, EUCO 13/20, 2020, blz. 6.<br>
<a class="internal-link" data-href="#ntc6-L_202401689NL.000101-E0006" href="about:blank#ntc6-L_202401689NL.000101-E0006" target="_self" rel="noopener">(6)</a> Resolutie van het Europees Parlement van 20 oktober 2020 met aanbevelingen aan de Commissie betreffende een kader voor ethische aspecten van artificiële intelligentie, robotica en aanverwante technologieën, 2020/2012(INL).<br>
<a class="internal-link" data-href="#ntc7-L_202401689NL.000101-E0007" href="about:blank#ntc7-L_202401689NL.000101-E0007" target="_self" rel="noopener">(7)</a> Verordening (EG) nr. 765/2008 van het Europees Parlement en de Raad van 9 juli 2008 tot vaststelling van de eisen inzake accreditatie en tot intrekking van Verordening (EEG) nr. 339/93 (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2008:218:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2008:218:TOC" target="_self" rel="noopener">PB L 218 van 13.8.2008, blz. 30</a>).<br>
<a class="internal-link" data-href="#ntc8-L_202401689NL.000101-E0008" href="about:blank#ntc8-L_202401689NL.000101-E0008" target="_self" rel="noopener">(8)</a> Besluit nr. 768/2008/EG van het Europees Parlement en de Raad van 9 juli 2008 betreffende een gemeenschappelijk kader voor het verhandelen van producten en tot intrekking van Besluit 93/465/EEG van de Raad (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2008:218:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2008:218:TOC" target="_self" rel="noopener">PB L 218 van 13.8.2008, blz. 82</a>).<br>
<a class="internal-link" data-href="#ntc9-L_202401689NL.000101-E0009" href="about:blank#ntc9-L_202401689NL.000101-E0009" target="_self" rel="noopener">(9)</a> Verordening (EU) 2019/1020 van het Europees Parlement en de Raad van 20 juni 2019 betreffende markttoezicht en conformiteit van producten en tot wijziging van Richtlijn 2004/42/EG en de Verordeningen (EG) nr. 765/2008 en (EU) nr. 305/2011 (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2019:169:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2019:169:TOC" target="_self" rel="noopener">PB L 169 van 25.6.2019, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc10-L_202401689NL.000101-E0010" href="about:blank#ntc10-L_202401689NL.000101-E0010" target="_self" rel="noopener">(10)</a> Richtlijn 85/374/EEG van de Raad van 25 juli 1985 betreffende de onderlinge aanpassing van de wettelijke en bestuursrechtelijke bepalingen der lidstaten inzake de aansprakelijkheid voor producten met gebreken (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:1985:210:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:1985:210:TOC" target="_self" rel="noopener">PB L 210 van 7.8.1985, blz. 29</a>).<br>
<a class="internal-link" data-href="#ntc11-L_202401689NL.000101-E0011" href="about:blank#ntc11-L_202401689NL.000101-E0011" target="_self" rel="noopener">(11)</a> Verordening (EU) 2016/679 van het Europees Parlement en de Raad van 27 april 2016 betreffende de bescherming van natuurlijke personen in verband met de verwerking van persoonsgegevens en betreffende het vrije verkeer van die gegevens en tot intrekking van Richtlijn 95/46/EG (algemene verordening gegevensbescherming) (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2016:119:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2016:119:TOC" target="_self" rel="noopener">PB L 119 van 4.5.2016, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc12-L_202401689NL.000101-E0012" href="about:blank#ntc12-L_202401689NL.000101-E0012" target="_self" rel="noopener">(12)</a> Verordening (EU) 2018/1725 van het Europees Parlement en de Raad van 23 oktober 2018 betreffende de bescherming van natuurlijke personen in verband met de verwerking van persoonsgegevens door de instellingen, organen en instanties van de Unie en betreffende het vrije verkeer van die gegevens, en tot intrekking van Verordening (EG) nr. 45/2001 en Besluit nr. 1247/2002/EG (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2018:295:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2018:295:TOC" target="_self" rel="noopener">PB L 295 van 21.11.2018, blz. 39</a>).<br>
<a class="internal-link" data-href="#ntc13-L_202401689NL.000101-E0013" href="about:blank#ntc13-L_202401689NL.000101-E0013" target="_self" rel="noopener">(13)</a> Richtlijn (EU) 2016/680 van het Europees Parlement en de Raad van 27 april 2016 betreffende de bescherming van natuurlijke personen in verband met de verwerking van persoonsgegevens door bevoegde autoriteiten met het oog op de voorkoming, het onderzoek, de opsporing en de vervolging van strafbare feiten of de tenuitvoerlegging van straffen, en betreffende het vrije verkeer van die gegevens en tot intrekking van KaderBesluit 2008/977/JBZ van de Raad (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2016:119:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2016:119:TOC" target="_self" rel="noopener">PB L 119 van 4.5.2016, blz. 89</a>).<br>
<a class="internal-link" data-href="#ntc14-L_202401689NL.000101-E0014" href="about:blank#ntc14-L_202401689NL.000101-E0014" target="_self" rel="noopener">(14)</a> Richtlijn 2002/58/EG van het Europees Parlement en de Raad van 12 juli 2002 betreffende de verwerking van persoonsgegevens en de bescherming van de persoonlijke levenssfeer in de sector elektronische communicatie (richtlijn betreffende privacy en elektronische communicatie) (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2002:201:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2002:201:TOC" target="_self" rel="noopener">PB L 201 van 31.7.2002, blz. 37</a>).<br>
<a class="internal-link" data-href="#ntc15-L_202401689NL.000101-E0015" href="about:blank#ntc15-L_202401689NL.000101-E0015" target="_self" rel="noopener">(15)</a> Verordening (EU) 2022/2065 van het Europees Parlement en de Raad van 19 oktober 2022 betreffende een eengemaakte markt voor digitale diensten en tot wijziging van Richtlijn 2000/31/EG (digitaledienstenverordening) (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2022:277:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2022:277:TOC" target="_self" rel="noopener">PB L 277 van 27.10.2022, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc16-L_202401689NL.000101-E0016" href="about:blank#ntc16-L_202401689NL.000101-E0016" target="_self" rel="noopener">(16)</a> Richtlijn (EU) 2019/882 van het Europees Parlement en de Raad van 17 april 2019 betreffende de toegankelijkheidsvoorschriften voor producten en diensten (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2019:151:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2019:151:TOC" target="_self" rel="noopener">PB L 151 van 7.6.2019, blz. 70</a>).<br>
<a class="internal-link" data-href="#ntc17-L_202401689NL.000101-E0017" href="about:blank#ntc17-L_202401689NL.000101-E0017" target="_self" rel="noopener">(17)</a> Richtlijn 2005/29/EG van het Europees Parlement en de Raad van 11 mei 2005 betreffende oneerlijke handelspraktijken van ondernemingen jegens consumenten op de interne markt en tot wijziging van Richtlijn 84/450/EEG van de Raad, Richtlijnen 97/7/EG, 98/27/EG en 2002/65/EG van het Europees Parlement en de Raad en van Verordening (EG) nr. 2006/2004 van het Europees Parlement en de Raad (“richtlijn oneerlijke handelspraktijken”) (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2005:149:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2005:149:TOC" target="_self" rel="noopener">PB L 149 van 11.6.2005, blz. 22</a>).<br>
<a class="internal-link" data-href="#ntc18-L_202401689NL.000101-E0018" href="about:blank#ntc18-L_202401689NL.000101-E0018" target="_self" rel="noopener">(18)</a> KaderBesluit 2002/584/JBZ van de Raad van 13 juni 2002 betreffende het Europees aanhoudingsbevel en de procedures van overlevering tussen de lidstaten (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2002:190:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2002:190:TOC" target="_self" rel="noopener">PB L 190 van 18.7.2002, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc19-L_202401689NL.000101-E0019" href="about:blank#ntc19-L_202401689NL.000101-E0019" target="_self" rel="noopener">(19)</a> Richtlijn (EU) 2022/2557 van het Europees Parlement en de Raad van 14 december 2022 betreffende de weerbaarheid van kritieke entiteiten en tot intrekking van Richtlijn 2008/114/EG van de Raad (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2022:333:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2022:333:TOC" target="_self" rel="noopener">PB L 333 van 27.12.2022, blz. 164</a>).<br>
<a class="internal-link" data-href="#ntc20-L_202401689NL.000101-E0020" href="about:blank#ntc20-L_202401689NL.000101-E0020" target="_self" rel="noopener">(20)</a> <a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:C:2022:247:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:C:2022:247:TOC" target="_self" rel="noopener">PB C 247 van 29.6.2022, blz. 1</a>.<br>
<a class="internal-link" data-href="#ntc21-L_202401689NL.000101-E0021" href="about:blank#ntc21-L_202401689NL.000101-E0021" target="_self" rel="noopener">(21)</a> Verordening (EU) 2017/745 van het Europees Parlement en de Raad van 5 april 2017 betreffende medische hulpmiddelen, tot wijziging van Richtlijn 2001/83/EG, Verordening (EG) nr. 178/2002 en Verordening (EG) nr. 1223/2009, en tot intrekking van Richtlijnen 90/385/EEG en 93/42/EEG van de Raad (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2017:117:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2017:117:TOC" target="_self" rel="noopener">PB L 117 van 5.5.2017, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc22-L_202401689NL.000101-E0022" href="about:blank#ntc22-L_202401689NL.000101-E0022" target="_self" rel="noopener">(22)</a> Verordening (EU) 2017/746 van het Europees Parlement en de Raad van 5 april 2017 betreffende medische hulpmiddelen voor in-vitrodiagnostiek en tot intrekking van Richtlijn 98/79/EG en Besluit 2010/227/EU van de Commissie (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2017:117:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2017:117:TOC" target="_self" rel="noopener">PB L 117 van 5.5.2017, blz. 176</a>).<br>
<a class="internal-link" data-href="#ntc23-L_202401689NL.000101-E0023" href="about:blank#ntc23-L_202401689NL.000101-E0023" target="_self" rel="noopener">(23)</a> Richtlijn 2006/42/EG van het Europees Parlement en de Raad van 17 mei 2006 betreffende machines en tot wijziging van Richtlijn 95/16/EG (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2006:157:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2006:157:TOC" target="_self" rel="noopener">PB L 157 van 9.6.2006, blz. 24</a>).<br>
<a class="internal-link" data-href="#ntc24-L_202401689NL.000101-E0024" href="about:blank#ntc24-L_202401689NL.000101-E0024" target="_self" rel="noopener">(24)</a> Verordening (EG) nr. 300/2008 van het Europees Parlement en de Raad van 11 maart 2008 inzake gemeenschappelijke regels op het gebied van de beveiliging van de burgerluchtvaart en tot intrekking van Verordening (EG) nr. 2320/2002 (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2008:097:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2008:097:TOC" target="_self" rel="noopener">PB L 97 van 9.4.2008, blz. 72</a>).<br>
<a class="internal-link" data-href="#ntc25-L_202401689NL.000101-E0025" href="about:blank#ntc25-L_202401689NL.000101-E0025" target="_self" rel="noopener">(25)</a> Verordening (EU) nr. 167/2013 van het Europees Parlement en de Raad van 5 februari 2013 inzake de goedkeuring van en het markttoezicht op landbouw- en bosbouwvoertuigen (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2013:060:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2013:060:TOC" target="_self" rel="noopener">PB L 60 van 2.3.2013, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc26-L_202401689NL.000101-E0026" href="about:blank#ntc26-L_202401689NL.000101-E0026" target="_self" rel="noopener">(26)</a> Verordening (EU) nr. 168/2013 van het Europees Parlement en de Raad van 15 januari 2013 betreffende de goedkeuring van en het markttoezicht op twee- of driewielige voertuigen en vierwielers (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2013:060:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2013:060:TOC" target="_self" rel="noopener">PB L 60 van 2.3.2013, blz. 52</a>).<br>
<a class="internal-link" data-href="#ntc27-L_202401689NL.000101-E0027" href="about:blank#ntc27-L_202401689NL.000101-E0027" target="_self" rel="noopener">(27)</a> Richtlijn 2014/90/EU van het Europees Parlement en de Raad van 23 juli 2014 inzake uitrusting van zeeschepen en tot intrekking van Richtlijn 96/98/EG van de Raad (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2014:257:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2014:257:TOC" target="_self" rel="noopener">PB L 257 van 28.8.2014, blz. 146</a>).<br>
<a class="internal-link" data-href="#ntc28-L_202401689NL.000101-E0028" href="about:blank#ntc28-L_202401689NL.000101-E0028" target="_self" rel="noopener">(28)</a> Richtlijn (EU) 2016/797 van het Europees Parlement en de Raad van 11 mei 2016 betreffende de interoperabiliteit van het spoorwegsysteem in de Europese Unie (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2016:138:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2016:138:TOC" target="_self" rel="noopener">PB L 138 van 26.5.2016, blz. 44</a>).<br>
<a class="internal-link" data-href="#ntc29-L_202401689NL.000101-E0029" href="about:blank#ntc29-L_202401689NL.000101-E0029" target="_self" rel="noopener">(29)</a> Verordening (EU) 2018/858 van het Europees Parlement en de Raad van 30 mei 2018 betreffende de goedkeuring van en het markttoezicht op motorvoertuigen en aanhangwagens daarvan en systemen, onderdelen en technische eenheden die voor dergelijke voertuigen zijn bestemd, tot wijziging van Verordeningen (EG) nr. 715/2007 en (EG) nr. 595/2009 en tot intrekking van Richtlijn 2007/46/EG (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2018:151:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2018:151:TOC" target="_self" rel="noopener">PB L 151 van 14.6.2018, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc30-L_202401689NL.000101-E0030" href="about:blank#ntc30-L_202401689NL.000101-E0030" target="_self" rel="noopener">(30)</a> Verordening (EU) 2018/1139 van het Europees Parlement en de Raad van 4 juli 2018 inzake gemeenschappelijke regels op het gebied van burgerluchtvaart en tot oprichting van een Agentschap van de Europese Unie voor de veiligheid van de luchtvaart, en tot wijziging van de Verordeningen (EG) nr. 2111/2005, (EG) nr. 1008/2008, (EU) nr. 996/2010, (EU) nr. 376/2014 en de Richtlijnen 2014/30/EU en 2014/53/EU van het Europees Parlement en de Raad, en tot intrekking van de Verordeningen (EG) nr. 552/2004 en (EG) nr. 216/2008 van het Europees Parlement en de Raad en Verordening (EEG) nr. 3922/91 van de Raad (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2018:212:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2018:212:TOC" target="_self" rel="noopener">PB L 212 van 22.8.2018, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc31-L_202401689NL.000101-E0031" href="about:blank#ntc31-L_202401689NL.000101-E0031" target="_self" rel="noopener">(31)</a> Verordening (EU) 2019/2144 van het Europees Parlement en de Raad van 27 november 2019 betreffende de voorschriften voor de typegoedkeuring van motorvoertuigen en aanhangwagens daarvan en van systemen, onderdelen en technische eenheden die voor dergelijke voertuigen zijn bestemd wat de algemene veiligheid ervan en de bescherming van de inzittenden van voertuigen en kwetsbare weggebruikers betreft, tot wijziging van Verordening (EU) 2018/858 van het Europees Parlement en de Raad en tot intrekking van de Verordeningen (EG) nr. 78/2009, (EG) nr. 79/2009 en (EG) nr. 661/2009 van het Europees Parlement en de Raad en de Verordeningen (EG) nr. 631/2009, (EU) nr. 406/2010, (EU) nr. 672/2010, (EU) nr. 1003/2010, (EU) nr. 1005/2010, (EU) nr. 1008/2010, (EU) nr. 1009/2010, (EU) nr. 19/2011, (EU) nr. 109/2011, (EU) nr. 458/2011, (EU) nr. 65/2012, (EU) nr. 130/2012, (EU) nr. 347/2012, (EU) nr. 351/2012, (EU) nr. 1230/2012 en (EU) 2015/166 van de Commissie (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2019:325:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2019:325:TOC" target="_self" rel="noopener">PB L 325 van 16.12.2019, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc32-L_202401689NL.000101-E0032" href="about:blank#ntc32-L_202401689NL.000101-E0032" target="_self" rel="noopener">(32)</a> Verordening (EG) nr. 810/2009 van het Europees Parlement en de Raad van 13 juli 2009 tot vaststelling van een gemeenschappelijke visumcode (Visumcode) (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2009:243:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2009:243:TOC" target="_self" rel="noopener">PB L 243 van 15.9.2009, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc33-L_202401689NL.000101-E0033" href="about:blank#ntc33-L_202401689NL.000101-E0033" target="_self" rel="noopener">(33)</a> Richtlijn 2013/32/EU van het Europees Parlement en de Raad van 26 juni 2013 betreffende gemeenschappelijke procedures voor de toekenning en intrekking van de internationale bescherming (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2013:180:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2013:180:TOC" target="_self" rel="noopener">PB L 180 van 29.6.2013, blz. 60</a>).<br>
<a class="internal-link" data-href="#ntc34-L_202401689NL.000101-E0034" href="about:blank#ntc34-L_202401689NL.000101-E0034" target="_self" rel="noopener">(34)</a> Verordening (EU) 2024/900 van het Europees Parlement en de Raad van 13 maart 2024 betreffende transparantie en gerichte politieke reclame (<a data-tooltip-position="top" aria-label="http://data.europa.eu/eli/reg/2024/900/oj" rel="noopener" class="external-link" href="http://data.europa.eu/eli/reg/2024/900/oj" target="_blank">PB L, 2024/900, 20.3.2024, ELI: http://data.europa.eu/eli/reg/2024/900/oj</a>).<br>
<a class="internal-link" data-href="#ntc35-L_202401689NL.000101-E0035" href="about:blank#ntc35-L_202401689NL.000101-E0035" target="_self" rel="noopener">(35)</a> Richtlijn 2014/31/EU van het Europees Parlement en de Raad van 26 februari 2014 betreffende de harmonisatie van de wetgevingen van de lidstaten inzake het op de markt aanbieden van niet-automatische weegwerktuigen (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2014:096:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2014:096:TOC" target="_self" rel="noopener">PB L 96 van 29.3.2014, blz. 107</a>).<br>
<a class="internal-link" data-href="#ntc36-L_202401689NL.000101-E0036" href="about:blank#ntc36-L_202401689NL.000101-E0036" target="_self" rel="noopener">(36)</a> Richtlijn 2014/32/EU van het Europees Parlement en de Raad van 26 februari 2014 betreffende de harmonisatie van de wetgevingen van de lidstaten inzake het op de markt aanbieden van meetinstrumenten (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2014:096:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2014:096:TOC" target="_self" rel="noopener">PB L 96 van 29.3.2014, blz. 149</a>).<br>
<a class="internal-link" data-href="#ntc37-L_202401689NL.000101-E0037" href="about:blank#ntc37-L_202401689NL.000101-E0037" target="_self" rel="noopener">(37)</a> Verordening (EU) 2019/881 van het Europees Parlement en de Raad van 17 april 2019 inzake Enisa (het Agentschap van de Europese Unie voor cyberbeveiliging), en inzake de certificering van de cyberbeveiliging van informatie- en communicatietechnologie en tot intrekking van Verordening (EU) nr. 526/2013 (cyberbeveiligingsverordening) (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2019:151:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2019:151:TOC" target="_self" rel="noopener">PB L 151 van 7.6.2019, blz. 15</a>).<br>
<a class="internal-link" data-href="#ntc38-L_202401689NL.000101-E0038" href="about:blank#ntc38-L_202401689NL.000101-E0038" target="_self" rel="noopener">(38)</a> Richtlijn (EU) 2016/2102 van het Europees Parlement en de Raad van 26 oktober 2016 inzake de toegankelijkheid van de websites en mobiele applicaties van overheidsinstanties (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2016:327:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2016:327:TOC" target="_self" rel="noopener">PB L 327 van 2.12.2016, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc39-L_202401689NL.000101-E0039" href="about:blank#ntc39-L_202401689NL.000101-E0039" target="_self" rel="noopener">(39)</a> Richtlijn 2002/14/EG van het Europees Parlement en de Raad van 11 maart 2002 tot vaststelling van een algemeen kader betreffende de informatie en de raadpleging van de werknemers in de Europese Gemeenschap (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2002:080:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2002:080:TOC" target="_self" rel="noopener">PB L 80 van 23.3.2002, blz. 29</a>).<br>
<a class="internal-link" data-href="#ntc40-L_202401689NL.000101-E0040" href="about:blank#ntc40-L_202401689NL.000101-E0040" target="_self" rel="noopener">(40)</a> Richtlijn (EU) 2019/790 van het Europees Parlement en de Raad van 17 april 2019 inzake auteursrechten en naburige rechten in de digitale eengemaakte markt en tot wijziging van Richtlijnen 96/9/EG en 2001/29/EG (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2019:130:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2019:130:TOC" target="_self" rel="noopener">PB L 130 van 17.5.2019, blz. 92</a>).<br>
<a class="internal-link" data-href="#ntc41-L_202401689NL.000101-E0041" href="about:blank#ntc41-L_202401689NL.000101-E0041" target="_self" rel="noopener">(41)</a> Verordening (EU) nr. 1025/2012 van het Europees Parlement en de Raad van 25 oktober 2012 betreffende Europese normalisatie, tot wijziging van de Richtlijnen 89/686/EEG en 93/15/EEG van de Raad alsmede de Richtlijnen 94/9/EG, 94/25/EG, 95/16/EG, 97/23/EG, 98/34/EG, 2004/22/EG, 2007/23/EG, 2009/23/EG en 2009/105/EG van het Europees Parlement en de Raad en tot intrekking van Beschikking 87/95/EEG van de Raad en Besluit nr. 1673/2006/EG van het Europees Parlement en de Raad (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2012:316:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2012:316:TOC" target="_self" rel="noopener">PB L 316 van 14.11.2012, blz. 12</a>).<br>
<a class="internal-link" data-href="#ntc42-L_202401689NL.000101-E0042" href="about:blank#ntc42-L_202401689NL.000101-E0042" target="_self" rel="noopener">(42)</a> Verordening (EU) 2022/868 van het Europees Parlement en de Raad van 30 mei 2022 betreffende Europese datagovernance en tot wijziging van Verordening (EU) 2018/1724 (datagovernanceverordening) (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2022:152:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2022:152:TOC" target="_self" rel="noopener">PB L 152 van 3.6.2022, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc43-L_202401689NL.000101-E0043" href="about:blank#ntc43-L_202401689NL.000101-E0043" target="_self" rel="noopener">(43)</a> Verordening (EU) 2023/2854 van het Europees Parlement en de Raad van 13 december 2023 betreffende geharmoniseerde regels inzake eerlijke toegang tot en eerlijk gebruik van data en tot wijziging van Verordening (EU) 2017/2394 en Richtlijn (EU) 2020/1828 (dataverordening) (<a data-tooltip-position="top" aria-label="http://data.europa.eu/eli/reg/2023/2854/oj" rel="noopener" class="external-link" href="http://data.europa.eu/eli/reg/2023/2854/oj" target="_blank">PB L, 2023/2854, 22.12.2023, ELI: http://data.europa.eu/eli/reg/2023/2854/oj</a>).<br>
<a class="internal-link" data-href="#ntc44-L_202401689NL.000101-E0044" href="about:blank#ntc44-L_202401689NL.000101-E0044" target="_self" rel="noopener">(44)</a> Aanbeveling van de Commissie van 6 mei 2003 betreffende de definitie van kleine, middelgrote en micro-ondernemingen (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2003:124:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2003:124:TOC" target="_self" rel="noopener">PB L 124 van 20.5.2003, blz. 36</a>).<br>
<a class="internal-link" data-href="#ntc45-L_202401689NL.000101-E0045" href="about:blank#ntc45-L_202401689NL.000101-E0045" target="_self" rel="noopener">(45)</a> Besluit van de Commissie van 24 januari 2024 tot oprichting van het Europees Bureau voor artificiële intelligentie (C/2024/390).<br>
<a class="internal-link" data-href="#ntc46-L_202401689NL.000101-E0046" href="about:blank#ntc46-L_202401689NL.000101-E0046" target="_self" rel="noopener">(46)</a> Verordening (EU) nr. 575/2013 van het Europees Parlement en de Raad van 26 juni 2013 betreffende prudentiële vereisten voor kredietinstellingen en beleggingsondernemingen en tot wijziging van Verordening (EU) nr. 648/2012 (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2013:176:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2013:176:TOC" target="_self" rel="noopener">PB L 176 van 27.6.2013, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc47-L_202401689NL.000101-E0047" href="about:blank#ntc47-L_202401689NL.000101-E0047" target="_self" rel="noopener">(47)</a> Richtlijn 2008/48/EG van het Europees Parlement en de Raad van 23 april 2008 inzake kredietovereenkomsten voor consumenten en tot intrekking van Richtlijn 87/102/EEG van de Raad (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2008:133:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2008:133:TOC" target="_self" rel="noopener">PB L 133 van 22.5.2008, blz. 66</a>).<br>
<a class="internal-link" data-href="#ntc48-L_202401689NL.000101-E0048" href="about:blank#ntc48-L_202401689NL.000101-E0048" target="_self" rel="noopener">(48)</a> Richtlijn 2009/138/EG van het Europees Parlement en de Raad van 25 november 2009 betreffende de toegang tot en uitoefening van het verzekerings- en het herverzekeringsbedrijf (Solvabiliteit II) (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2009:335:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2009:335:TOC" target="_self" rel="noopener">PB L 335 van 17.12.2009, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc49-L_202401689NL.000101-E0049" href="about:blank#ntc49-L_202401689NL.000101-E0049" target="_self" rel="noopener">(49)</a> Richtlijn 2013/36/EU van het Europees Parlement en de Raad van 26 juni 2013 betreffende toegang tot het bedrijf van kredietinstellingen en het prudentieel toezicht op kredietinstellingen en beleggingsondernemingen, tot wijziging van Richtlijn 2002/87/EG en tot intrekking van de Richtlijnen 2006/48/EG en 2006/49/EG (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2013:176:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2013:176:TOC" target="_self" rel="noopener">PB L 176 van 27.6.2013, blz. 338</a>).<br>
<a class="internal-link" data-href="#ntc50-L_202401689NL.000101-E0050" href="about:blank#ntc50-L_202401689NL.000101-E0050" target="_self" rel="noopener">(50)</a> Richtlijn 2014/17/EU van het Europees Parlement en de Raad van 4 februari 2014 inzake kredietovereenkomsten voor consumenten met betrekking tot voor bewoning bestemde onroerende goederen en tot wijziging van de Richtlijnen 2008/48/EG en 2013/36/EU en Verordening (EU) nr. 1093/2010 (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2014:060:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2014:060:TOC" target="_self" rel="noopener">PB L 60 van 28.2.2014, blz. 34</a>).<br>
<a class="internal-link" data-href="#ntc51-L_202401689NL.000101-E0051" href="about:blank#ntc51-L_202401689NL.000101-E0051" target="_self" rel="noopener">(51)</a> Richtlijn (EU) 2016/97 van het Europees Parlement en de Raad van 20 januari 2016 betreffende verzekeringsdistributie (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2016:026:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2016:026:TOC" target="_self" rel="noopener">PB L 26 van 2.2.2016, blz. 19</a>).<br>
<a class="internal-link" data-href="#ntc52-L_202401689NL.000101-E0052" href="about:blank#ntc52-L_202401689NL.000101-E0052" target="_self" rel="noopener">(52)</a> Verordening (EU) nr. 1024/2013 van de Raad van 15 oktober 2013 waarbij aan de Europese Centrale Bank specifieke taken worden opgedragen betreffende het beleid inzake het prudentieel toezicht op kredietinstellingen (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2013:287:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2013:287:TOC" target="_self" rel="noopener">PB L 287 van 29.10.2013, blz. 63</a>).<br>
<a class="internal-link" data-href="#ntc53-L_202401689NL.000101-E0053" href="about:blank#ntc53-L_202401689NL.000101-E0053" target="_self" rel="noopener">(53)</a> Verordening (EU) 2023/988 van het Europees Parlement en de Raad van 10 mei 2023 inzake algemene productveiligheid, tot wijziging van Verordening (EU) nr. 1025/2012 van het Europees Parlement en de Raad en Richtlijn (EU) 2020/1828 van het Europees Parlement en de Raad, en tot intrekking van Richtlijn 2001/95/EG van het Europees Parlement en de Raad en Richtlijn 87/357/EEG van de Raad (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2023:135:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2023:135:TOC" target="_self" rel="noopener">PB L 135 van 23.5.2023, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc54-L_202401689NL.000101-E0054" href="about:blank#ntc54-L_202401689NL.000101-E0054" target="_self" rel="noopener">(54)</a> Richtlijn (EU) 2019/1937 van het Europees Parlement en de Raad van 23 oktober 2019 inzake de bescherming van personen die inbreuken op het Unierecht melden (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2019:305:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2019:305:TOC" target="_self" rel="noopener">PB L 305 van 26.11.2019, blz. 17</a>).<br>
<a class="internal-link" data-href="#ntc55-L_202401689NL.000101-E0055" href="about:blank#ntc55-L_202401689NL.000101-E0055" target="_self" rel="noopener">(55)</a> <a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2016:123:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2016:123:TOC" target="_self" rel="noopener">PB L 123 van 12.5.2016, blz. 1</a>.<br>
<a class="internal-link" data-href="#ntc56-L_202401689NL.000101-E0056" href="about:blank#ntc56-L_202401689NL.000101-E0056" target="_self" rel="noopener">(56)</a> Verordening (EU) nr. 182/2011 van het Europees Parlement en de Raad van 16 februari 2011 tot vaststelling van de algemene voorschriften en beginselen die van toepassing zijn op de wijze waarop de lidstaten de uitoefening van de uitvoeringsbevoegdheden door de Commissie controleren (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2011:055:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2011:055:TOC" target="_self" rel="noopener">PB L 55 van 28.2.2011, blz. 13</a>).<br>
<a class="internal-link" data-href="#ntc57-L_202401689NL.000101-E0057" href="about:blank#ntc57-L_202401689NL.000101-E0057" target="_self" rel="noopener">(57)</a> Richtlijn (EU) 2016/943 van het Europees Parlement en de Raad van 8 juni 2016 betreffende de bescherming van niet-openbaar gemaakte knowhow en bedrijfsinformatie (bedrijfsgeheimen) tegen het onrechtmatig verkrijgen, gebruiken en openbaar maken daarvan (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2016:157:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2016:157:TOC" target="_self" rel="noopener">PB L 157 van 15.6.2016, blz. 1</a>).<br>
<a class="internal-link" data-href="#ntc58-L_202401689NL.000101-E0066" href="about:blank#ntc58-L_202401689NL.000101-E0066" target="_self" rel="noopener">(58)</a> Richtlijn (EU) 2020/1828 van het Europees Parlement en de Raad van 25 november 2020 betreffende representatieve vorderingen ter bescherming van de collectieve belangen van consumenten en tot intrekking van Richtlijn 2009/22/EG (<a class="internal-link" data-href="./../../../../legal-content/NL/AUTO/?uri=OJ:L:2020:409:TOC" href="../../../../legal-content/NL/AUTO?uri=OJ:L:2020:409:TOC" target="_self" rel="noopener">PB L 409 van 4.12.2020, blz. 1</a>).]]></description><link>hoofdstukken/hoofdstuk_13.html</link><guid isPermaLink="false">Hoofdstukken/hoofdstuk_13.md</guid><pubDate>Tue, 13 Aug 2024 13:55:53 GMT</pubDate></item></channel></rss>